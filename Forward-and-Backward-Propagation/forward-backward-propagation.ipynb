{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Explain the concept of forward propagation in a neural network.\n",
    "ans:\n",
    "Forward Propagation in a neural network is used to compute and transmit the input data through the network's layers in a sequential manner, ultimately generating an output prediction. It is an essential step in the operation of a neural network during both training and inference.\n",
    "\n",
    "During forward propagation, the input data is fed into the network, and the computations flow forward through the layers. Each neuron in a layer receives inputs from the neurons in the previous layer, applies a set of weights and biases to those inputs, and passes the result through an activation function. This process continues until the data reaches the output layer, where the final prediction or output of the network is generated.\n",
    "\n",
    "`Forward propagation can be mathematically represented as a series of matrix multiplications and activation function applications`. By propagating the data through the network, the model learns to transform the input data into a useful representation that can be used for tasks like classification, regression, or any other problem the network is designed to solve.\n",
    "\n",
    "During training, forward propagation is followed by the calculation of the loss, which measures the difference between the network's predicted output and the expected output. This loss is then used to adjust the network's weights and biases during the subsequent backpropagation step, which helps the network learn and improve its performance over time.\n",
    "\n",
    "It involves the following steps:\n",
    "\n",
    "- Input Layer: \n",
    "  - The input data is fed into the input layer of the neural network.\n",
    "- Hidden Layers: \n",
    "  - The input data is processed through one or more hidden layers. Each neuron in a hidden layer receives inputs from the previous layer, applies an activation function to the weighted sum of these inputs, and passes the result to the next layer.\n",
    "- Output Layer: \n",
    "  - The processed data moves through the output layer, where the final output of the network is generated. The output layer typically applies an activation function suitable for the task, such as softmax for classification or linear activation for regression.\n",
    "- Prediction: \n",
    "  - The final output of the network is the prediction or classification result for the input data.\n",
    "\n",
    "In summary, forward propagation enables the flow of data through the network, producing predictions or outputs based on the given inputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. What is the purpose of the activation function in forward propagation ?\n",
    "ans:\n",
    "\n",
    "Activation functions are used during forward propagation in neural networks to introduce non-linearity to the output of each neuron or unit in a layer. The activation function is applied to the weighted sum of inputs and biases, also known as the activation value or pre-activation value, before passing it as the output of that neuron.\n",
    "\n",
    "Mathematically, let's denote the weighted sum of inputs and biases as z for a particular neuron in a layer. The activation function, denoted as σ(z), is applied element-wise to the value of z, producing the output of the neuron, which is commonly denoted as a. Therefore, we have:\n",
    "\n",
    "a = σ(z)\n",
    "\n",
    "The choice of activation function depends on the nature of the problem and the desired properties of the network. Here are some commonly used activation functions:\n",
    "\n",
    "1. Step function: A simple activation function that outputs a binary value based on a threshold. If the input is above the threshold, it outputs one; otherwise, it outputs zero. However, the step function is rarely used in practice due to its lack of differentiability.\n",
    "\n",
    "2. Sigmoid function: The sigmoid function squashes the input into a range between 0 and 1, which makes it suitable for binary classification problems. It has a smooth, S-shaped curve and is given by the formula:\n",
    "\n",
    "   σ(z) = 1 / (1 + exp(-z))\n",
    "\n",
    "3. Hyperbolic tangent (tanh) function: The tanh function is similar to the sigmoid function but squashes the input into a range between -1 and 1. It is useful when the output range needs to be symmetric around zero:\n",
    "\n",
    "   σ(z) = (exp(z) - exp(-z)) / (exp(z) + exp(-z))\n",
    "\n",
    "4. Rectified Linear Unit (ReLU): The ReLU activation function is widely used in deep learning networks. It returns the input if it is positive, otherwise, it outputs zero. Mathematically, ReLU is defined as:\n",
    "\n",
    "   σ(z) = max(0, z)\n",
    "\n",
    "5. Leaky ReLU: Leaky ReLU is a modified version of the ReLU function that allows small negative values when the input is less than zero. It addresses the \"dying ReLU\" problem, where certain neurons may become inactive during training. Leaky ReLU is defined as:\n",
    "\n",
    "   σ(z) = max(αz, z) (where α is a small positive constant)\n",
    "\n",
    "These are just a few examples of activation functions commonly used in neural networks. The choice of activation function depends on the specific problem and the characteristics of the data being processed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Describe the steps involved in the backward propagation (backpropagation) algorithm.\n",
    "ans:\n",
    "\n",
    "`Backward Propagation, also known as BackPropagation`, in a neural network is `used to calculate the gradients of the network's parameters (weights and biases) with respect to the loss function`. It is an essential step in the training process of a neural network, allowing it to learn and improve its performance.\n",
    "\n",
    "During forward propagation, the input data flows through the network, and the output prediction is generated. `In the subsequent step of backward propagation, the gradients are calculated by propagating the error backward from the output layer to the input layer`. The gradients represent the sensitivity of the loss function with respect to each parameter, indicating how changing a particular parameter would affect the overall loss.\n",
    "\n",
    "The process of backward propagation involves the following steps:\n",
    "\n",
    "1. Loss calculation: \n",
    "   - First, the loss function is calculated by comparing the network's output with the expected output. The choice of loss function depends on the specific problem, such as mean squared error for regression or cross-entropy loss for classification.\n",
    "\n",
    "2. Gradient calculation: \n",
    "   - Starting from the output layer, the gradients of the parameters with respect to the loss function are calculated layer by layer, moving backward through the network. This is done using the chain rule of calculus, which allows the gradients to be recursively computed based on the gradients of subsequent layers.\n",
    "\n",
    "3. Weight and bias updates: \n",
    "   - Once the gradients are obtained, they are used to update the weights and biases of the network. This update step is typically performed using an optimization algorithm such as gradient descent, where the parameters are adjusted in the opposite direction of the gradients to minimize the loss function.\n",
    "\n",
    "By iteratively performing forward propagation and backward propagation, the neural network gradually learns to adjust its weights and biases to minimize the loss and improve its performance on the given task. The gradients obtained from backward propagation guide the optimization process, allowing the network to update its parameters in a way that reduces the error and improves its ability to make accurate predictions.\n",
    "\n",
    "In summary, backward propagation plays a critical role in training a neural network by calculating the gradients of the parameters with respect to the loss function. It enables the network to learn from the training data and adjust its parameters to minimize the error, leading to improved performance on the task at hand."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. What is the purpose of the chain rule in backpropagation ?\n",
    "ans:\n",
    "\n",
    "The chain rule is a fundamental rule in calculus that allows us to calculate the derivative of a composition of functions. In the context of neural networks and backward propagation, the chain rule is essential for efficiently computing the gradients of the loss function with respect to the network's parameters (weights and biases) at each layer.\n",
    "\n",
    "The chain rule states that if we have a composition of functions, say function f(x) and g(u), and we want to calculate the derivative of f(g(x)) with respect to x, we can express it as the product of the derivatives of f and g with respect to their respective variables, multiplied together.\n",
    "\n",
    "Mathematically, if we have y = f(g(x)), then the chain rule can be stated as:\n",
    "\n",
    "dy/dx = (df/du) * (dg/dx)\n",
    "\n",
    "Applying the chain rule in the context of backward propagation in a neural network, we can break down the derivative calculation step by step:\n",
    "\n",
    "1. Start with the loss function L and the output of a neuron (denoted as a) in a particular layer.\n",
    "2. Calculate the derivative of the loss function with respect to a, denoted as δL/δa. This measures how much the loss function changes with respect to the output of the neuron.\n",
    "3. Calculate the derivative of the activation function (denoted as σ) with respect to the weighted sum (denoted as z) of the neuron. Denote this derivative as δa/δz.\n",
    "4. Compute the derivative of the weighted sum (z) with respect to the parameters (weights w and biases b) of the neuron. Denote these derivatives as δz/δw and δz/δb.\n",
    "5. Apply the chain rule to calculate the gradients of the loss with respect to the weights and biases:\n",
    "\n",
    "   δL/δw = δL/δa * δa/δz * δz/δw\n",
    "   δL/δb = δL/δa * δa/δz * δz/δb\n",
    "\n",
    "By applying the chain rule repeatedly for each layer during backward propagation, the gradients of the loss function with respect to the weights and biases at each layer can be efficiently calculated. These gradients are then used to update the parameters of the network in the optimization step, allowing the network to learn and improve its performance.\n",
    "\n",
    "The chain rule is a fundamental tool that enables the efficient calculation of gradients in complex networks with multiple layers and non-linear activation functions. It forms the basis for the successful implementation of backward propagation, which is essential for training deep neural networks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Implement the forward propagation process for a simple neural network with one hidden layer using NumPy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 0\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.37660359]\n",
      " [0.38619524]\n",
      " [0.37145716]]\n",
      "Loss: \n",
      "0.262885763875226\n",
      "\n",
      "\n",
      "# 1\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.49565923]\n",
      " [0.49131673]\n",
      " [0.48467816]]\n",
      "Loss: \n",
      "0.1600927434619697\n",
      "\n",
      "\n",
      "# 2\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.59403403]\n",
      " [0.57863829]\n",
      " [0.57918871]]\n",
      "Loss: \n",
      "0.09400729688191782\n",
      "\n",
      "\n",
      "# 3\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.66306284]\n",
      " [0.6409112 ]\n",
      " [0.64637886]]\n",
      "Loss: \n",
      "0.05778928895972654\n",
      "\n",
      "\n",
      "# 4\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.71006768]\n",
      " [0.68409192]\n",
      " [0.69268446]]\n",
      "Loss: \n",
      "0.037982883646824644\n",
      "\n",
      "\n",
      "# 5\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.74307036]\n",
      " [0.71491554]\n",
      " [0.725521  ]]\n",
      "Loss: \n",
      "0.026468980037131457\n",
      "\n",
      "\n",
      "# 6\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.76723432]\n",
      " [0.73780929]\n",
      " [0.74975854]]\n",
      "Loss: \n",
      "0.019311863724321764\n",
      "\n",
      "\n",
      "# 7\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.78561363]\n",
      " [0.75543736]\n",
      " [0.76831665]]\n",
      "Loss: \n",
      "0.014599959955896349\n",
      "\n",
      "\n",
      "# 8\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.80004277]\n",
      " [0.76942366]\n",
      " [0.78296703]]\n",
      "Loss: \n",
      "0.011349956151746258\n",
      "\n",
      "\n",
      "# 9\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.81166711]\n",
      " [0.78079508]\n",
      " [0.79482504]]\n",
      "Loss: \n",
      "0.009022569129366664\n",
      "\n",
      "\n",
      "# 10\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.82123181]\n",
      " [0.79022714]\n",
      " [0.80462129]]\n",
      "Loss: \n",
      "0.0073043106488594675\n",
      "\n",
      "\n",
      "# 11\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.82924023]\n",
      " [0.79818074]\n",
      " [0.81285225]]\n",
      "Loss: \n",
      "0.0060035769483361605\n",
      "\n",
      "\n",
      "# 12\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.83604391]\n",
      " [0.80498066]\n",
      " [0.81986641]]\n",
      "Loss: \n",
      "0.004998158026201605\n",
      "\n",
      "\n",
      "# 13\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.84189551]\n",
      " [0.8108622 ]\n",
      " [0.82591537]]\n",
      "Loss: \n",
      "0.004207224808546414\n",
      "\n",
      "\n",
      "# 14\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.84698127]\n",
      " [0.81600008]\n",
      " [0.83118532]]\n",
      "Loss: \n",
      "0.003575631656073603\n",
      "\n",
      "\n",
      "# 15\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.85144143]\n",
      " [0.82052679]\n",
      " [0.83581703]]\n",
      "Loss: \n",
      "0.0030647352551461623\n",
      "\n",
      "\n",
      "# 16\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.85538371]\n",
      " [0.82454472]\n",
      " [0.8399189 ]]\n",
      "Loss: \n",
      "0.002646819788661064\n",
      "\n",
      "\n",
      "# 17\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.85889217]\n",
      " [0.82813424]\n",
      " [0.84357584]]\n",
      "Loss: \n",
      "0.0023015987281759928\n",
      "\n",
      "\n",
      "# 18\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.86203346]\n",
      " [0.83135941]\n",
      " [0.84685533]]\n",
      "Loss: \n",
      "0.0020139551703493882\n",
      "\n",
      "\n",
      "# 19\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.86486109]\n",
      " [0.83427193]\n",
      " [0.84981169]]\n",
      "Loss: \n",
      "0.001772444254031675\n",
      "\n",
      "\n",
      "# 20\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.86741855]\n",
      " [0.83691402]\n",
      " [0.85248918]]\n",
      "Loss: \n",
      "0.0015682776883729555\n",
      "\n",
      "\n",
      "# 21\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.86974156]\n",
      " [0.83932051]\n",
      " [0.85492422]]\n",
      "Loss: \n",
      "0.0013946209474553911\n",
      "\n",
      "\n",
      "# 22\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.87185974]\n",
      " [0.84152042]\n",
      " [0.85714708]]\n",
      "Loss: \n",
      "0.0012460978192441786\n",
      "\n",
      "\n",
      "# 23\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.8737979 ]\n",
      " [0.84353811]\n",
      " [0.85918316]]\n",
      "Loss: \n",
      "0.0011184352683945413\n",
      "\n",
      "\n",
      "# 24\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.87557693]\n",
      " [0.84539422]\n",
      " [0.86105389]]\n",
      "Loss: \n",
      "0.00100820499926135\n",
      "\n",
      "\n",
      "# 25\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.8772146 ]\n",
      " [0.84710636]\n",
      " [0.86277754]]\n",
      "Loss: \n",
      "0.0009126327802928422\n",
      "\n",
      "\n",
      "# 26\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.87872612]\n",
      " [0.84868962]\n",
      " [0.86436975]]\n",
      "Loss: \n",
      "0.0008294559790226298\n",
      "\n",
      "\n",
      "# 27\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.88012456]\n",
      " [0.85015704]\n",
      " [0.86584399]]\n",
      "Loss: \n",
      "0.0007568158795335705\n",
      "\n",
      "\n",
      "# 28\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.88142125]\n",
      " [0.85151997]\n",
      " [0.86721195]]\n",
      "Loss: \n",
      "0.0006931754185477169\n",
      "\n",
      "\n",
      "# 29\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.88262604]\n",
      " [0.85278827]\n",
      " [0.86848384]]\n",
      "Loss: \n",
      "0.0006372557184899739\n",
      "\n",
      "\n",
      "# 30\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.88374756]\n",
      " [0.85397064]\n",
      " [0.86966856]]\n",
      "Loss: \n",
      "0.000587986674076729\n",
      "\n",
      "\n",
      "# 31\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.88479338]\n",
      " [0.85507472]\n",
      " [0.87077398]]\n",
      "Loss: \n",
      "0.0005444681534567798\n",
      "\n",
      "\n",
      "# 32\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.88577019]\n",
      " [0.85610726]\n",
      " [0.87180702]]\n",
      "Loss: \n",
      "0.000505939292727133\n",
      "\n",
      "\n",
      "# 33\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.88668391]\n",
      " [0.85707427]\n",
      " [0.87277384]]\n",
      "Loss: \n",
      "0.0004717540162049682\n",
      "\n",
      "\n",
      "# 34\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.88753982]\n",
      " [0.85798112]\n",
      " [0.87367993]]\n",
      "Loss: \n",
      "0.0004413613854915672\n",
      "\n",
      "\n",
      "# 35\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.88834261]\n",
      " [0.85883259]\n",
      " [0.87453017]]\n",
      "Loss: \n",
      "0.0004142897228808755\n",
      "\n",
      "\n",
      "# 36\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.88909649]\n",
      " [0.85963298]\n",
      " [0.87532895]]\n",
      "Loss: \n",
      "0.00039013370639713846\n",
      "\n",
      "\n",
      "# 37\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.88980526]\n",
      " [0.86038617]\n",
      " [0.87608023]]\n",
      "Loss: \n",
      "0.0003685438204727375\n",
      "\n",
      "\n",
      "# 38\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.89047232]\n",
      " [0.86109567]\n",
      " [0.87678757]]\n",
      "Loss: \n",
      "0.0003492176859955799\n",
      "\n",
      "\n",
      "# 39\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.89110074]\n",
      " [0.86176462]\n",
      " [0.87745417]]\n",
      "Loss: \n",
      "0.0003318928988589693\n",
      "\n",
      "\n",
      "# 40\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.89169334]\n",
      " [0.86239591]\n",
      " [0.87808297]]\n",
      "Loss: \n",
      "0.0003163410862807231\n",
      "\n",
      "\n",
      "# 41\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.89225263]\n",
      " [0.86299215]\n",
      " [0.87867661]]\n",
      "Loss: \n",
      "0.00030236295152784467\n",
      "\n",
      "\n",
      "# 42\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.89278093]\n",
      " [0.86355574]\n",
      " [0.87923751]]\n",
      "Loss: \n",
      "0.0002897841250080133\n",
      "\n",
      "\n",
      "# 43\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.89328034]\n",
      " [0.86408884]\n",
      " [0.87976789]]\n",
      "Loss: \n",
      "0.00027845167642430647\n",
      "\n",
      "\n",
      "# 44\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.89375279]\n",
      " [0.86459346]\n",
      " [0.88026976]]\n",
      "Loss: \n",
      "0.00026823117138235336\n",
      "\n",
      "\n",
      "# 45\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.89420005]\n",
      " [0.86507143]\n",
      " [0.88074498]]\n",
      "Loss: \n",
      "0.0002590041783833283\n",
      "\n",
      "\n",
      "# 46\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.89462373]\n",
      " [0.86552445]\n",
      " [0.88119524]]\n",
      "Loss: \n",
      "0.00025066614994965765\n",
      "\n",
      "\n",
      "# 47\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.89502533]\n",
      " [0.86595405]\n",
      " [0.88162212]]\n",
      "Loss: \n",
      "0.000243124615781121\n",
      "\n",
      "\n",
      "# 48\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.89540622]\n",
      " [0.86636168]\n",
      " [0.88202706]]\n",
      "Loss: \n",
      "0.00023629763713821863\n",
      "\n",
      "\n",
      "# 49\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.89576766]\n",
      " [0.86674865]\n",
      " [0.8824114 ]]\n",
      "Loss: \n",
      "0.00023011248071592343\n",
      "\n",
      "\n",
      "# 50\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.89611084]\n",
      " [0.86711621]\n",
      " [0.88277636]]\n",
      "Loss: \n",
      "0.00022450447757970264\n",
      "\n",
      "\n",
      "# 51\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.89643683]\n",
      " [0.86746548]\n",
      " [0.8831231 ]]\n",
      "Loss: \n",
      "0.0002194160386538288\n",
      "\n",
      "\n",
      "# 52\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.89674664]\n",
      " [0.86779751]\n",
      " [0.88345267]]\n",
      "Loss: \n",
      "0.00021479580306494922\n",
      "\n",
      "\n",
      "# 53\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.89704121]\n",
      " [0.8681133 ]\n",
      " [0.88376606]]\n",
      "Loss: \n",
      "0.00021059789957366098\n",
      "\n",
      "\n",
      "# 54\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.8973214 ]\n",
      " [0.86841376]\n",
      " [0.88406419]]\n",
      "Loss: \n",
      "0.0002067813045487781\n",
      "\n",
      "\n",
      "# 55\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.89758803]\n",
      " [0.86869973]\n",
      " [0.88434792]]\n",
      "Loss: \n",
      "0.00020330928258977486\n",
      "\n",
      "\n",
      "# 56\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.89784184]\n",
      " [0.86897202]\n",
      " [0.88461802]]\n",
      "Loss: \n",
      "0.00020014889809253752\n",
      "\n",
      "\n",
      "# 57\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.89808355]\n",
      " [0.86923136]\n",
      " [0.88487526]]\n",
      "Loss: \n",
      "0.00019727058786788102\n",
      "\n",
      "\n",
      "# 58\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.8983138 ]\n",
      " [0.86947845]\n",
      " [0.88512033]]\n",
      "Loss: \n",
      "0.0001946477864311173\n",
      "\n",
      "\n",
      "# 59\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.89853322]\n",
      " [0.86971394]\n",
      " [0.88535388]]\n",
      "Loss: \n",
      "0.0001922565968397252\n",
      "\n",
      "\n",
      "# 60\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.89874237]\n",
      " [0.86993844]\n",
      " [0.88557651]]\n",
      "Loss: \n",
      "0.0001900755010092503\n",
      "\n",
      "\n",
      "# 61\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.89894181]\n",
      " [0.87015252]\n",
      " [0.8857888 ]]\n",
      "Loss: \n",
      "0.00018808510432183164\n",
      "\n",
      "\n",
      "# 62\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.89913203]\n",
      " [0.87035672]\n",
      " [0.88599128]]\n",
      "Loss: \n",
      "0.00018626791008574008\n",
      "\n",
      "\n",
      "# 63\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.89931351]\n",
      " [0.87055154]\n",
      " [0.88618446]]\n",
      "Loss: \n",
      "0.00018460812003254898\n",
      "\n",
      "\n",
      "# 64\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.89948669]\n",
      " [0.87073746]\n",
      " [0.88636881]]\n",
      "Loss: \n",
      "0.00018309145757018132\n",
      "\n",
      "\n",
      "# 65\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.899652  ]\n",
      " [0.87091492]\n",
      " [0.88654478]]\n",
      "Loss: \n",
      "0.00018170501096125325\n",
      "\n",
      "\n",
      "# 66\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.89980984]\n",
      " [0.87108435]\n",
      " [0.88671278]]\n",
      "Loss: \n",
      "0.00018043709397997786\n",
      "\n",
      "\n",
      "# 67\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.89996056]\n",
      " [0.87124613]\n",
      " [0.88687321]]\n",
      "Loss: \n",
      "0.0001792771219281177\n",
      "\n",
      "\n",
      "# 68\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90010453]\n",
      " [0.87140066]\n",
      " [0.88702645]]\n",
      "Loss: \n",
      "0.00017821550117044394\n",
      "\n",
      "\n",
      "# 69\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90024208]\n",
      " [0.87154827]\n",
      " [0.88717284]]\n",
      "Loss: \n",
      "0.00017724353058969858\n",
      "\n",
      "\n",
      "# 70\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90037352]\n",
      " [0.8716893 ]\n",
      " [0.88731272]]\n",
      "Loss: \n",
      "0.000176353313567041\n",
      "\n",
      "\n",
      "# 71\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90049914]\n",
      " [0.87182407]\n",
      " [0.8874464 ]]\n",
      "Loss: \n",
      "0.00017553767927097554\n",
      "\n",
      "\n",
      "# 72\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90061922]\n",
      " [0.87195287]\n",
      " [0.88757417]]\n",
      "Loss: \n",
      "0.0001747901121905877\n",
      "\n",
      "\n",
      "# 73\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90073404]\n",
      " [0.872076  ]\n",
      " [0.88769632]]\n",
      "Loss: \n",
      "0.00017410468898077208\n",
      "\n",
      "\n",
      "# 74\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90084382]\n",
      " [0.87219371]\n",
      " [0.88781312]]\n",
      "Loss: \n",
      "0.0001734760218014683\n",
      "\n",
      "\n",
      "# 75\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90094883]\n",
      " [0.87230626]\n",
      " [0.88792481]]\n",
      "Loss: \n",
      "0.00017289920743192733\n",
      "\n",
      "\n",
      "# 76\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90104926]\n",
      " [0.87241388]\n",
      " [0.88803163]]\n",
      "Loss: \n",
      "0.0001723697815271717\n",
      "\n",
      "\n",
      "# 77\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90114535]\n",
      " [0.87251682]\n",
      " [0.88813382]]\n",
      "Loss: \n",
      "0.00017188367745875075\n",
      "\n",
      "\n",
      "# 78\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90123729]\n",
      " [0.87261527]\n",
      " [0.88823157]]\n",
      "Loss: \n",
      "0.0001714371892471876\n",
      "\n",
      "\n",
      "# 79\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90132528]\n",
      " [0.87270945]\n",
      " [0.88832511]]\n",
      "Loss: \n",
      "0.00017102693815068814\n",
      "\n",
      "\n",
      "# 80\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90140948]\n",
      " [0.87279956]\n",
      " [0.88841461]]\n",
      "Loss: \n",
      "0.00017064984252451797\n",
      "\n",
      "\n",
      "# 81\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90149009]\n",
      " [0.87288577]\n",
      " [0.88850026]]\n",
      "Loss: \n",
      "0.0001703030906092801\n",
      "\n",
      "\n",
      "# 82\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90156725]\n",
      " [0.87296827]\n",
      " [0.88858225]]\n",
      "Loss: \n",
      "0.00016998411594466964\n",
      "\n",
      "\n",
      "# 83\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90164112]\n",
      " [0.87304721]\n",
      " [0.88866072]]\n",
      "Loss: \n",
      "0.00016969057513908697\n",
      "\n",
      "\n",
      "# 84\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90171186]\n",
      " [0.87312277]\n",
      " [0.88873585]]\n",
      "Loss: \n",
      "0.00016942032775513696\n",
      "\n",
      "\n",
      "# 85\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90177961]\n",
      " [0.87319508]\n",
      " [0.88880778]]\n",
      "Loss: \n",
      "0.00016917141809728886\n",
      "\n",
      "\n",
      "# 86\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90184449]\n",
      " [0.8732643 ]\n",
      " [0.88887665]]\n",
      "Loss: \n",
      "0.0001689420587110101\n",
      "\n",
      "\n",
      "# 87\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90190663]\n",
      " [0.87333056]\n",
      " [0.8889426 ]]\n",
      "Loss: \n",
      "0.00016873061542318333\n",
      "\n",
      "\n",
      "# 88\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90196616]\n",
      " [0.87339399]\n",
      " [0.88900576]]\n",
      "Loss: \n",
      "0.0001685355937716118\n",
      "\n",
      "\n",
      "# 89\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.9020232 ]\n",
      " [0.87345472]\n",
      " [0.88906624]]\n",
      "Loss: \n",
      "0.0001683556266875391\n",
      "\n",
      "\n",
      "# 90\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90207784]\n",
      " [0.87351286]\n",
      " [0.88912418]]\n",
      "Loss: \n",
      "0.0001681894633091959\n",
      "\n",
      "\n",
      "# 91\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.9021302 ]\n",
      " [0.87356853]\n",
      " [0.88917968]]\n",
      "Loss: \n",
      "0.0001680359588170916\n",
      "\n",
      "\n",
      "# 92\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90218037]\n",
      " [0.87362184]\n",
      " [0.88923284]]\n",
      "Loss: \n",
      "0.00016789406519299272\n",
      "\n",
      "\n",
      "# 93\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90222846]\n",
      " [0.87367288]\n",
      " [0.88928377]]\n",
      "Loss: \n",
      "0.00016776282281443758\n",
      "\n",
      "\n",
      "# 94\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90227454]\n",
      " [0.87372176]\n",
      " [0.88933256]]\n",
      "Loss: \n",
      "0.00016764135280563223\n",
      "\n",
      "\n",
      "# 95\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90231872]\n",
      " [0.87376857]\n",
      " [0.88937932]]\n",
      "Loss: \n",
      "0.00016752885007348232\n",
      "\n",
      "\n",
      "# 96\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90236107]\n",
      " [0.8738134 ]\n",
      " [0.88942411]]\n",
      "Loss: \n",
      "0.00016742457696457326\n",
      "\n",
      "\n",
      "# 97\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90240166]\n",
      " [0.87385633]\n",
      " [0.88946704]]\n",
      "Loss: \n",
      "0.00016732785748533544\n",
      "\n",
      "\n",
      "# 98\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90244058]\n",
      " [0.87389745]\n",
      " [0.88950818]]\n",
      "Loss: \n",
      "0.00016723807203320283\n",
      "\n",
      "\n",
      "# 99\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.9024779 ]\n",
      " [0.87393683]\n",
      " [0.8895476 ]]\n",
      "Loss: \n",
      "0.0001671546525917428\n",
      "\n",
      "\n",
      "# 100\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90251368]\n",
      " [0.87397455]\n",
      " [0.88958538]]\n",
      "Loss: \n",
      "0.00016707707834725735\n",
      "\n",
      "\n",
      "# 101\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.902548  ]\n",
      " [0.87401067]\n",
      " [0.8896216 ]]\n",
      "Loss: \n",
      "0.0001670048716884263\n",
      "\n",
      "\n",
      "# 102\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.9025809 ]\n",
      " [0.87404528]\n",
      " [0.88965631]]\n",
      "Loss: \n",
      "0.00016693759455427564\n",
      "\n",
      "\n",
      "# 103\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90261247]\n",
      " [0.87407842]\n",
      " [0.88968958]]\n",
      "Loss: \n",
      "0.0001668748450990273\n",
      "\n",
      "\n",
      "# 104\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90264274]\n",
      " [0.87411016]\n",
      " [0.88972147]]\n",
      "Loss: \n",
      "0.00016681625464534767\n",
      "\n",
      "\n",
      "# 105\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90267178]\n",
      " [0.87414057]\n",
      " [0.88975204]]\n",
      "Loss: \n",
      "0.00016676148490022284\n",
      "\n",
      "\n",
      "# 106\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90269963]\n",
      " [0.87416969]\n",
      " [0.88978135]]\n",
      "Loss: \n",
      "0.00016671022541007467\n",
      "\n",
      "\n",
      "# 107\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90272635]\n",
      " [0.87419758]\n",
      " [0.88980945]]\n",
      "Loss: \n",
      "0.000166662191233864\n",
      "\n",
      "\n",
      "# 108\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90275199]\n",
      " [0.8742243 ]\n",
      " [0.88983639]]\n",
      "Loss: \n",
      "0.00016661712081497945\n",
      "\n",
      "\n",
      "# 109\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90277659]\n",
      " [0.87424989]\n",
      " [0.88986221]]\n",
      "Loss: \n",
      "0.0001665747740343958\n",
      "\n",
      "\n",
      "# 110\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90280019]\n",
      " [0.8742744 ]\n",
      " [0.88988698]]\n",
      "Loss: \n",
      "0.00016653493042921423\n",
      "\n",
      "\n",
      "# 111\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90282284]\n",
      " [0.87429788]\n",
      " [0.88991072]]\n",
      "Loss: \n",
      "0.00016649738756213637\n",
      "\n",
      "\n",
      "# 112\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90284458]\n",
      " [0.87432037]\n",
      " [0.88993348]]\n",
      "Loss: \n",
      "0.000166461959528784\n",
      "\n",
      "\n",
      "# 113\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90286544]\n",
      " [0.8743419 ]\n",
      " [0.88995531]]\n",
      "Loss: \n",
      "0.00016642847559082574\n",
      "\n",
      "\n",
      "# 114\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90288546]\n",
      " [0.87436253]\n",
      " [0.88997624]]\n",
      "Loss: \n",
      "0.00016639677892413867\n",
      "\n",
      "\n",
      "# 115\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90290467]\n",
      " [0.87438228]\n",
      " [0.88999632]]\n",
      "Loss: \n",
      "0.00016636672547200044\n",
      "\n",
      "\n",
      "# 116\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90292312]\n",
      " [0.8744012 ]\n",
      " [0.89001557]]\n",
      "Loss: \n",
      "0.00016633818289435052\n",
      "\n",
      "\n",
      "# 117\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90294083]\n",
      " [0.87441932]\n",
      " [0.89003402]]\n",
      "Loss: \n",
      "0.00016631102960486773\n",
      "\n",
      "\n",
      "# 118\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90295783]\n",
      " [0.87443666]\n",
      " [0.89005173]]\n",
      "Loss: \n",
      "0.0001662851538883741\n",
      "\n",
      "\n",
      "# 119\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90297415]\n",
      " [0.87445328]\n",
      " [0.8900687 ]]\n",
      "Loss: \n",
      "0.00016626045309171201\n",
      "\n",
      "\n",
      "# 120\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90298983]\n",
      " [0.87446919]\n",
      " [0.89008499]]\n",
      "Loss: \n",
      "0.00016623683288187203\n",
      "\n",
      "\n",
      "# 121\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90300488]\n",
      " [0.87448442]\n",
      " [0.8901006 ]]\n",
      "Loss: \n",
      "0.00016621420656565505\n",
      "\n",
      "\n",
      "# 122\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90301933]\n",
      " [0.874499  ]\n",
      " [0.89011558]]\n",
      "Loss: \n",
      "0.0001661924944656745\n",
      "\n",
      "\n",
      "# 123\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90303321]\n",
      " [0.87451296]\n",
      " [0.89012995]]\n",
      "Loss: \n",
      "0.00016617162334796627\n",
      "\n",
      "\n",
      "# 124\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90304654]\n",
      " [0.87452633]\n",
      " [0.89014372]]\n",
      "Loss: \n",
      "0.00016615152589683619\n",
      "\n",
      "\n",
      "# 125\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90305935]\n",
      " [0.87453912]\n",
      " [0.89015694]]\n",
      "Loss: \n",
      "0.00016613214023298854\n",
      "\n",
      "\n",
      "# 126\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90307165]\n",
      " [0.87455137]\n",
      " [0.89016962]]\n",
      "Loss: \n",
      "0.0001661134094713374\n",
      "\n",
      "\n",
      "# 127\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90308347]\n",
      " [0.8745631 ]\n",
      " [0.89018177]]\n",
      "Loss: \n",
      "0.00016609528131514447\n",
      "\n",
      "\n",
      "# 128\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90309482]\n",
      " [0.87457432]\n",
      " [0.89019344]]\n",
      "Loss: \n",
      "0.00016607770768346935\n",
      "\n",
      "\n",
      "# 129\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90310573]\n",
      " [0.87458505]\n",
      " [0.89020462]]\n",
      "Loss: \n",
      "0.00016606064436917517\n",
      "\n",
      "\n",
      "# 130\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90311622]\n",
      " [0.87459533]\n",
      " [0.89021536]]\n",
      "Loss: \n",
      "0.00016604405072492064\n",
      "\n",
      "\n",
      "# 131\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90312629]\n",
      " [0.87460516]\n",
      " [0.89022565]]\n",
      "Loss: \n",
      "0.00016602788937483692\n",
      "\n",
      "\n",
      "# 132\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90313597]\n",
      " [0.87461457]\n",
      " [0.89023553]]\n",
      "Loss: \n",
      "0.00016601212594975775\n",
      "\n",
      "\n",
      "# 133\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90314528]\n",
      " [0.87462357]\n",
      " [0.890245  ]]\n",
      "Loss: \n",
      "0.0001659967288440547\n",
      "\n",
      "\n",
      "# 134\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90315423]\n",
      " [0.87463217]\n",
      " [0.89025409]]\n",
      "Loss: \n",
      "0.00016598166899228195\n",
      "\n",
      "\n",
      "# 135\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90316283]\n",
      " [0.8746404 ]\n",
      " [0.89026281]]\n",
      "Loss: \n",
      "0.0001659669196640213\n",
      "\n",
      "\n",
      "# 136\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.9031711 ]\n",
      " [0.87464828]\n",
      " [0.89027117]]\n",
      "Loss: \n",
      "0.00016595245627540808\n",
      "\n",
      "\n",
      "# 137\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90317905]\n",
      " [0.8746558 ]\n",
      " [0.8902792 ]]\n",
      "Loss: \n",
      "0.00016593825621598977\n",
      "\n",
      "\n",
      "# 138\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.9031867]\n",
      " [0.874663 ]\n",
      " [0.8902869]]\n",
      "Loss: \n",
      "0.00016592429868961253\n",
      "\n",
      "\n",
      "# 139\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90319406]\n",
      " [0.87466988]\n",
      " [0.89029428]]\n",
      "Loss: \n",
      "0.00016591056456824699\n",
      "\n",
      "\n",
      "# 140\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90320113]\n",
      " [0.87467646]\n",
      " [0.89030137]]\n",
      "Loss: \n",
      "0.00016589703625766161\n",
      "\n",
      "\n",
      "# 141\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90320794]\n",
      " [0.87468274]\n",
      " [0.89030817]]\n",
      "Loss: \n",
      "0.00016588369757395113\n",
      "\n",
      "\n",
      "# 142\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90321449]\n",
      " [0.87468875]\n",
      " [0.89031469]]\n",
      "Loss: \n",
      "0.00016587053363008555\n",
      "\n",
      "\n",
      "# 143\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90322079]\n",
      " [0.87469448]\n",
      " [0.89032095]]\n",
      "Loss: \n",
      "0.00016585753073162805\n",
      "\n",
      "\n",
      "# 144\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90322686]\n",
      " [0.87469996]\n",
      " [0.89032696]]\n",
      "Loss: \n",
      "0.00016584467628087565\n",
      "\n",
      "\n",
      "# 145\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.9032327 ]\n",
      " [0.87470519]\n",
      " [0.89033272]]\n",
      "Loss: \n",
      "0.0001658319586887397\n",
      "\n",
      "\n",
      "# 146\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90323831]\n",
      " [0.87471019]\n",
      " [0.89033825]]\n",
      "Loss: \n",
      "0.0001658193672937516\n",
      "\n",
      "\n",
      "# 147\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90324373]\n",
      " [0.87471495]\n",
      " [0.89034355]]\n",
      "Loss: \n",
      "0.00016580689228760543\n",
      "\n",
      "\n",
      "# 148\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90324893]\n",
      " [0.87471951]\n",
      " [0.89034864]]\n",
      "Loss: \n",
      "0.0001657945246466704\n",
      "\n",
      "\n",
      "# 149\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90325395]\n",
      " [0.87472385]\n",
      " [0.89035353]]\n",
      "Loss: \n",
      "0.00016578225606906936\n",
      "\n",
      "\n",
      "# 150\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90325878]\n",
      " [0.87472799]\n",
      " [0.89035822]]\n",
      "Loss: \n",
      "0.000165770078916793\n",
      "\n",
      "\n",
      "# 151\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90326344]\n",
      " [0.87473194]\n",
      " [0.89036271]]\n",
      "Loss: \n",
      "0.00016575798616247304\n",
      "\n",
      "\n",
      "# 152\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90326793]\n",
      " [0.8747357 ]\n",
      " [0.89036703]]\n",
      "Loss: \n",
      "0.00016574597134046124\n",
      "\n",
      "\n",
      "# 153\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90327225]\n",
      " [0.87473929]\n",
      " [0.89037117]]\n",
      "Loss: \n",
      "0.00016573402850181965\n",
      "\n",
      "\n",
      "# 154\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90327642]\n",
      " [0.87474271]\n",
      " [0.89037515]]\n",
      "Loss: \n",
      "0.00016572215217292862\n",
      "\n",
      "\n",
      "# 155\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90328043]\n",
      " [0.87474596]\n",
      " [0.89037896]]\n",
      "Loss: \n",
      "0.00016571033731744702\n",
      "\n",
      "\n",
      "# 156\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90328431]\n",
      " [0.87474906]\n",
      " [0.89038262]]\n",
      "Loss: \n",
      "0.00016569857930128713\n",
      "\n",
      "\n",
      "# 157\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90328804]\n",
      " [0.87475201]\n",
      " [0.89038614]]\n",
      "Loss: \n",
      "0.0001656868738604408\n",
      "\n",
      "\n",
      "# 158\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90329164]\n",
      " [0.87475482]\n",
      " [0.89038951]]\n",
      "Loss: \n",
      "0.0001656752170713581\n",
      "\n",
      "\n",
      "# 159\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90329512]\n",
      " [0.87475749]\n",
      " [0.89039274]]\n",
      "Loss: \n",
      "0.00016566360532371807\n",
      "\n",
      "\n",
      "# 160\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90329847]\n",
      " [0.87476003]\n",
      " [0.89039585]]\n",
      "Loss: \n",
      "0.00016565203529537913\n",
      "\n",
      "\n",
      "# 161\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90330171]\n",
      " [0.87476244]\n",
      " [0.89039883]]\n",
      "Loss: \n",
      "0.00016564050392933098\n",
      "\n",
      "\n",
      "# 162\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90330484]\n",
      " [0.87476473]\n",
      " [0.89040169]]\n",
      "Loss: \n",
      "0.00016562900841250727\n",
      "\n",
      "\n",
      "# 163\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90330785]\n",
      " [0.8747669 ]\n",
      " [0.89040444]]\n",
      "Loss: \n",
      "0.00016561754615627543\n",
      "\n",
      "\n",
      "# 164\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90331077]\n",
      " [0.87476896]\n",
      " [0.89040708]]\n",
      "Loss: \n",
      "0.00016560611477852563\n",
      "\n",
      "\n",
      "# 165\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90331358]\n",
      " [0.87477091]\n",
      " [0.89040961]]\n",
      "Loss: \n",
      "0.0001655947120871378\n",
      "\n",
      "\n",
      "# 166\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.9033163 ]\n",
      " [0.87477276]\n",
      " [0.89041204]]\n",
      "Loss: \n",
      "0.00016558333606482678\n",
      "\n",
      "\n",
      "# 167\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90331893]\n",
      " [0.87477452]\n",
      " [0.89041437]]\n",
      "Loss: \n",
      "0.0001655719848551704\n",
      "\n",
      "\n",
      "# 168\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90332148]\n",
      " [0.87477617]\n",
      " [0.89041661]]\n",
      "Loss: \n",
      "0.00016556065674976222\n",
      "\n",
      "\n",
      "# 169\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90332394]\n",
      " [0.87477774]\n",
      " [0.89041876]]\n",
      "Loss: \n",
      "0.00016554935017638555\n",
      "\n",
      "\n",
      "# 170\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90332631]\n",
      " [0.87477922]\n",
      " [0.89042082]]\n",
      "Loss: \n",
      "0.00016553806368815546\n",
      "\n",
      "\n",
      "# 171\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90332862]\n",
      " [0.87478061]\n",
      " [0.8904228 ]]\n",
      "Loss: \n",
      "0.00016552679595349773\n",
      "\n",
      "\n",
      "# 172\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90333084]\n",
      " [0.87478193]\n",
      " [0.8904247 ]]\n",
      "Loss: \n",
      "0.0001655155457469528\n",
      "\n",
      "\n",
      "# 173\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.903333  ]\n",
      " [0.87478317]\n",
      " [0.89042653]]\n",
      "Loss: \n",
      "0.00016550431194070105\n",
      "\n",
      "\n",
      "# 174\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90333509]\n",
      " [0.87478433]\n",
      " [0.89042828]]\n",
      "Loss: \n",
      "0.000165493093496776\n",
      "\n",
      "\n",
      "# 175\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90333711]\n",
      " [0.87478543]\n",
      " [0.89042996]]\n",
      "Loss: \n",
      "0.00016548188945989133\n",
      "\n",
      "\n",
      "# 176\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90333907]\n",
      " [0.87478646]\n",
      " [0.89043158]]\n",
      "Loss: \n",
      "0.000165470698950836\n",
      "\n",
      "\n",
      "# 177\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90334097]\n",
      " [0.87478742]\n",
      " [0.89043313]]\n",
      "Loss: \n",
      "0.00016545952116042738\n",
      "\n",
      "\n",
      "# 178\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90334281]\n",
      " [0.87478832]\n",
      " [0.89043462]]\n",
      "Loss: \n",
      "0.00016544835534389166\n",
      "\n",
      "\n",
      "# 179\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.9033446 ]\n",
      " [0.87478916]\n",
      " [0.89043605]]\n",
      "Loss: \n",
      "0.0001654372008157568\n",
      "\n",
      "\n",
      "# 180\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90334633]\n",
      " [0.87478994]\n",
      " [0.89043743]]\n",
      "Loss: \n",
      "0.00016542605694509825\n",
      "\n",
      "\n",
      "# 181\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90334802]\n",
      " [0.87479066]\n",
      " [0.89043875]]\n",
      "Loss: \n",
      "0.00016541492315120488\n",
      "\n",
      "\n",
      "# 182\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90334965]\n",
      " [0.87479134]\n",
      " [0.89044002]]\n",
      "Loss: \n",
      "0.00016540379889956472\n",
      "\n",
      "\n",
      "# 183\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90335124]\n",
      " [0.87479196]\n",
      " [0.89044124]]\n",
      "Loss: \n",
      "0.00016539268369818454\n",
      "\n",
      "\n",
      "# 184\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90335278]\n",
      " [0.87479254]\n",
      " [0.89044241]]\n",
      "Loss: \n",
      "0.00016538157709419376\n",
      "\n",
      "\n",
      "# 185\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90335428]\n",
      " [0.87479306]\n",
      " [0.89044353]]\n",
      "Loss: \n",
      "0.00016537047867073496\n",
      "\n",
      "\n",
      "# 186\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90335574]\n",
      " [0.87479355]\n",
      " [0.89044461]]\n",
      "Loss: \n",
      "0.00016535938804407714\n",
      "\n",
      "\n",
      "# 187\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90335716]\n",
      " [0.87479399]\n",
      " [0.89044565]]\n",
      "Loss: \n",
      "0.00016534830486098913\n",
      "\n",
      "\n",
      "# 188\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90335854]\n",
      " [0.87479439]\n",
      " [0.89044664]]\n",
      "Loss: \n",
      "0.0001653372287962948\n",
      "\n",
      "\n",
      "# 189\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90335988]\n",
      " [0.87479475]\n",
      " [0.8904476 ]]\n",
      "Loss: \n",
      "0.00016532615955064695\n",
      "\n",
      "\n",
      "# 190\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90336119]\n",
      " [0.87479507]\n",
      " [0.89044852]]\n",
      "Loss: \n",
      "0.00016531509684846607\n",
      "\n",
      "\n",
      "# 191\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90336246]\n",
      " [0.87479536]\n",
      " [0.89044941]]\n",
      "Loss: \n",
      "0.00016530404043603423\n",
      "\n",
      "\n",
      "# 192\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90336371]\n",
      " [0.87479561]\n",
      " [0.89045025]]\n",
      "Loss: \n",
      "0.0001652929900797604\n",
      "\n",
      "\n",
      "# 193\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90336492]\n",
      " [0.87479582]\n",
      " [0.89045107]]\n",
      "Loss: \n",
      "0.00016528194556458562\n",
      "\n",
      "\n",
      "# 194\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.9033661 ]\n",
      " [0.87479601]\n",
      " [0.89045186]]\n",
      "Loss: \n",
      "0.00016527090669248283\n",
      "\n",
      "\n",
      "# 195\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90336725]\n",
      " [0.87479616]\n",
      " [0.89045261]]\n",
      "Loss: \n",
      "0.0001652598732811149\n",
      "\n",
      "\n",
      "# 196\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90336838]\n",
      " [0.87479629]\n",
      " [0.89045334]]\n",
      "Loss: \n",
      "0.00016524884516258922\n",
      "\n",
      "\n",
      "# 197\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90336948]\n",
      " [0.87479639]\n",
      " [0.89045403]]\n",
      "Loss: \n",
      "0.0001652378221822826\n",
      "\n",
      "\n",
      "# 198\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90337055]\n",
      " [0.87479646]\n",
      " [0.8904547 ]]\n",
      "Loss: \n",
      "0.00016522680419780753\n",
      "\n",
      "\n",
      "# 199\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.9033716 ]\n",
      " [0.8747965 ]\n",
      " [0.89045535]]\n",
      "Loss: \n",
      "0.00016521579107802128\n",
      "\n",
      "\n",
      "# 200\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90337263]\n",
      " [0.87479652]\n",
      " [0.89045597]]\n",
      "Loss: \n",
      "0.0001652047827021417\n",
      "\n",
      "\n",
      "# 201\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90337363]\n",
      " [0.87479651]\n",
      " [0.89045656]]\n",
      "Loss: \n",
      "0.00016519377895890292\n",
      "\n",
      "\n",
      "# 202\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90337462]\n",
      " [0.87479649]\n",
      " [0.89045714]]\n",
      "Loss: \n",
      "0.0001651827797458223\n",
      "\n",
      "\n",
      "# 203\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90337558]\n",
      " [0.87479643]\n",
      " [0.89045769]]\n",
      "Loss: \n",
      "0.00016517178496847087\n",
      "\n",
      "\n",
      "# 204\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90337652]\n",
      " [0.87479636]\n",
      " [0.89045822]]\n",
      "Loss: \n",
      "0.00016516079453985787\n",
      "\n",
      "\n",
      "# 205\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90337745]\n",
      " [0.87479627]\n",
      " [0.89045873]]\n",
      "Loss: \n",
      "0.00016514980837982194\n",
      "\n",
      "\n",
      "# 206\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90337835]\n",
      " [0.87479616]\n",
      " [0.89045922]]\n",
      "Loss: \n",
      "0.00016513882641448456\n",
      "\n",
      "\n",
      "# 207\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90337924]\n",
      " [0.87479603]\n",
      " [0.8904597 ]]\n",
      "Loss: \n",
      "0.00016512784857576355\n",
      "\n",
      "\n",
      "# 208\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90338011]\n",
      " [0.87479588]\n",
      " [0.89046015]]\n",
      "Loss: \n",
      "0.00016511687480089818\n",
      "\n",
      "\n",
      "# 209\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90338097]\n",
      " [0.87479572]\n",
      " [0.89046059]]\n",
      "Loss: \n",
      "0.00016510590503202873\n",
      "\n",
      "\n",
      "# 210\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90338181]\n",
      " [0.87479554]\n",
      " [0.89046101]]\n",
      "Loss: \n",
      "0.00016509493921580527\n",
      "\n",
      "\n",
      "# 211\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90338263]\n",
      " [0.87479534]\n",
      " [0.89046142]]\n",
      "Loss: \n",
      "0.00016508397730302998\n",
      "\n",
      "\n",
      "# 212\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90338345]\n",
      " [0.87479513]\n",
      " [0.89046181]]\n",
      "Loss: \n",
      "0.0001650730192483183\n",
      "\n",
      "\n",
      "# 213\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90338424]\n",
      " [0.8747949 ]\n",
      " [0.89046218]]\n",
      "Loss: \n",
      "0.00016506206500981662\n",
      "\n",
      "\n",
      "# 214\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90338503]\n",
      " [0.87479466]\n",
      " [0.89046255]]\n",
      "Loss: \n",
      "0.00016505111454888464\n",
      "\n",
      "\n",
      "# 215\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.9033858 ]\n",
      " [0.87479441]\n",
      " [0.89046289]]\n",
      "Loss: \n",
      "0.00016504016782986977\n",
      "\n",
      "\n",
      "# 216\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90338656]\n",
      " [0.87479415]\n",
      " [0.89046323]]\n",
      "Loss: \n",
      "0.00016502922481986124\n",
      "\n",
      "\n",
      "# 217\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90338731]\n",
      " [0.87479387]\n",
      " [0.89046356]]\n",
      "Loss: \n",
      "0.00016501828548846228\n",
      "\n",
      "\n",
      "# 218\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90338805]\n",
      " [0.87479358]\n",
      " [0.89046387]]\n",
      "Loss: \n",
      "0.00016500734980759793\n",
      "\n",
      "\n",
      "# 219\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90338877]\n",
      " [0.87479328]\n",
      " [0.89046417]]\n",
      "Loss: \n",
      "0.00016499641775132454\n",
      "\n",
      "\n",
      "# 220\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90338949]\n",
      " [0.87479296]\n",
      " [0.89046446]]\n",
      "Loss: \n",
      "0.00016498548929566774\n",
      "\n",
      "\n",
      "# 221\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.9033902 ]\n",
      " [0.87479264]\n",
      " [0.89046474]]\n",
      "Loss: \n",
      "0.00016497456441845977\n",
      "\n",
      "\n",
      "# 222\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.9033909 ]\n",
      " [0.87479231]\n",
      " [0.89046501]]\n",
      "Loss: \n",
      "0.00016496364309918725\n",
      "\n",
      "\n",
      "# 223\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90339159]\n",
      " [0.87479197]\n",
      " [0.89046527]]\n",
      "Loss: \n",
      "0.00016495272531888154\n",
      "\n",
      "\n",
      "# 224\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90339227]\n",
      " [0.87479162]\n",
      " [0.89046552]]\n",
      "Loss: \n",
      "0.00016494181105996937\n",
      "\n",
      "\n",
      "# 225\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90339294]\n",
      " [0.87479126]\n",
      " [0.89046577]]\n",
      "Loss: \n",
      "0.00016493090030618017\n",
      "\n",
      "\n",
      "# 226\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.9033936 ]\n",
      " [0.87479089]\n",
      " [0.890466  ]]\n",
      "Loss: \n",
      "0.00016491999304243512\n",
      "\n",
      "\n",
      "# 227\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90339426]\n",
      " [0.87479051]\n",
      " [0.89046623]]\n",
      "Loss: \n",
      "0.00016490908925474493\n",
      "\n",
      "\n",
      "# 228\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90339491]\n",
      " [0.87479013]\n",
      " [0.89046645]]\n",
      "Loss: \n",
      "0.0001648981889301442\n",
      "\n",
      "\n",
      "# 229\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90339555]\n",
      " [0.87478974]\n",
      " [0.89046666]]\n",
      "Loss: \n",
      "0.00016488729205658403\n",
      "\n",
      "\n",
      "# 230\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90339618]\n",
      " [0.87478934]\n",
      " [0.89046686]]\n",
      "Loss: \n",
      "0.00016487639862287256\n",
      "\n",
      "\n",
      "# 231\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90339681]\n",
      " [0.87478893]\n",
      " [0.89046706]]\n",
      "Loss: \n",
      "0.00016486550861861003\n",
      "\n",
      "\n",
      "# 232\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90339743]\n",
      " [0.87478852]\n",
      " [0.89046725]]\n",
      "Loss: \n",
      "0.00016485462203411397\n",
      "\n",
      "\n",
      "# 233\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90339805]\n",
      " [0.8747881 ]\n",
      " [0.89046743]]\n",
      "Loss: \n",
      "0.0001648437388603729\n",
      "\n",
      "\n",
      "# 234\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90339866]\n",
      " [0.87478768]\n",
      " [0.89046761]]\n",
      "Loss: \n",
      "0.0001648328590889863\n",
      "\n",
      "\n",
      "# 235\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90339927]\n",
      " [0.87478725]\n",
      " [0.89046778]]\n",
      "Loss: \n",
      "0.00016482198271211231\n",
      "\n",
      "\n",
      "# 236\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90339987]\n",
      " [0.87478681]\n",
      " [0.89046795]]\n",
      "Loss: \n",
      "0.00016481110972243397\n",
      "\n",
      "\n",
      "# 237\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90340046]\n",
      " [0.87478637]\n",
      " [0.89046811]]\n",
      "Loss: \n",
      "0.00016480024011311057\n",
      "\n",
      "\n",
      "# 238\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90340105]\n",
      " [0.87478593]\n",
      " [0.89046827]]\n",
      "Loss: \n",
      "0.0001647893738777422\n",
      "\n",
      "\n",
      "# 239\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90340164]\n",
      " [0.87478548]\n",
      " [0.89046842]]\n",
      "Loss: \n",
      "0.0001647785110103231\n",
      "\n",
      "\n",
      "# 240\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90340222]\n",
      " [0.87478502]\n",
      " [0.89046857]]\n",
      "Loss: \n",
      "0.00016476765150523533\n",
      "\n",
      "\n",
      "# 241\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90340279]\n",
      " [0.87478457]\n",
      " [0.89046871]]\n",
      "Loss: \n",
      "0.00016475679535718813\n",
      "\n",
      "\n",
      "# 242\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90340336]\n",
      " [0.8747841 ]\n",
      " [0.89046885]]\n",
      "Loss: \n",
      "0.00016474594256121324\n",
      "\n",
      "\n",
      "# 243\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90340393]\n",
      " [0.87478363]\n",
      " [0.89046898]]\n",
      "Loss: \n",
      "0.00016473509311263113\n",
      "\n",
      "\n",
      "# 244\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.9034045 ]\n",
      " [0.87478316]\n",
      " [0.89046911]]\n",
      "Loss: \n",
      "0.00016472424700702485\n",
      "\n",
      "\n",
      "# 245\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90340506]\n",
      " [0.87478269]\n",
      " [0.89046924]]\n",
      "Loss: \n",
      "0.0001647134042402287\n",
      "\n",
      "\n",
      "# 246\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90340561]\n",
      " [0.87478221]\n",
      " [0.89046936]]\n",
      "Loss: \n",
      "0.000164702564808298\n",
      "\n",
      "\n",
      "# 247\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90340617]\n",
      " [0.87478173]\n",
      " [0.89046948]]\n",
      "Loss: \n",
      "0.0001646917287074966\n",
      "\n",
      "\n",
      "# 248\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90340672]\n",
      " [0.87478124]\n",
      " [0.89046959]]\n",
      "Loss: \n",
      "0.00016468089593427865\n",
      "\n",
      "\n",
      "# 249\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90340726]\n",
      " [0.87478075]\n",
      " [0.89046971]]\n",
      "Loss: \n",
      "0.00016467006648527424\n",
      "\n",
      "\n",
      "# 250\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90340781]\n",
      " [0.87478026]\n",
      " [0.89046982]]\n",
      "Loss: \n",
      "0.00016465924035727753\n",
      "\n",
      "\n",
      "# 251\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90340835]\n",
      " [0.87477977]\n",
      " [0.89046992]]\n",
      "Loss: \n",
      "0.00016464841754722738\n",
      "\n",
      "\n",
      "# 252\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90340889]\n",
      " [0.87477927]\n",
      " [0.89047002]]\n",
      "Loss: \n",
      "0.00016463759805220282\n",
      "\n",
      "\n",
      "# 253\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90340942]\n",
      " [0.87477877]\n",
      " [0.89047012]]\n",
      "Loss: \n",
      "0.00016462678186940618\n",
      "\n",
      "\n",
      "# 254\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90340996]\n",
      " [0.87477827]\n",
      " [0.89047022]]\n",
      "Loss: \n",
      "0.00016461596899615814\n",
      "\n",
      "\n",
      "# 255\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90341049]\n",
      " [0.87477777]\n",
      " [0.89047032]]\n",
      "Loss: \n",
      "0.0001646051594298817\n",
      "\n",
      "\n",
      "# 256\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90341102]\n",
      " [0.87477726]\n",
      " [0.89047041]]\n",
      "Loss: \n",
      "0.0001645943531681009\n",
      "\n",
      "\n",
      "# 257\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90341154]\n",
      " [0.87477675]\n",
      " [0.8904705 ]]\n",
      "Loss: \n",
      "0.00016458355020843238\n",
      "\n",
      "\n",
      "# 258\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90341207]\n",
      " [0.87477624]\n",
      " [0.89047059]]\n",
      "Loss: \n",
      "0.00016457275054856935\n",
      "\n",
      "\n",
      "# 259\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90341259]\n",
      " [0.87477573]\n",
      " [0.89047068]]\n",
      "Loss: \n",
      "0.00016456195418628614\n",
      "\n",
      "\n",
      "# 260\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90341311]\n",
      " [0.87477521]\n",
      " [0.89047076]]\n",
      "Loss: \n",
      "0.00016455116111942732\n",
      "\n",
      "\n",
      "# 261\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90341362]\n",
      " [0.87477469]\n",
      " [0.89047084]]\n",
      "Loss: \n",
      "0.00016454037134589915\n",
      "\n",
      "\n",
      "# 262\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90341414]\n",
      " [0.87477417]\n",
      " [0.89047092]]\n",
      "Loss: \n",
      "0.00016452958486367112\n",
      "\n",
      "\n",
      "# 263\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90341465]\n",
      " [0.87477365]\n",
      " [0.890471  ]]\n",
      "Loss: \n",
      "0.00016451880167076317\n",
      "\n",
      "\n",
      "# 264\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90341517]\n",
      " [0.87477313]\n",
      " [0.89047108]]\n",
      "Loss: \n",
      "0.0001645080217652518\n",
      "\n",
      "\n",
      "# 265\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90341568]\n",
      " [0.87477261]\n",
      " [0.89047115]]\n",
      "Loss: \n",
      "0.00016449724514525232\n",
      "\n",
      "\n",
      "# 266\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90341619]\n",
      " [0.87477208]\n",
      " [0.89047122]]\n",
      "Loss: \n",
      "0.00016448647180892744\n",
      "\n",
      "\n",
      "# 267\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90341669]\n",
      " [0.87477156]\n",
      " [0.8904713 ]]\n",
      "Loss: \n",
      "0.00016447570175447804\n",
      "\n",
      "\n",
      "# 268\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.9034172 ]\n",
      " [0.87477103]\n",
      " [0.89047137]]\n",
      "Loss: \n",
      "0.00016446493498014294\n",
      "\n",
      "\n",
      "# 269\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.9034177 ]\n",
      " [0.8747705 ]\n",
      " [0.89047144]]\n",
      "Loss: \n",
      "0.00016445417148419042\n",
      "\n",
      "\n",
      "# 270\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90341821]\n",
      " [0.87476997]\n",
      " [0.8904715 ]]\n",
      "Loss: \n",
      "0.00016444341126492173\n",
      "\n",
      "\n",
      "# 271\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90341871]\n",
      " [0.87476944]\n",
      " [0.89047157]]\n",
      "Loss: \n",
      "0.00016443265432066696\n",
      "\n",
      "\n",
      "# 272\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90341921]\n",
      " [0.87476891]\n",
      " [0.89047163]]\n",
      "Loss: \n",
      "0.0001644219006497796\n",
      "\n",
      "\n",
      "# 273\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90341971]\n",
      " [0.87476837]\n",
      " [0.8904717 ]]\n",
      "Loss: \n",
      "0.00016441115025064197\n",
      "\n",
      "\n",
      "# 274\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90342021]\n",
      " [0.87476784]\n",
      " [0.89047176]]\n",
      "Loss: \n",
      "0.000164400403121652\n",
      "\n",
      "\n",
      "# 275\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.9034207 ]\n",
      " [0.8747673 ]\n",
      " [0.89047182]]\n",
      "Loss: \n",
      "0.0001643896592612336\n",
      "\n",
      "\n",
      "# 276\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.9034212 ]\n",
      " [0.87476677]\n",
      " [0.89047188]]\n",
      "Loss: \n",
      "0.00016437891866782442\n",
      "\n",
      "\n",
      "# 277\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90342169]\n",
      " [0.87476623]\n",
      " [0.89047194]]\n",
      "Loss: \n",
      "0.00016436818133988378\n",
      "\n",
      "\n",
      "# 278\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90342219]\n",
      " [0.87476569]\n",
      " [0.890472  ]]\n",
      "Loss: \n",
      "0.0001643574472758851\n",
      "\n",
      "\n",
      "# 279\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90342268]\n",
      " [0.87476515]\n",
      " [0.89047206]]\n",
      "Loss: \n",
      "0.00016434671647431095\n",
      "\n",
      "\n",
      "# 280\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90342317]\n",
      " [0.87476461]\n",
      " [0.89047211]]\n",
      "Loss: \n",
      "0.00016433598893367244\n",
      "\n",
      "\n",
      "# 281\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90342366]\n",
      " [0.87476407]\n",
      " [0.89047217]]\n",
      "Loss: \n",
      "0.00016432526465247677\n",
      "\n",
      "\n",
      "# 282\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90342415]\n",
      " [0.87476353]\n",
      " [0.89047222]]\n",
      "Loss: \n",
      "0.0001643145436292509\n",
      "\n",
      "\n",
      "# 283\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90342464]\n",
      " [0.87476299]\n",
      " [0.89047228]]\n",
      "Loss: \n",
      "0.00016430382586252905\n",
      "\n",
      "\n",
      "# 284\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90342513]\n",
      " [0.87476245]\n",
      " [0.89047233]]\n",
      "Loss: \n",
      "0.00016429311135086\n",
      "\n",
      "\n",
      "# 285\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90342562]\n",
      " [0.87476191]\n",
      " [0.89047238]]\n",
      "Loss: \n",
      "0.00016428240009279537\n",
      "\n",
      "\n",
      "# 286\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.9034261 ]\n",
      " [0.87476136]\n",
      " [0.89047243]]\n",
      "Loss: \n",
      "0.00016427169208690093\n",
      "\n",
      "\n",
      "# 287\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90342659]\n",
      " [0.87476082]\n",
      " [0.89047249]]\n",
      "Loss: \n",
      "0.00016426098733174688\n",
      "\n",
      "\n",
      "# 288\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90342708]\n",
      " [0.87476028]\n",
      " [0.89047254]]\n",
      "Loss: \n",
      "0.00016425028582591131\n",
      "\n",
      "\n",
      "# 289\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90342756]\n",
      " [0.87475973]\n",
      " [0.89047259]]\n",
      "Loss: \n",
      "0.00016423958756797677\n",
      "\n",
      "\n",
      "# 290\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90342804]\n",
      " [0.87475919]\n",
      " [0.89047264]]\n",
      "Loss: \n",
      "0.00016422889255653496\n",
      "\n",
      "\n",
      "# 291\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90342853]\n",
      " [0.87475864]\n",
      " [0.89047268]]\n",
      "Loss: \n",
      "0.00016421820079018447\n",
      "\n",
      "\n",
      "# 292\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90342901]\n",
      " [0.87475809]\n",
      " [0.89047273]]\n",
      "Loss: \n",
      "0.00016420751226752393\n",
      "\n",
      "\n",
      "# 293\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90342949]\n",
      " [0.87475755]\n",
      " [0.89047278]]\n",
      "Loss: \n",
      "0.00016419682698716072\n",
      "\n",
      "\n",
      "# 294\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90342997]\n",
      " [0.874757  ]\n",
      " [0.89047283]]\n",
      "Loss: \n",
      "0.0001641861449477042\n",
      "\n",
      "\n",
      "# 295\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90343045]\n",
      " [0.87475645]\n",
      " [0.89047287]]\n",
      "Loss: \n",
      "0.00016417546614777505\n",
      "\n",
      "\n",
      "# 296\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90343093]\n",
      " [0.87475591]\n",
      " [0.89047292]]\n",
      "Loss: \n",
      "0.00016416479058598658\n",
      "\n",
      "\n",
      "# 297\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90343141]\n",
      " [0.87475536]\n",
      " [0.89047296]]\n",
      "Loss: \n",
      "0.0001641541182609633\n",
      "\n",
      "\n",
      "# 298\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90343189]\n",
      " [0.87475481]\n",
      " [0.89047301]]\n",
      "Loss: \n",
      "0.0001641434491713328\n",
      "\n",
      "\n",
      "# 299\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90343237]\n",
      " [0.87475426]\n",
      " [0.89047305]]\n",
      "Loss: \n",
      "0.00016413278331572185\n",
      "\n",
      "\n",
      "# 300\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90343285]\n",
      " [0.87475371]\n",
      " [0.8904731 ]]\n",
      "Loss: \n",
      "0.0001641221206927624\n",
      "\n",
      "\n",
      "# 301\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90343333]\n",
      " [0.87475317]\n",
      " [0.89047314]]\n",
      "Loss: \n",
      "0.00016411146130109648\n",
      "\n",
      "\n",
      "# 302\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90343381]\n",
      " [0.87475262]\n",
      " [0.89047319]]\n",
      "Loss: \n",
      "0.00016410080513935043\n",
      "\n",
      "\n",
      "# 303\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90343428]\n",
      " [0.87475207]\n",
      " [0.89047323]]\n",
      "Loss: \n",
      "0.00016409015220617291\n",
      "\n",
      "\n",
      "# 304\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90343476]\n",
      " [0.87475152]\n",
      " [0.89047327]]\n",
      "Loss: \n",
      "0.00016407950250020334\n",
      "\n",
      "\n",
      "# 305\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90343523]\n",
      " [0.87475097]\n",
      " [0.89047331]]\n",
      "Loss: \n",
      "0.00016406885602008464\n",
      "\n",
      "\n",
      "# 306\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90343571]\n",
      " [0.87475042]\n",
      " [0.89047336]]\n",
      "Loss: \n",
      "0.0001640582127644646\n",
      "\n",
      "\n",
      "# 307\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90343619]\n",
      " [0.87474987]\n",
      " [0.8904734 ]]\n",
      "Loss: \n",
      "0.00016404757273199267\n",
      "\n",
      "\n",
      "# 308\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90343666]\n",
      " [0.87474932]\n",
      " [0.89047344]]\n",
      "Loss: \n",
      "0.00016403693592131324\n",
      "\n",
      "\n",
      "# 309\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90343713]\n",
      " [0.87474877]\n",
      " [0.89047348]]\n",
      "Loss: \n",
      "0.00016402630233108777\n",
      "\n",
      "\n",
      "# 310\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90343761]\n",
      " [0.87474822]\n",
      " [0.89047352]]\n",
      "Loss: \n",
      "0.00016401567195996358\n",
      "\n",
      "\n",
      "# 311\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90343808]\n",
      " [0.87474767]\n",
      " [0.89047356]]\n",
      "Loss: \n",
      "0.00016400504480659303\n",
      "\n",
      "\n",
      "# 312\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90343856]\n",
      " [0.87474712]\n",
      " [0.8904736 ]]\n",
      "Loss: \n",
      "0.00016399442086963872\n",
      "\n",
      "\n",
      "# 313\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90343903]\n",
      " [0.87474657]\n",
      " [0.89047364]]\n",
      "Loss: \n",
      "0.00016398380014775367\n",
      "\n",
      "\n",
      "# 314\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.9034395 ]\n",
      " [0.87474602]\n",
      " [0.89047368]]\n",
      "Loss: \n",
      "0.00016397318263960012\n",
      "\n",
      "\n",
      "# 315\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90343997]\n",
      " [0.87474547]\n",
      " [0.89047372]]\n",
      "Loss: \n",
      "0.00016396256834383537\n",
      "\n",
      "\n",
      "# 316\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90344045]\n",
      " [0.87474492]\n",
      " [0.89047376]]\n",
      "Loss: \n",
      "0.00016395195725912536\n",
      "\n",
      "\n",
      "# 317\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90344092]\n",
      " [0.87474437]\n",
      " [0.8904738 ]]\n",
      "Loss: \n",
      "0.00016394134938412688\n",
      "\n",
      "\n",
      "# 318\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90344139]\n",
      " [0.87474382]\n",
      " [0.89047384]]\n",
      "Loss: \n",
      "0.000163930744717507\n",
      "\n",
      "\n",
      "# 319\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90344186]\n",
      " [0.87474327]\n",
      " [0.89047388]]\n",
      "Loss: \n",
      "0.00016392014325793155\n",
      "\n",
      "\n",
      "# 320\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90344233]\n",
      " [0.87474272]\n",
      " [0.89047392]]\n",
      "Loss: \n",
      "0.00016390954500406394\n",
      "\n",
      "\n",
      "# 321\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.9034428 ]\n",
      " [0.87474217]\n",
      " [0.89047396]]\n",
      "Loss: \n",
      "0.00016389894995457293\n",
      "\n",
      "\n",
      "# 322\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90344327]\n",
      " [0.87474162]\n",
      " [0.890474  ]]\n",
      "Loss: \n",
      "0.00016388835810812936\n",
      "\n",
      "\n",
      "# 323\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90344374]\n",
      " [0.87474106]\n",
      " [0.89047404]]\n",
      "Loss: \n",
      "0.0001638777694633962\n",
      "\n",
      "\n",
      "# 324\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90344421]\n",
      " [0.87474051]\n",
      " [0.89047407]]\n",
      "Loss: \n",
      "0.00016386718401904636\n",
      "\n",
      "\n",
      "# 325\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90344468]\n",
      " [0.87473996]\n",
      " [0.89047411]]\n",
      "Loss: \n",
      "0.00016385660177374616\n",
      "\n",
      "\n",
      "# 326\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90344515]\n",
      " [0.87473941]\n",
      " [0.89047415]]\n",
      "Loss: \n",
      "0.00016384602272617645\n",
      "\n",
      "\n",
      "# 327\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90344562]\n",
      " [0.87473886]\n",
      " [0.89047419]]\n",
      "Loss: \n",
      "0.00016383544687500277\n",
      "\n",
      "\n",
      "# 328\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90344609]\n",
      " [0.87473831]\n",
      " [0.89047423]]\n",
      "Loss: \n",
      "0.00016382487421889882\n",
      "\n",
      "\n",
      "# 329\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90344656]\n",
      " [0.87473776]\n",
      " [0.89047426]]\n",
      "Loss: \n",
      "0.00016381430475653799\n",
      "\n",
      "\n",
      "# 330\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90344703]\n",
      " [0.87473721]\n",
      " [0.8904743 ]]\n",
      "Loss: \n",
      "0.0001638037384866\n",
      "\n",
      "\n",
      "# 331\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.9034475 ]\n",
      " [0.87473666]\n",
      " [0.89047434]]\n",
      "Loss: \n",
      "0.00016379317540775564\n",
      "\n",
      "\n",
      "# 332\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90344797]\n",
      " [0.87473611]\n",
      " [0.89047437]]\n",
      "Loss: \n",
      "0.0001637826155186851\n",
      "\n",
      "\n",
      "# 333\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90344843]\n",
      " [0.87473556]\n",
      " [0.89047441]]\n",
      "Loss: \n",
      "0.00016377205881806337\n",
      "\n",
      "\n",
      "# 334\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.9034489 ]\n",
      " [0.87473501]\n",
      " [0.89047445]]\n",
      "Loss: \n",
      "0.00016376150530456683\n",
      "\n",
      "\n",
      "# 335\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90344937]\n",
      " [0.87473446]\n",
      " [0.89047449]]\n",
      "Loss: \n",
      "0.00016375095497688107\n",
      "\n",
      "\n",
      "# 336\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90344984]\n",
      " [0.87473391]\n",
      " [0.89047452]]\n",
      "Loss: \n",
      "0.00016374040783367785\n",
      "\n",
      "\n",
      "# 337\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.9034503 ]\n",
      " [0.87473336]\n",
      " [0.89047456]]\n",
      "Loss: \n",
      "0.0001637298638736401\n",
      "\n",
      "\n",
      "# 338\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90345077]\n",
      " [0.87473281]\n",
      " [0.89047459]]\n",
      "Loss: \n",
      "0.00016371932309545102\n",
      "\n",
      "\n",
      "# 339\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90345124]\n",
      " [0.87473226]\n",
      " [0.89047463]]\n",
      "Loss: \n",
      "0.0001637087854977886\n",
      "\n",
      "\n",
      "# 340\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.9034517 ]\n",
      " [0.87473171]\n",
      " [0.89047467]]\n",
      "Loss: \n",
      "0.00016369825107933795\n",
      "\n",
      "\n",
      "# 341\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90345217]\n",
      " [0.87473116]\n",
      " [0.8904747 ]]\n",
      "Loss: \n",
      "0.0001636877198387852\n",
      "\n",
      "\n",
      "# 342\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90345264]\n",
      " [0.87473061]\n",
      " [0.89047474]]\n",
      "Loss: \n",
      "0.0001636771917748066\n",
      "\n",
      "\n",
      "# 343\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.9034531 ]\n",
      " [0.87473006]\n",
      " [0.89047478]]\n",
      "Loss: \n",
      "0.00016366666688609165\n",
      "\n",
      "\n",
      "# 344\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90345357]\n",
      " [0.87472951]\n",
      " [0.89047481]]\n",
      "Loss: \n",
      "0.00016365614517132576\n",
      "\n",
      "\n",
      "# 345\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90345403]\n",
      " [0.87472896]\n",
      " [0.89047485]]\n",
      "Loss: \n",
      "0.00016364562662919384\n",
      "\n",
      "\n",
      "# 346\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.9034545 ]\n",
      " [0.87472841]\n",
      " [0.89047488]]\n",
      "Loss: \n",
      "0.0001636351112583827\n",
      "\n",
      "\n",
      "# 347\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90345496]\n",
      " [0.87472787]\n",
      " [0.89047492]]\n",
      "Loss: \n",
      "0.0001636245990575787\n",
      "\n",
      "\n",
      "# 348\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90345543]\n",
      " [0.87472732]\n",
      " [0.89047496]]\n",
      "Loss: \n",
      "0.0001636140900254716\n",
      "\n",
      "\n",
      "# 349\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90345589]\n",
      " [0.87472677]\n",
      " [0.89047499]]\n",
      "Loss: \n",
      "0.00016360358416074927\n",
      "\n",
      "\n",
      "# 350\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90345636]\n",
      " [0.87472622]\n",
      " [0.89047503]]\n",
      "Loss: \n",
      "0.00016359308146210037\n",
      "\n",
      "\n",
      "# 351\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90345682]\n",
      " [0.87472567]\n",
      " [0.89047506]]\n",
      "Loss: \n",
      "0.00016358258192821718\n",
      "\n",
      "\n",
      "# 352\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90345729]\n",
      " [0.87472512]\n",
      " [0.8904751 ]]\n",
      "Loss: \n",
      "0.00016357208555778816\n",
      "\n",
      "\n",
      "# 353\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90345775]\n",
      " [0.87472457]\n",
      " [0.89047513]]\n",
      "Loss: \n",
      "0.0001635615923495046\n",
      "\n",
      "\n",
      "# 354\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90345822]\n",
      " [0.87472402]\n",
      " [0.89047517]]\n",
      "Loss: \n",
      "0.00016355110230206141\n",
      "\n",
      "\n",
      "# 355\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90345868]\n",
      " [0.87472348]\n",
      " [0.8904752 ]]\n",
      "Loss: \n",
      "0.0001635406154141512\n",
      "\n",
      "\n",
      "# 356\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90345914]\n",
      " [0.87472293]\n",
      " [0.89047524]]\n",
      "Loss: \n",
      "0.00016353013168446257\n",
      "\n",
      "\n",
      "# 357\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90345961]\n",
      " [0.87472238]\n",
      " [0.89047527]]\n",
      "Loss: \n",
      "0.00016351965111169577\n",
      "\n",
      "\n",
      "# 358\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90346007]\n",
      " [0.87472183]\n",
      " [0.89047531]]\n",
      "Loss: \n",
      "0.0001635091736945413\n",
      "\n",
      "\n",
      "# 359\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90346053]\n",
      " [0.87472128]\n",
      " [0.89047534]]\n",
      "Loss: \n",
      "0.0001634986994316984\n",
      "\n",
      "\n",
      "# 360\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.903461  ]\n",
      " [0.87472074]\n",
      " [0.89047538]]\n",
      "Loss: \n",
      "0.00016348822832185986\n",
      "\n",
      "\n",
      "# 361\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90346146]\n",
      " [0.87472019]\n",
      " [0.89047541]]\n",
      "Loss: \n",
      "0.0001634777603637239\n",
      "\n",
      "\n",
      "# 362\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90346192]\n",
      " [0.87471964]\n",
      " [0.89047545]]\n",
      "Loss: \n",
      "0.0001634672955559879\n",
      "\n",
      "\n",
      "# 363\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90346239]\n",
      " [0.8747191 ]\n",
      " [0.89047548]]\n",
      "Loss: \n",
      "0.00016345683389734945\n",
      "\n",
      "\n",
      "# 364\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90346285]\n",
      " [0.87471855]\n",
      " [0.89047552]]\n",
      "Loss: \n",
      "0.00016344637538650902\n",
      "\n",
      "\n",
      "# 365\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90346331]\n",
      " [0.874718  ]\n",
      " [0.89047555]]\n",
      "Loss: \n",
      "0.000163435920022164\n",
      "\n",
      "\n",
      "# 366\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90346377]\n",
      " [0.87471745]\n",
      " [0.89047559]]\n",
      "Loss: \n",
      "0.0001634254678030166\n",
      "\n",
      "\n",
      "# 367\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90346424]\n",
      " [0.87471691]\n",
      " [0.89047562]]\n",
      "Loss: \n",
      "0.00016341501872776465\n",
      "\n",
      "\n",
      "# 368\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.9034647 ]\n",
      " [0.87471636]\n",
      " [0.89047566]]\n",
      "Loss: \n",
      "0.00016340457279511388\n",
      "\n",
      "\n",
      "# 369\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90346516]\n",
      " [0.87471581]\n",
      " [0.89047569]]\n",
      "Loss: \n",
      "0.00016339413000376334\n",
      "\n",
      "\n",
      "# 370\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90346562]\n",
      " [0.87471527]\n",
      " [0.89047573]]\n",
      "Loss: \n",
      "0.0001633836903524153\n",
      "\n",
      "\n",
      "# 371\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90346608]\n",
      " [0.87471472]\n",
      " [0.89047576]]\n",
      "Loss: \n",
      "0.00016337325383977686\n",
      "\n",
      "\n",
      "# 372\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90346655]\n",
      " [0.87471418]\n",
      " [0.8904758 ]]\n",
      "Loss: \n",
      "0.00016336282046454677\n",
      "\n",
      "\n",
      "# 373\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90346701]\n",
      " [0.87471363]\n",
      " [0.89047583]]\n",
      "Loss: \n",
      "0.00016335239022543486\n",
      "\n",
      "\n",
      "# 374\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90346747]\n",
      " [0.87471308]\n",
      " [0.89047587]]\n",
      "Loss: \n",
      "0.00016334196312114743\n",
      "\n",
      "\n",
      "# 375\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90346793]\n",
      " [0.87471254]\n",
      " [0.8904759 ]]\n",
      "Loss: \n",
      "0.00016333153915038532\n",
      "\n",
      "\n",
      "# 376\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90346839]\n",
      " [0.87471199]\n",
      " [0.89047593]]\n",
      "Loss: \n",
      "0.00016332111831185802\n",
      "\n",
      "\n",
      "# 377\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90346885]\n",
      " [0.87471145]\n",
      " [0.89047597]]\n",
      "Loss: \n",
      "0.00016331070060427518\n",
      "\n",
      "\n",
      "# 378\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90346931]\n",
      " [0.8747109 ]\n",
      " [0.890476  ]]\n",
      "Loss: \n",
      "0.00016330028602633796\n",
      "\n",
      "\n",
      "# 379\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90346977]\n",
      " [0.87471036]\n",
      " [0.89047604]]\n",
      "Loss: \n",
      "0.00016328987457676336\n",
      "\n",
      "\n",
      "# 380\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90347023]\n",
      " [0.87470981]\n",
      " [0.89047607]]\n",
      "Loss: \n",
      "0.00016327946625425578\n",
      "\n",
      "\n",
      "# 381\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90347069]\n",
      " [0.87470927]\n",
      " [0.89047611]]\n",
      "Loss: \n",
      "0.0001632690610575273\n",
      "\n",
      "\n",
      "# 382\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90347115]\n",
      " [0.87470872]\n",
      " [0.89047614]]\n",
      "Loss: \n",
      "0.00016325865898529014\n",
      "\n",
      "\n",
      "# 383\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90347161]\n",
      " [0.87470818]\n",
      " [0.89047618]]\n",
      "Loss: \n",
      "0.00016324826003625173\n",
      "\n",
      "\n",
      "# 384\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90347207]\n",
      " [0.87470763]\n",
      " [0.89047621]]\n",
      "Loss: \n",
      "0.0001632378642091274\n",
      "\n",
      "\n",
      "# 385\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90347253]\n",
      " [0.87470709]\n",
      " [0.89047624]]\n",
      "Loss: \n",
      "0.0001632274715026288\n",
      "\n",
      "\n",
      "# 386\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90347299]\n",
      " [0.87470655]\n",
      " [0.89047628]]\n",
      "Loss: \n",
      "0.00016321708191546793\n",
      "\n",
      "\n",
      "# 387\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90347345]\n",
      " [0.874706  ]\n",
      " [0.89047631]]\n",
      "Loss: \n",
      "0.00016320669544636125\n",
      "\n",
      "\n",
      "# 388\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90347391]\n",
      " [0.87470546]\n",
      " [0.89047635]]\n",
      "Loss: \n",
      "0.0001631963120940234\n",
      "\n",
      "\n",
      "# 389\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90347437]\n",
      " [0.87470491]\n",
      " [0.89047638]]\n",
      "Loss: \n",
      "0.00016318593185716494\n",
      "\n",
      "\n",
      "# 390\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90347483]\n",
      " [0.87470437]\n",
      " [0.89047641]]\n",
      "Loss: \n",
      "0.00016317555473450952\n",
      "\n",
      "\n",
      "# 391\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90347529]\n",
      " [0.87470383]\n",
      " [0.89047645]]\n",
      "Loss: \n",
      "0.00016316518072476943\n",
      "\n",
      "\n",
      "# 392\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90347575]\n",
      " [0.87470328]\n",
      " [0.89047648]]\n",
      "Loss: \n",
      "0.0001631548098266619\n",
      "\n",
      "\n",
      "# 393\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90347621]\n",
      " [0.87470274]\n",
      " [0.89047652]]\n",
      "Loss: \n",
      "0.00016314444203890485\n",
      "\n",
      "\n",
      "# 394\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90347667]\n",
      " [0.8747022 ]\n",
      " [0.89047655]]\n",
      "Loss: \n",
      "0.00016313407736022196\n",
      "\n",
      "\n",
      "# 395\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90347713]\n",
      " [0.87470165]\n",
      " [0.89047658]]\n",
      "Loss: \n",
      "0.00016312371578932271\n",
      "\n",
      "\n",
      "# 396\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90347758]\n",
      " [0.87470111]\n",
      " [0.89047662]]\n",
      "Loss: \n",
      "0.00016311335732493827\n",
      "\n",
      "\n",
      "# 397\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90347804]\n",
      " [0.87470057]\n",
      " [0.89047665]]\n",
      "Loss: \n",
      "0.00016310300196578132\n",
      "\n",
      "\n",
      "# 398\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.9034785 ]\n",
      " [0.87470003]\n",
      " [0.89047669]]\n",
      "Loss: \n",
      "0.00016309264971057808\n",
      "\n",
      "\n",
      "# 399\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90347896]\n",
      " [0.87469948]\n",
      " [0.89047672]]\n",
      "Loss: \n",
      "0.00016308230055804584\n",
      "\n",
      "\n",
      "# 400\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90347942]\n",
      " [0.87469894]\n",
      " [0.89047675]]\n",
      "Loss: \n",
      "0.00016307195450690915\n",
      "\n",
      "\n",
      "# 401\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90347988]\n",
      " [0.8746984 ]\n",
      " [0.89047679]]\n",
      "Loss: \n",
      "0.00016306161155589473\n",
      "\n",
      "\n",
      "# 402\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90348033]\n",
      " [0.87469786]\n",
      " [0.89047682]]\n",
      "Loss: \n",
      "0.00016305127170372058\n",
      "\n",
      "\n",
      "# 403\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90348079]\n",
      " [0.87469732]\n",
      " [0.89047686]]\n",
      "Loss: \n",
      "0.00016304093494911656\n",
      "\n",
      "\n",
      "# 404\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90348125]\n",
      " [0.87469678]\n",
      " [0.89047689]]\n",
      "Loss: \n",
      "0.00016303060129080357\n",
      "\n",
      "\n",
      "# 405\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90348171]\n",
      " [0.87469623]\n",
      " [0.89047692]]\n",
      "Loss: \n",
      "0.00016302027072751023\n",
      "\n",
      "\n",
      "# 406\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90348216]\n",
      " [0.87469569]\n",
      " [0.89047696]]\n",
      "Loss: \n",
      "0.00016300994325796448\n",
      "\n",
      "\n",
      "# 407\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90348262]\n",
      " [0.87469515]\n",
      " [0.89047699]]\n",
      "Loss: \n",
      "0.0001629996188808892\n",
      "\n",
      "\n",
      "# 408\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90348308]\n",
      " [0.87469461]\n",
      " [0.89047702]]\n",
      "Loss: \n",
      "0.00016298929759501392\n",
      "\n",
      "\n",
      "# 409\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90348353]\n",
      " [0.87469407]\n",
      " [0.89047706]]\n",
      "Loss: \n",
      "0.00016297897939906829\n",
      "\n",
      "\n",
      "# 410\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90348399]\n",
      " [0.87469353]\n",
      " [0.89047709]]\n",
      "Loss: \n",
      "0.0001629686642917843\n",
      "\n",
      "\n",
      "# 411\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90348445]\n",
      " [0.87469299]\n",
      " [0.89047713]]\n",
      "Loss: \n",
      "0.00016295835227188562\n",
      "\n",
      "\n",
      "# 412\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.9034849 ]\n",
      " [0.87469245]\n",
      " [0.89047716]]\n",
      "Loss: \n",
      "0.00016294804333810494\n",
      "\n",
      "\n",
      "# 413\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90348536]\n",
      " [0.87469191]\n",
      " [0.89047719]]\n",
      "Loss: \n",
      "0.00016293773748917651\n",
      "\n",
      "\n",
      "# 414\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90348582]\n",
      " [0.87469137]\n",
      " [0.89047723]]\n",
      "Loss: \n",
      "0.0001629274347238277\n",
      "\n",
      "\n",
      "# 415\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90348627]\n",
      " [0.87469083]\n",
      " [0.89047726]]\n",
      "Loss: \n",
      "0.0001629171350407947\n",
      "\n",
      "\n",
      "# 416\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90348673]\n",
      " [0.87469029]\n",
      " [0.89047729]]\n",
      "Loss: \n",
      "0.00016290683843880795\n",
      "\n",
      "\n",
      "# 417\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90348719]\n",
      " [0.87468975]\n",
      " [0.89047733]]\n",
      "Loss: \n",
      "0.00016289654491660188\n",
      "\n",
      "\n",
      "# 418\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90348764]\n",
      " [0.87468921]\n",
      " [0.89047736]]\n",
      "Loss: \n",
      "0.00016288625447291084\n",
      "\n",
      "\n",
      "# 419\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.9034881 ]\n",
      " [0.87468867]\n",
      " [0.89047739]]\n",
      "Loss: \n",
      "0.00016287596710647267\n",
      "\n",
      "\n",
      "# 420\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90348855]\n",
      " [0.87468813]\n",
      " [0.89047743]]\n",
      "Loss: \n",
      "0.0001628656828160167\n",
      "\n",
      "\n",
      "# 421\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90348901]\n",
      " [0.87468759]\n",
      " [0.89047746]]\n",
      "Loss: \n",
      "0.00016285540160028544\n",
      "\n",
      "\n",
      "# 422\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90348946]\n",
      " [0.87468705]\n",
      " [0.89047749]]\n",
      "Loss: \n",
      "0.00016284512345801267\n",
      "\n",
      "\n",
      "# 423\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90348992]\n",
      " [0.87468651]\n",
      " [0.89047753]]\n",
      "Loss: \n",
      "0.00016283484838793788\n",
      "\n",
      "\n",
      "# 424\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90349037]\n",
      " [0.87468598]\n",
      " [0.89047756]]\n",
      "Loss: \n",
      "0.00016282457638879867\n",
      "\n",
      "\n",
      "# 425\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90349083]\n",
      " [0.87468544]\n",
      " [0.8904776 ]]\n",
      "Loss: \n",
      "0.00016281430745933442\n",
      "\n",
      "\n",
      "# 426\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90349128]\n",
      " [0.8746849 ]\n",
      " [0.89047763]]\n",
      "Loss: \n",
      "0.0001628040415982817\n",
      "\n",
      "\n",
      "# 427\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90349174]\n",
      " [0.87468436]\n",
      " [0.89047766]]\n",
      "Loss: \n",
      "0.00016279377880438456\n",
      "\n",
      "\n",
      "# 428\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90349219]\n",
      " [0.87468382]\n",
      " [0.8904777 ]]\n",
      "Loss: \n",
      "0.00016278351907638117\n",
      "\n",
      "\n",
      "# 429\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90349265]\n",
      " [0.87468329]\n",
      " [0.89047773]]\n",
      "Loss: \n",
      "0.0001627732624130168\n",
      "\n",
      "\n",
      "# 430\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.9034931 ]\n",
      " [0.87468275]\n",
      " [0.89047776]]\n",
      "Loss: \n",
      "0.0001627630088130314\n",
      "\n",
      "\n",
      "# 431\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90349356]\n",
      " [0.87468221]\n",
      " [0.8904778 ]]\n",
      "Loss: \n",
      "0.00016275275827516643\n",
      "\n",
      "\n",
      "# 432\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90349401]\n",
      " [0.87468167]\n",
      " [0.89047783]]\n",
      "Loss: \n",
      "0.00016274251079816509\n",
      "\n",
      "\n",
      "# 433\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90349446]\n",
      " [0.87468114]\n",
      " [0.89047786]]\n",
      "Loss: \n",
      "0.00016273226638077664\n",
      "\n",
      "\n",
      "# 434\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90349492]\n",
      " [0.8746806 ]\n",
      " [0.8904779 ]]\n",
      "Loss: \n",
      "0.00016272202502173744\n",
      "\n",
      "\n",
      "# 435\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90349537]\n",
      " [0.87468006]\n",
      " [0.89047793]]\n",
      "Loss: \n",
      "0.00016271178671980284\n",
      "\n",
      "\n",
      "# 436\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90349583]\n",
      " [0.87467953]\n",
      " [0.89047796]]\n",
      "Loss: \n",
      "0.00016270155147371195\n",
      "\n",
      "\n",
      "# 437\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90349628]\n",
      " [0.87467899]\n",
      " [0.890478  ]]\n",
      "Loss: \n",
      "0.00016269131928221264\n",
      "\n",
      "\n",
      "# 438\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90349673]\n",
      " [0.87467845]\n",
      " [0.89047803]]\n",
      "Loss: \n",
      "0.00016268109014405308\n",
      "\n",
      "\n",
      "# 439\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90349719]\n",
      " [0.87467792]\n",
      " [0.89047806]]\n",
      "Loss: \n",
      "0.0001626708640579823\n",
      "\n",
      "\n",
      "# 440\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90349764]\n",
      " [0.87467738]\n",
      " [0.89047809]]\n",
      "Loss: \n",
      "0.00016266064102274876\n",
      "\n",
      "\n",
      "# 441\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90349809]\n",
      " [0.87467684]\n",
      " [0.89047813]]\n",
      "Loss: \n",
      "0.00016265042103709706\n",
      "\n",
      "\n",
      "# 442\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90349855]\n",
      " [0.87467631]\n",
      " [0.89047816]]\n",
      "Loss: \n",
      "0.00016264020409978308\n",
      "\n",
      "\n",
      "# 443\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.903499  ]\n",
      " [0.87467577]\n",
      " [0.89047819]]\n",
      "Loss: \n",
      "0.000162629990209554\n",
      "\n",
      "\n",
      "# 444\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90349945]\n",
      " [0.87467524]\n",
      " [0.89047823]]\n",
      "Loss: \n",
      "0.00016261977936516325\n",
      "\n",
      "\n",
      "# 445\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.9034999 ]\n",
      " [0.8746747 ]\n",
      " [0.89047826]]\n",
      "Loss: \n",
      "0.00016260957156536245\n",
      "\n",
      "\n",
      "# 446\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90350036]\n",
      " [0.87467417]\n",
      " [0.89047829]]\n",
      "Loss: \n",
      "0.00016259936680890392\n",
      "\n",
      "\n",
      "# 447\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90350081]\n",
      " [0.87467363]\n",
      " [0.89047833]]\n",
      "Loss: \n",
      "0.0001625891650945387\n",
      "\n",
      "\n",
      "# 448\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90350126]\n",
      " [0.8746731 ]\n",
      " [0.89047836]]\n",
      "Loss: \n",
      "0.00016257896642102323\n",
      "\n",
      "\n",
      "# 449\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90350171]\n",
      " [0.87467256]\n",
      " [0.89047839]]\n",
      "Loss: \n",
      "0.00016256877078710944\n",
      "\n",
      "\n",
      "# 450\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90350217]\n",
      " [0.87467203]\n",
      " [0.89047843]]\n",
      "Loss: \n",
      "0.00016255857819155741\n",
      "\n",
      "\n",
      "# 451\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90350262]\n",
      " [0.87467149]\n",
      " [0.89047846]]\n",
      "Loss: \n",
      "0.00016254838863311372\n",
      "\n",
      "\n",
      "# 452\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90350307]\n",
      " [0.87467096]\n",
      " [0.89047849]]\n",
      "Loss: \n",
      "0.00016253820211054222\n",
      "\n",
      "\n",
      "# 453\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90350352]\n",
      " [0.87467042]\n",
      " [0.89047853]]\n",
      "Loss: \n",
      "0.00016252801862260023\n",
      "\n",
      "\n",
      "# 454\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90350397]\n",
      " [0.87466989]\n",
      " [0.89047856]]\n",
      "Loss: \n",
      "0.0001625178381680402\n",
      "\n",
      "\n",
      "# 455\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90350443]\n",
      " [0.87466935]\n",
      " [0.89047859]]\n",
      "Loss: \n",
      "0.00016250766074562506\n",
      "\n",
      "\n",
      "# 456\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90350488]\n",
      " [0.87466882]\n",
      " [0.89047862]]\n",
      "Loss: \n",
      "0.00016249748635411196\n",
      "\n",
      "\n",
      "# 457\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90350533]\n",
      " [0.87466829]\n",
      " [0.89047866]]\n",
      "Loss: \n",
      "0.00016248731499225857\n",
      "\n",
      "\n",
      "# 458\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90350578]\n",
      " [0.87466775]\n",
      " [0.89047869]]\n",
      "Loss: \n",
      "0.00016247714665883068\n",
      "\n",
      "\n",
      "# 459\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90350623]\n",
      " [0.87466722]\n",
      " [0.89047872]]\n",
      "Loss: \n",
      "0.00016246698135258104\n",
      "\n",
      "\n",
      "# 460\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90350668]\n",
      " [0.87466669]\n",
      " [0.89047876]]\n",
      "Loss: \n",
      "0.00016245681907227813\n",
      "\n",
      "\n",
      "# 461\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90350713]\n",
      " [0.87466615]\n",
      " [0.89047879]]\n",
      "Loss: \n",
      "0.00016244665981667898\n",
      "\n",
      "\n",
      "# 462\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90350758]\n",
      " [0.87466562]\n",
      " [0.89047882]]\n",
      "Loss: \n",
      "0.00016243650358454927\n",
      "\n",
      "\n",
      "# 463\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90350803]\n",
      " [0.87466509]\n",
      " [0.89047885]]\n",
      "Loss: \n",
      "0.00016242635037465273\n",
      "\n",
      "\n",
      "# 464\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90350848]\n",
      " [0.87466456]\n",
      " [0.89047889]]\n",
      "Loss: \n",
      "0.00016241620018575317\n",
      "\n",
      "\n",
      "# 465\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90350894]\n",
      " [0.87466402]\n",
      " [0.89047892]]\n",
      "Loss: \n",
      "0.0001624060530166115\n",
      "\n",
      "\n",
      "# 466\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90350939]\n",
      " [0.87466349]\n",
      " [0.89047895]]\n",
      "Loss: \n",
      "0.00016239590886599838\n",
      "\n",
      "\n",
      "# 467\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90350984]\n",
      " [0.87466296]\n",
      " [0.89047899]]\n",
      "Loss: \n",
      "0.00016238576773267658\n",
      "\n",
      "\n",
      "# 468\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90351029]\n",
      " [0.87466243]\n",
      " [0.89047902]]\n",
      "Loss: \n",
      "0.0001623756296154119\n",
      "\n",
      "\n",
      "# 469\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90351074]\n",
      " [0.87466189]\n",
      " [0.89047905]]\n",
      "Loss: \n",
      "0.00016236549451297382\n",
      "\n",
      "\n",
      "# 470\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90351119]\n",
      " [0.87466136]\n",
      " [0.89047908]]\n",
      "Loss: \n",
      "0.00016235536242412938\n",
      "\n",
      "\n",
      "# 471\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90351164]\n",
      " [0.87466083]\n",
      " [0.89047912]]\n",
      "Loss: \n",
      "0.00016234523334764396\n",
      "\n",
      "\n",
      "# 472\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90351208]\n",
      " [0.8746603 ]\n",
      " [0.89047915]]\n",
      "Loss: \n",
      "0.00016233510728229185\n",
      "\n",
      "\n",
      "# 473\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90351253]\n",
      " [0.87465977]\n",
      " [0.89047918]]\n",
      "Loss: \n",
      "0.0001623249842268407\n",
      "\n",
      "\n",
      "# 474\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90351298]\n",
      " [0.87465924]\n",
      " [0.89047922]]\n",
      "Loss: \n",
      "0.00016231486418006032\n",
      "\n",
      "\n",
      "# 475\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90351343]\n",
      " [0.87465871]\n",
      " [0.89047925]]\n",
      "Loss: \n",
      "0.00016230474714072187\n",
      "\n",
      "\n",
      "# 476\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90351388]\n",
      " [0.87465818]\n",
      " [0.89047928]]\n",
      "Loss: \n",
      "0.00016229463310759524\n",
      "\n",
      "\n",
      "# 477\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90351433]\n",
      " [0.87465764]\n",
      " [0.89047931]]\n",
      "Loss: \n",
      "0.00016228452207945267\n",
      "\n",
      "\n",
      "# 478\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90351478]\n",
      " [0.87465711]\n",
      " [0.89047935]]\n",
      "Loss: \n",
      "0.0001622744140550721\n",
      "\n",
      "\n",
      "# 479\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90351523]\n",
      " [0.87465658]\n",
      " [0.89047938]]\n",
      "Loss: \n",
      "0.0001622643090332249\n",
      "\n",
      "\n",
      "# 480\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90351568]\n",
      " [0.87465605]\n",
      " [0.89047941]]\n",
      "Loss: \n",
      "0.00016225420701268054\n",
      "\n",
      "\n",
      "# 481\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90351613]\n",
      " [0.87465552]\n",
      " [0.89047944]]\n",
      "Loss: \n",
      "0.000162244107992217\n",
      "\n",
      "\n",
      "# 482\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90351658]\n",
      " [0.87465499]\n",
      " [0.89047948]]\n",
      "Loss: \n",
      "0.00016223401197061092\n",
      "\n",
      "\n",
      "# 483\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90351702]\n",
      " [0.87465446]\n",
      " [0.89047951]]\n",
      "Loss: \n",
      "0.0001622239189466343\n",
      "\n",
      "\n",
      "# 484\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90351747]\n",
      " [0.87465393]\n",
      " [0.89047954]]\n",
      "Loss: \n",
      "0.00016221382891906926\n",
      "\n",
      "\n",
      "# 485\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90351792]\n",
      " [0.8746534 ]\n",
      " [0.89047957]]\n",
      "Loss: \n",
      "0.0001622037418866885\n",
      "\n",
      "\n",
      "# 486\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90351837]\n",
      " [0.87465288]\n",
      " [0.89047961]]\n",
      "Loss: \n",
      "0.00016219365784827185\n",
      "\n",
      "\n",
      "# 487\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90351882]\n",
      " [0.87465235]\n",
      " [0.89047964]]\n",
      "Loss: \n",
      "0.0001621835768025978\n",
      "\n",
      "\n",
      "# 488\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90351926]\n",
      " [0.87465182]\n",
      " [0.89047967]]\n",
      "Loss: \n",
      "0.00016217349874844531\n",
      "\n",
      "\n",
      "# 489\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90351971]\n",
      " [0.87465129]\n",
      " [0.8904797 ]]\n",
      "Loss: \n",
      "0.00016216342368459286\n",
      "\n",
      "\n",
      "# 490\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90352016]\n",
      " [0.87465076]\n",
      " [0.89047974]]\n",
      "Loss: \n",
      "0.0001621533516098237\n",
      "\n",
      "\n",
      "# 491\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90352061]\n",
      " [0.87465023]\n",
      " [0.89047977]]\n",
      "Loss: \n",
      "0.00016214328252291607\n",
      "\n",
      "\n",
      "# 492\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90352105]\n",
      " [0.8746497 ]\n",
      " [0.8904798 ]]\n",
      "Loss: \n",
      "0.00016213321642265154\n",
      "\n",
      "\n",
      "# 493\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.9035215 ]\n",
      " [0.87464917]\n",
      " [0.89047983]]\n",
      "Loss: \n",
      "0.0001621231533078148\n",
      "\n",
      "\n",
      "# 494\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90352195]\n",
      " [0.87464865]\n",
      " [0.89047987]]\n",
      "Loss: \n",
      "0.00016211309317718623\n",
      "\n",
      "\n",
      "# 495\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.9035224 ]\n",
      " [0.87464812]\n",
      " [0.8904799 ]]\n",
      "Loss: \n",
      "0.00016210303602955077\n",
      "\n",
      "\n",
      "# 496\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90352284]\n",
      " [0.87464759]\n",
      " [0.89047993]]\n",
      "Loss: \n",
      "0.00016209298186369345\n",
      "\n",
      "\n",
      "# 497\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90352329]\n",
      " [0.87464706]\n",
      " [0.89047996]]\n",
      "Loss: \n",
      "0.00016208293067839646\n",
      "\n",
      "\n",
      "# 498\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90352374]\n",
      " [0.87464653]\n",
      " [0.89048   ]]\n",
      "Loss: \n",
      "0.00016207288247244628\n",
      "\n",
      "\n",
      "# 499\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90352418]\n",
      " [0.87464601]\n",
      " [0.89048003]]\n",
      "Loss: \n",
      "0.0001620628372446269\n",
      "\n",
      "\n",
      "# 500\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90352463]\n",
      " [0.87464548]\n",
      " [0.89048006]]\n",
      "Loss: \n",
      "0.00016205279499372958\n",
      "\n",
      "\n",
      "# 501\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90352508]\n",
      " [0.87464495]\n",
      " [0.89048009]]\n",
      "Loss: \n",
      "0.00016204275571853874\n",
      "\n",
      "\n",
      "# 502\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90352552]\n",
      " [0.87464443]\n",
      " [0.89048013]]\n",
      "Loss: \n",
      "0.0001620327194178433\n",
      "\n",
      "\n",
      "# 503\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90352597]\n",
      " [0.8746439 ]\n",
      " [0.89048016]]\n",
      "Loss: \n",
      "0.00016202268609042696\n",
      "\n",
      "\n",
      "# 504\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90352641]\n",
      " [0.87464337]\n",
      " [0.89048019]]\n",
      "Loss: \n",
      "0.00016201265573508438\n",
      "\n",
      "\n",
      "# 505\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90352686]\n",
      " [0.87464285]\n",
      " [0.89048022]]\n",
      "Loss: \n",
      "0.0001620026283506046\n",
      "\n",
      "\n",
      "# 506\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90352731]\n",
      " [0.87464232]\n",
      " [0.89048026]]\n",
      "Loss: \n",
      "0.00016199260393577754\n",
      "\n",
      "\n",
      "# 507\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90352775]\n",
      " [0.87464179]\n",
      " [0.89048029]]\n",
      "Loss: \n",
      "0.00016198258248939352\n",
      "\n",
      "\n",
      "# 508\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.9035282 ]\n",
      " [0.87464127]\n",
      " [0.89048032]]\n",
      "Loss: \n",
      "0.00016197256401023966\n",
      "\n",
      "\n",
      "# 509\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90352864]\n",
      " [0.87464074]\n",
      " [0.89048035]]\n",
      "Loss: \n",
      "0.0001619625484971175\n",
      "\n",
      "\n",
      "# 510\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90352909]\n",
      " [0.87464021]\n",
      " [0.89048038]]\n",
      "Loss: \n",
      "0.0001619525359488112\n",
      "\n",
      "\n",
      "# 511\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90352953]\n",
      " [0.87463969]\n",
      " [0.89048042]]\n",
      "Loss: \n",
      "0.00016194252636412128\n",
      "\n",
      "\n",
      "# 512\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90352998]\n",
      " [0.87463916]\n",
      " [0.89048045]]\n",
      "Loss: \n",
      "0.00016193251974183737\n",
      "\n",
      "\n",
      "# 513\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90353042]\n",
      " [0.87463864]\n",
      " [0.89048048]]\n",
      "Loss: \n",
      "0.0001619225160807527\n",
      "\n",
      "\n",
      "# 514\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90353087]\n",
      " [0.87463811]\n",
      " [0.89048051]]\n",
      "Loss: \n",
      "0.00016191251537966514\n",
      "\n",
      "\n",
      "# 515\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90353131]\n",
      " [0.87463759]\n",
      " [0.89048055]]\n",
      "Loss: \n",
      "0.0001619025176373698\n",
      "\n",
      "\n",
      "# 516\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90353176]\n",
      " [0.87463706]\n",
      " [0.89048058]]\n",
      "Loss: \n",
      "0.0001618925228526662\n",
      "\n",
      "\n",
      "# 517\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.9035322 ]\n",
      " [0.87463654]\n",
      " [0.89048061]]\n",
      "Loss: \n",
      "0.00016188253102434862\n",
      "\n",
      "\n",
      "# 518\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90353265]\n",
      " [0.87463601]\n",
      " [0.89048064]]\n",
      "Loss: \n",
      "0.00016187254215121273\n",
      "\n",
      "\n",
      "# 519\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90353309]\n",
      " [0.87463549]\n",
      " [0.89048067]]\n",
      "Loss: \n",
      "0.00016186255623206237\n",
      "\n",
      "\n",
      "# 520\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90353353]\n",
      " [0.87463496]\n",
      " [0.89048071]]\n",
      "Loss: \n",
      "0.00016185257326569152\n",
      "\n",
      "\n",
      "# 521\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90353398]\n",
      " [0.87463444]\n",
      " [0.89048074]]\n",
      "Loss: \n",
      "0.00016184259325089872\n",
      "\n",
      "\n",
      "# 522\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90353442]\n",
      " [0.87463392]\n",
      " [0.89048077]]\n",
      "Loss: \n",
      "0.0001618326161864876\n",
      "\n",
      "\n",
      "# 523\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90353487]\n",
      " [0.87463339]\n",
      " [0.8904808 ]]\n",
      "Loss: \n",
      "0.00016182264207125957\n",
      "\n",
      "\n",
      "# 524\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90353531]\n",
      " [0.87463287]\n",
      " [0.89048083]]\n",
      "Loss: \n",
      "0.00016181267090401626\n",
      "\n",
      "\n",
      "# 525\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90353575]\n",
      " [0.87463234]\n",
      " [0.89048087]]\n",
      "Loss: \n",
      "0.00016180270268355618\n",
      "\n",
      "\n",
      "# 526\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.9035362 ]\n",
      " [0.87463182]\n",
      " [0.8904809 ]]\n",
      "Loss: \n",
      "0.000161792737408683\n",
      "\n",
      "\n",
      "# 527\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90353664]\n",
      " [0.8746313 ]\n",
      " [0.89048093]]\n",
      "Loss: \n",
      "0.000161782775078202\n",
      "\n",
      "\n",
      "# 528\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90353708]\n",
      " [0.87463077]\n",
      " [0.89048096]]\n",
      "Loss: \n",
      "0.00016177281569091265\n",
      "\n",
      "\n",
      "# 529\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90353753]\n",
      " [0.87463025]\n",
      " [0.89048099]]\n",
      "Loss: \n",
      "0.00016176285924562582\n",
      "\n",
      "\n",
      "# 530\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90353797]\n",
      " [0.87462973]\n",
      " [0.89048103]]\n",
      "Loss: \n",
      "0.00016175290574114366\n",
      "\n",
      "\n",
      "# 531\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90353841]\n",
      " [0.8746292 ]\n",
      " [0.89048106]]\n",
      "Loss: \n",
      "0.0001617429551762701\n",
      "\n",
      "\n",
      "# 532\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90353886]\n",
      " [0.87462868]\n",
      " [0.89048109]]\n",
      "Loss: \n",
      "0.00016173300754981245\n",
      "\n",
      "\n",
      "# 533\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.9035393 ]\n",
      " [0.87462816]\n",
      " [0.89048112]]\n",
      "Loss: \n",
      "0.000161723062860578\n",
      "\n",
      "\n",
      "# 534\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90353974]\n",
      " [0.87462764]\n",
      " [0.89048115]]\n",
      "Loss: \n",
      "0.000161713121107374\n",
      "\n",
      "\n",
      "# 535\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90354018]\n",
      " [0.87462711]\n",
      " [0.89048119]]\n",
      "Loss: \n",
      "0.00016170318228900815\n",
      "\n",
      "\n",
      "# 536\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90354063]\n",
      " [0.87462659]\n",
      " [0.89048122]]\n",
      "Loss: \n",
      "0.00016169324640429147\n",
      "\n",
      "\n",
      "# 537\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90354107]\n",
      " [0.87462607]\n",
      " [0.89048125]]\n",
      "Loss: \n",
      "0.0001616833134520291\n",
      "\n",
      "\n",
      "# 538\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90354151]\n",
      " [0.87462555]\n",
      " [0.89048128]]\n",
      "Loss: \n",
      "0.0001616733834310347\n",
      "\n",
      "\n",
      "# 539\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90354195]\n",
      " [0.87462503]\n",
      " [0.89048131]]\n",
      "Loss: \n",
      "0.00016166345634011661\n",
      "\n",
      "\n",
      "# 540\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.9035424 ]\n",
      " [0.87462451]\n",
      " [0.89048135]]\n",
      "Loss: \n",
      "0.00016165353217808715\n",
      "\n",
      "\n",
      "# 541\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90354284]\n",
      " [0.87462398]\n",
      " [0.89048138]]\n",
      "Loss: \n",
      "0.00016164361094375885\n",
      "\n",
      "\n",
      "# 542\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90354328]\n",
      " [0.87462346]\n",
      " [0.89048141]]\n",
      "Loss: \n",
      "0.00016163369263594055\n",
      "\n",
      "\n",
      "# 543\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90354372]\n",
      " [0.87462294]\n",
      " [0.89048144]]\n",
      "Loss: \n",
      "0.00016162377725344756\n",
      "\n",
      "\n",
      "# 544\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90354416]\n",
      " [0.87462242]\n",
      " [0.89048147]]\n",
      "Loss: \n",
      "0.00016161386479509346\n",
      "\n",
      "\n",
      "# 545\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.9035446]\n",
      " [0.8746219]\n",
      " [0.8904815]]\n",
      "Loss: \n",
      "0.0001616039552596943\n",
      "\n",
      "\n",
      "# 546\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90354505]\n",
      " [0.87462138]\n",
      " [0.89048154]]\n",
      "Loss: \n",
      "0.00016159404864606202\n",
      "\n",
      "\n",
      "# 547\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90354549]\n",
      " [0.87462086]\n",
      " [0.89048157]]\n",
      "Loss: \n",
      "0.0001615841449530138\n",
      "\n",
      "\n",
      "# 548\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90354593]\n",
      " [0.87462034]\n",
      " [0.8904816 ]]\n",
      "Loss: \n",
      "0.00016157424417936314\n",
      "\n",
      "\n",
      "# 549\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90354637]\n",
      " [0.87461982]\n",
      " [0.89048163]]\n",
      "Loss: \n",
      "0.00016156434632392763\n",
      "\n",
      "\n",
      "# 550\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90354681]\n",
      " [0.8746193 ]\n",
      " [0.89048166]]\n",
      "Loss: \n",
      "0.0001615544513855249\n",
      "\n",
      "\n",
      "# 551\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90354725]\n",
      " [0.87461878]\n",
      " [0.89048169]]\n",
      "Loss: \n",
      "0.00016154455936297395\n",
      "\n",
      "\n",
      "# 552\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90354769]\n",
      " [0.87461826]\n",
      " [0.89048173]]\n",
      "Loss: \n",
      "0.00016153467025509046\n",
      "\n",
      "\n",
      "# 553\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90354813]\n",
      " [0.87461774]\n",
      " [0.89048176]]\n",
      "Loss: \n",
      "0.00016152478406069362\n",
      "\n",
      "\n",
      "# 554\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90354857]\n",
      " [0.87461722]\n",
      " [0.89048179]]\n",
      "Loss: \n",
      "0.0001615149007786077\n",
      "\n",
      "\n",
      "# 555\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90354901]\n",
      " [0.8746167 ]\n",
      " [0.89048182]]\n",
      "Loss: \n",
      "0.00016150502040764787\n",
      "\n",
      "\n",
      "# 556\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90354945]\n",
      " [0.87461618]\n",
      " [0.89048185]]\n",
      "Loss: \n",
      "0.00016149514294663865\n",
      "\n",
      "\n",
      "# 557\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90354989]\n",
      " [0.87461566]\n",
      " [0.89048188]]\n",
      "Loss: \n",
      "0.00016148526839439664\n",
      "\n",
      "\n",
      "# 558\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90355033]\n",
      " [0.87461514]\n",
      " [0.89048192]]\n",
      "Loss: \n",
      "0.00016147539674974572\n",
      "\n",
      "\n",
      "# 559\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90355077]\n",
      " [0.87461462]\n",
      " [0.89048195]]\n",
      "Loss: \n",
      "0.00016146552801151102\n",
      "\n",
      "\n",
      "# 560\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90355121]\n",
      " [0.87461411]\n",
      " [0.89048198]]\n",
      "Loss: \n",
      "0.00016145566217851205\n",
      "\n",
      "\n",
      "# 561\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90355165]\n",
      " [0.87461359]\n",
      " [0.89048201]]\n",
      "Loss: \n",
      "0.00016144579924957548\n",
      "\n",
      "\n",
      "# 562\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90355209]\n",
      " [0.87461307]\n",
      " [0.89048204]]\n",
      "Loss: \n",
      "0.00016143593922352464\n",
      "\n",
      "\n",
      "# 563\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90355253]\n",
      " [0.87461255]\n",
      " [0.89048207]]\n",
      "Loss: \n",
      "0.00016142608209918313\n",
      "\n",
      "\n",
      "# 564\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90355297]\n",
      " [0.87461203]\n",
      " [0.89048211]]\n",
      "Loss: \n",
      "0.00016141622787538032\n",
      "\n",
      "\n",
      "# 565\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90355341]\n",
      " [0.87461152]\n",
      " [0.89048214]]\n",
      "Loss: \n",
      "0.00016140637655093933\n",
      "\n",
      "\n",
      "# 566\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90355385]\n",
      " [0.874611  ]\n",
      " [0.89048217]]\n",
      "Loss: \n",
      "0.00016139652812468524\n",
      "\n",
      "\n",
      "# 567\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90355429]\n",
      " [0.87461048]\n",
      " [0.8904822 ]]\n",
      "Loss: \n",
      "0.00016138668259545034\n",
      "\n",
      "\n",
      "# 568\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90355473]\n",
      " [0.87460996]\n",
      " [0.89048223]]\n",
      "Loss: \n",
      "0.0001613768399620582\n",
      "\n",
      "\n",
      "# 569\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90355517]\n",
      " [0.87460944]\n",
      " [0.89048226]]\n",
      "Loss: \n",
      "0.00016136700022333918\n",
      "\n",
      "\n",
      "# 570\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90355561]\n",
      " [0.87460893]\n",
      " [0.89048229]]\n",
      "Loss: \n",
      "0.00016135716337812252\n",
      "\n",
      "\n",
      "# 571\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90355604]\n",
      " [0.87460841]\n",
      " [0.89048233]]\n",
      "Loss: \n",
      "0.0001613473294252384\n",
      "\n",
      "\n",
      "# 572\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90355648]\n",
      " [0.87460789]\n",
      " [0.89048236]]\n",
      "Loss: \n",
      "0.00016133749836351504\n",
      "\n",
      "\n",
      "# 573\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90355692]\n",
      " [0.87460738]\n",
      " [0.89048239]]\n",
      "Loss: \n",
      "0.00016132767019178606\n",
      "\n",
      "\n",
      "# 574\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90355736]\n",
      " [0.87460686]\n",
      " [0.89048242]]\n",
      "Loss: \n",
      "0.00016131784490888172\n",
      "\n",
      "\n",
      "# 575\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.9035578 ]\n",
      " [0.87460634]\n",
      " [0.89048245]]\n",
      "Loss: \n",
      "0.00016130802251363251\n",
      "\n",
      "\n",
      "# 576\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90355824]\n",
      " [0.87460583]\n",
      " [0.89048248]]\n",
      "Loss: \n",
      "0.00016129820300487578\n",
      "\n",
      "\n",
      "# 577\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90355867]\n",
      " [0.87460531]\n",
      " [0.89048251]]\n",
      "Loss: \n",
      "0.00016128838638143785\n",
      "\n",
      "\n",
      "# 578\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90355911]\n",
      " [0.8746048 ]\n",
      " [0.89048254]]\n",
      "Loss: \n",
      "0.00016127857264215963\n",
      "\n",
      "\n",
      "# 579\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90355955]\n",
      " [0.87460428]\n",
      " [0.89048258]]\n",
      "Loss: \n",
      "0.00016126876178587272\n",
      "\n",
      "\n",
      "# 580\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90355999]\n",
      " [0.87460376]\n",
      " [0.89048261]]\n",
      "Loss: \n",
      "0.00016125895381141037\n",
      "\n",
      "\n",
      "# 581\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90356042]\n",
      " [0.87460325]\n",
      " [0.89048264]]\n",
      "Loss: \n",
      "0.00016124914871761006\n",
      "\n",
      "\n",
      "# 582\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90356086]\n",
      " [0.87460273]\n",
      " [0.89048267]]\n",
      "Loss: \n",
      "0.00016123934650330793\n",
      "\n",
      "\n",
      "# 583\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.9035613 ]\n",
      " [0.87460222]\n",
      " [0.8904827 ]]\n",
      "Loss: \n",
      "0.00016122954716733944\n",
      "\n",
      "\n",
      "# 584\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90356174]\n",
      " [0.8746017 ]\n",
      " [0.89048273]]\n",
      "Loss: \n",
      "0.0001612197507085467\n",
      "\n",
      "\n",
      "# 585\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90356217]\n",
      " [0.87460119]\n",
      " [0.89048276]]\n",
      "Loss: \n",
      "0.00016120995712576083\n",
      "\n",
      "\n",
      "# 586\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90356261]\n",
      " [0.87460067]\n",
      " [0.89048279]]\n",
      "Loss: \n",
      "0.00016120016641782585\n",
      "\n",
      "\n",
      "# 587\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90356305]\n",
      " [0.87460016]\n",
      " [0.89048283]]\n",
      "Loss: \n",
      "0.00016119037858358125\n",
      "\n",
      "\n",
      "# 588\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90356348]\n",
      " [0.87459964]\n",
      " [0.89048286]]\n",
      "Loss: \n",
      "0.00016118059362186203\n",
      "\n",
      "\n",
      "# 589\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90356392]\n",
      " [0.87459913]\n",
      " [0.89048289]]\n",
      "Loss: \n",
      "0.00016117081153150912\n",
      "\n",
      "\n",
      "# 590\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90356436]\n",
      " [0.87459861]\n",
      " [0.89048292]]\n",
      "Loss: \n",
      "0.00016116103231137054\n",
      "\n",
      "\n",
      "# 591\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90356479]\n",
      " [0.8745981 ]\n",
      " [0.89048295]]\n",
      "Loss: \n",
      "0.00016115125596027942\n",
      "\n",
      "\n",
      "# 592\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90356523]\n",
      " [0.87459759]\n",
      " [0.89048298]]\n",
      "Loss: \n",
      "0.00016114148247708238\n",
      "\n",
      "\n",
      "# 593\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90356567]\n",
      " [0.87459707]\n",
      " [0.89048301]]\n",
      "Loss: \n",
      "0.00016113171186062062\n",
      "\n",
      "\n",
      "# 594\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.9035661 ]\n",
      " [0.87459656]\n",
      " [0.89048304]]\n",
      "Loss: \n",
      "0.00016112194410973824\n",
      "\n",
      "\n",
      "# 595\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90356654]\n",
      " [0.87459604]\n",
      " [0.89048308]]\n",
      "Loss: \n",
      "0.00016111217922328008\n",
      "\n",
      "\n",
      "# 596\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90356697]\n",
      " [0.87459553]\n",
      " [0.89048311]]\n",
      "Loss: \n",
      "0.00016110241720008675\n",
      "\n",
      "\n",
      "# 597\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90356741]\n",
      " [0.87459502]\n",
      " [0.89048314]]\n",
      "Loss: \n",
      "0.00016109265803900894\n",
      "\n",
      "\n",
      "# 598\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90356785]\n",
      " [0.8745945 ]\n",
      " [0.89048317]]\n",
      "Loss: \n",
      "0.00016108290173888682\n",
      "\n",
      "\n",
      "# 599\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90356828]\n",
      " [0.87459399]\n",
      " [0.8904832 ]]\n",
      "Loss: \n",
      "0.0001610731482985724\n",
      "\n",
      "\n",
      "# 600\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90356872]\n",
      " [0.87459348]\n",
      " [0.89048323]]\n",
      "Loss: \n",
      "0.0001610633977169072\n",
      "\n",
      "\n",
      "# 601\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90356915]\n",
      " [0.87459297]\n",
      " [0.89048326]]\n",
      "Loss: \n",
      "0.0001610536499927402\n",
      "\n",
      "\n",
      "# 602\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90356959]\n",
      " [0.87459245]\n",
      " [0.89048329]]\n",
      "Loss: \n",
      "0.00016104390512491833\n",
      "\n",
      "\n",
      "# 603\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90357002]\n",
      " [0.87459194]\n",
      " [0.89048332]]\n",
      "Loss: \n",
      "0.00016103416311229397\n",
      "\n",
      "\n",
      "# 604\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90357046]\n",
      " [0.87459143]\n",
      " [0.89048335]]\n",
      "Loss: \n",
      "0.00016102442395371543\n",
      "\n",
      "\n",
      "# 605\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90357089]\n",
      " [0.87459092]\n",
      " [0.89048339]]\n",
      "Loss: \n",
      "0.00016101468764802992\n",
      "\n",
      "\n",
      "# 606\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90357133]\n",
      " [0.8745904 ]\n",
      " [0.89048342]]\n",
      "Loss: \n",
      "0.00016100495419408824\n",
      "\n",
      "\n",
      "# 607\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90357176]\n",
      " [0.87458989]\n",
      " [0.89048345]]\n",
      "Loss: \n",
      "0.00016099522359074147\n",
      "\n",
      "\n",
      "# 608\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.9035722 ]\n",
      " [0.87458938]\n",
      " [0.89048348]]\n",
      "Loss: \n",
      "0.00016098549583684344\n",
      "\n",
      "\n",
      "# 609\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90357263]\n",
      " [0.87458887]\n",
      " [0.89048351]]\n",
      "Loss: \n",
      "0.00016097577093124264\n",
      "\n",
      "\n",
      "# 610\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90357306]\n",
      " [0.87458836]\n",
      " [0.89048354]]\n",
      "Loss: \n",
      "0.0001609660488727933\n",
      "\n",
      "\n",
      "# 611\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.9035735 ]\n",
      " [0.87458784]\n",
      " [0.89048357]]\n",
      "Loss: \n",
      "0.00016095632966034936\n",
      "\n",
      "\n",
      "# 612\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90357393]\n",
      " [0.87458733]\n",
      " [0.8904836 ]]\n",
      "Loss: \n",
      "0.0001609466132927641\n",
      "\n",
      "\n",
      "# 613\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90357437]\n",
      " [0.87458682]\n",
      " [0.89048363]]\n",
      "Loss: \n",
      "0.00016093689976889367\n",
      "\n",
      "\n",
      "# 614\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.9035748 ]\n",
      " [0.87458631]\n",
      " [0.89048366]]\n",
      "Loss: \n",
      "0.0001609271890875873\n",
      "\n",
      "\n",
      "# 615\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90357524]\n",
      " [0.8745858 ]\n",
      " [0.89048369]]\n",
      "Loss: \n",
      "0.00016091748124770768\n",
      "\n",
      "\n",
      "# 616\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90357567]\n",
      " [0.87458529]\n",
      " [0.89048373]]\n",
      "Loss: \n",
      "0.00016090777624810622\n",
      "\n",
      "\n",
      "# 617\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.9035761 ]\n",
      " [0.87458478]\n",
      " [0.89048376]]\n",
      "Loss: \n",
      "0.00016089807408764133\n",
      "\n",
      "\n",
      "# 618\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90357654]\n",
      " [0.87458427]\n",
      " [0.89048379]]\n",
      "Loss: \n",
      "0.00016088837476516954\n",
      "\n",
      "\n",
      "# 619\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90357697]\n",
      " [0.87458376]\n",
      " [0.89048382]]\n",
      "Loss: \n",
      "0.00016087867827954967\n",
      "\n",
      "\n",
      "# 620\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.9035774 ]\n",
      " [0.87458325]\n",
      " [0.89048385]]\n",
      "Loss: \n",
      "0.00016086898462963845\n",
      "\n",
      "\n",
      "# 621\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90357784]\n",
      " [0.87458274]\n",
      " [0.89048388]]\n",
      "Loss: \n",
      "0.0001608592938142996\n",
      "\n",
      "\n",
      "# 622\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90357827]\n",
      " [0.87458223]\n",
      " [0.89048391]]\n",
      "Loss: \n",
      "0.00016084960583238683\n",
      "\n",
      "\n",
      "# 623\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.9035787 ]\n",
      " [0.87458172]\n",
      " [0.89048394]]\n",
      "Loss: \n",
      "0.0001608399206827632\n",
      "\n",
      "\n",
      "# 624\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90357913]\n",
      " [0.87458121]\n",
      " [0.89048397]]\n",
      "Loss: \n",
      "0.0001608302383642905\n",
      "\n",
      "\n",
      "# 625\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90357957]\n",
      " [0.8745807 ]\n",
      " [0.890484  ]]\n",
      "Loss: \n",
      "0.00016082055887582536\n",
      "\n",
      "\n",
      "# 626\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90358   ]\n",
      " [0.87458019]\n",
      " [0.89048403]]\n",
      "Loss: \n",
      "0.00016081088221623694\n",
      "\n",
      "\n",
      "# 627\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90358043]\n",
      " [0.87457968]\n",
      " [0.89048406]]\n",
      "Loss: \n",
      "0.00016080120838437849\n",
      "\n",
      "\n",
      "# 628\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90358087]\n",
      " [0.87457917]\n",
      " [0.89048409]]\n",
      "Loss: \n",
      "0.00016079153737912096\n",
      "\n",
      "\n",
      "# 629\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.9035813 ]\n",
      " [0.87457866]\n",
      " [0.89048412]]\n",
      "Loss: \n",
      "0.00016078186919932716\n",
      "\n",
      "\n",
      "# 630\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90358173]\n",
      " [0.87457816]\n",
      " [0.89048416]]\n",
      "Loss: \n",
      "0.0001607722038438565\n",
      "\n",
      "\n",
      "# 631\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90358216]\n",
      " [0.87457765]\n",
      " [0.89048419]]\n",
      "Loss: \n",
      "0.00016076254131157798\n",
      "\n",
      "\n",
      "# 632\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90358259]\n",
      " [0.87457714]\n",
      " [0.89048422]]\n",
      "Loss: \n",
      "0.00016075288160135283\n",
      "\n",
      "\n",
      "# 633\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90358303]\n",
      " [0.87457663]\n",
      " [0.89048425]]\n",
      "Loss: \n",
      "0.00016074322471205143\n",
      "\n",
      "\n",
      "# 634\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90358346]\n",
      " [0.87457612]\n",
      " [0.89048428]]\n",
      "Loss: \n",
      "0.00016073357064253852\n",
      "\n",
      "\n",
      "# 635\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90358389]\n",
      " [0.87457561]\n",
      " [0.89048431]]\n",
      "Loss: \n",
      "0.00016072391939168153\n",
      "\n",
      "\n",
      "# 636\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90358432]\n",
      " [0.87457511]\n",
      " [0.89048434]]\n",
      "Loss: \n",
      "0.00016071427095834897\n",
      "\n",
      "\n",
      "# 637\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90358475]\n",
      " [0.8745746 ]\n",
      " [0.89048437]]\n",
      "Loss: \n",
      "0.00016070462534140424\n",
      "\n",
      "\n",
      "# 638\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90358518]\n",
      " [0.87457409]\n",
      " [0.8904844 ]]\n",
      "Loss: \n",
      "0.00016069498253972305\n",
      "\n",
      "\n",
      "# 639\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90358561]\n",
      " [0.87457358]\n",
      " [0.89048443]]\n",
      "Loss: \n",
      "0.00016068534255216964\n",
      "\n",
      "\n",
      "# 640\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90358605]\n",
      " [0.87457308]\n",
      " [0.89048446]]\n",
      "Loss: \n",
      "0.00016067570537761498\n",
      "\n",
      "\n",
      "# 641\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90358648]\n",
      " [0.87457257]\n",
      " [0.89048449]]\n",
      "Loss: \n",
      "0.00016066607101493057\n",
      "\n",
      "\n",
      "# 642\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90358691]\n",
      " [0.87457206]\n",
      " [0.89048452]]\n",
      "Loss: \n",
      "0.00016065643946298604\n",
      "\n",
      "\n",
      "# 643\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90358734]\n",
      " [0.87457155]\n",
      " [0.89048455]]\n",
      "Loss: \n",
      "0.000160646810720656\n",
      "\n",
      "\n",
      "# 644\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90358777]\n",
      " [0.87457105]\n",
      " [0.89048458]]\n",
      "Loss: \n",
      "0.00016063718478680805\n",
      "\n",
      "\n",
      "# 645\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.9035882 ]\n",
      " [0.87457054]\n",
      " [0.89048461]]\n",
      "Loss: \n",
      "0.00016062756166031794\n",
      "\n",
      "\n",
      "# 646\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90358863]\n",
      " [0.87457003]\n",
      " [0.89048464]]\n",
      "Loss: \n",
      "0.00016061794134005863\n",
      "\n",
      "\n",
      "# 647\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90358906]\n",
      " [0.87456953]\n",
      " [0.89048467]]\n",
      "Loss: \n",
      "0.00016060832382490492\n",
      "\n",
      "\n",
      "# 648\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90358949]\n",
      " [0.87456902]\n",
      " [0.8904847 ]]\n",
      "Loss: \n",
      "0.000160598709113731\n",
      "\n",
      "\n",
      "# 649\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90358992]\n",
      " [0.87456852]\n",
      " [0.89048473]]\n",
      "Loss: \n",
      "0.000160589097205409\n",
      "\n",
      "\n",
      "# 650\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90359035]\n",
      " [0.87456801]\n",
      " [0.89048477]]\n",
      "Loss: \n",
      "0.0001605794880988178\n",
      "\n",
      "\n",
      "# 651\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90359078]\n",
      " [0.8745675 ]\n",
      " [0.8904848 ]]\n",
      "Loss: \n",
      "0.00016056988179283322\n",
      "\n",
      "\n",
      "# 652\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90359121]\n",
      " [0.874567  ]\n",
      " [0.89048483]]\n",
      "Loss: \n",
      "0.0001605602782863277\n",
      "\n",
      "\n",
      "# 653\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90359164]\n",
      " [0.87456649]\n",
      " [0.89048486]]\n",
      "Loss: \n",
      "0.00016055067757818426\n",
      "\n",
      "\n",
      "# 654\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90359207]\n",
      " [0.87456599]\n",
      " [0.89048489]]\n",
      "Loss: \n",
      "0.00016054107966727906\n",
      "\n",
      "\n",
      "# 655\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.9035925 ]\n",
      " [0.87456548]\n",
      " [0.89048492]]\n",
      "Loss: \n",
      "0.00016053148455248882\n",
      "\n",
      "\n",
      "# 656\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90359293]\n",
      " [0.87456498]\n",
      " [0.89048495]]\n",
      "Loss: \n",
      "0.00016052189223269198\n",
      "\n",
      "\n",
      "# 657\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90359336]\n",
      " [0.87456447]\n",
      " [0.89048498]]\n",
      "Loss: \n",
      "0.00016051230270677262\n",
      "\n",
      "\n",
      "# 658\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90359379]\n",
      " [0.87456397]\n",
      " [0.89048501]]\n",
      "Loss: \n",
      "0.0001605027159736074\n",
      "\n",
      "\n",
      "# 659\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90359422]\n",
      " [0.87456346]\n",
      " [0.89048504]]\n",
      "Loss: \n",
      "0.00016049313203207592\n",
      "\n",
      "\n",
      "# 660\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90359465]\n",
      " [0.87456296]\n",
      " [0.89048507]]\n",
      "Loss: \n",
      "0.0001604835508810609\n",
      "\n",
      "\n",
      "# 661\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90359508]\n",
      " [0.87456245]\n",
      " [0.8904851 ]]\n",
      "Loss: \n",
      "0.00016047397251944568\n",
      "\n",
      "\n",
      "# 662\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.9035955 ]\n",
      " [0.87456195]\n",
      " [0.89048513]]\n",
      "Loss: \n",
      "0.00016046439694611132\n",
      "\n",
      "\n",
      "# 663\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90359593]\n",
      " [0.87456145]\n",
      " [0.89048516]]\n",
      "Loss: \n",
      "0.00016045482415994022\n",
      "\n",
      "\n",
      "# 664\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90359636]\n",
      " [0.87456094]\n",
      " [0.89048519]]\n",
      "Loss: \n",
      "0.00016044525415981686\n",
      "\n",
      "\n",
      "# 665\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90359679]\n",
      " [0.87456044]\n",
      " [0.89048522]]\n",
      "Loss: \n",
      "0.00016043568694462096\n",
      "\n",
      "\n",
      "# 666\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90359722]\n",
      " [0.87455993]\n",
      " [0.89048525]]\n",
      "Loss: \n",
      "0.0001604261225132454\n",
      "\n",
      "\n",
      "# 667\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90359765]\n",
      " [0.87455943]\n",
      " [0.89048528]]\n",
      "Loss: \n",
      "0.00016041656086456725\n",
      "\n",
      "\n",
      "# 668\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90359808]\n",
      " [0.87455893]\n",
      " [0.89048531]]\n",
      "Loss: \n",
      "0.0001604070019974782\n",
      "\n",
      "\n",
      "# 669\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.9035985 ]\n",
      " [0.87455842]\n",
      " [0.89048534]]\n",
      "Loss: \n",
      "0.0001603974459108612\n",
      "\n",
      "\n",
      "# 670\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90359893]\n",
      " [0.87455792]\n",
      " [0.89048537]]\n",
      "Loss: \n",
      "0.00016038789260360586\n",
      "\n",
      "\n",
      "# 671\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90359936]\n",
      " [0.87455742]\n",
      " [0.8904854 ]]\n",
      "Loss: \n",
      "0.00016037834207459446\n",
      "\n",
      "\n",
      "# 672\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90359979]\n",
      " [0.87455691]\n",
      " [0.89048543]]\n",
      "Loss: \n",
      "0.00016036879432272105\n",
      "\n",
      "\n",
      "# 673\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90360021]\n",
      " [0.87455641]\n",
      " [0.89048546]]\n",
      "Loss: \n",
      "0.00016035924934686764\n",
      "\n",
      "\n",
      "# 674\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90360064]\n",
      " [0.87455591]\n",
      " [0.89048549]]\n",
      "Loss: \n",
      "0.0001603497071459307\n",
      "\n",
      "\n",
      "# 675\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90360107]\n",
      " [0.87455541]\n",
      " [0.89048552]]\n",
      "Loss: \n",
      "0.00016034016771879605\n",
      "\n",
      "\n",
      "# 676\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.9036015 ]\n",
      " [0.8745549 ]\n",
      " [0.89048555]]\n",
      "Loss: \n",
      "0.0001603306310643524\n",
      "\n",
      "\n",
      "# 677\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90360192]\n",
      " [0.8745544 ]\n",
      " [0.89048558]]\n",
      "Loss: \n",
      "0.00016032109718149264\n",
      "\n",
      "\n",
      "# 678\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90360235]\n",
      " [0.8745539 ]\n",
      " [0.89048561]]\n",
      "Loss: \n",
      "0.00016031156606910736\n",
      "\n",
      "\n",
      "# 679\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90360278]\n",
      " [0.8745534 ]\n",
      " [0.89048564]]\n",
      "Loss: \n",
      "0.00016030203772608611\n",
      "\n",
      "\n",
      "# 680\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.9036032 ]\n",
      " [0.8745529 ]\n",
      " [0.89048567]]\n",
      "Loss: \n",
      "0.00016029251215132767\n",
      "\n",
      "\n",
      "# 681\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90360363]\n",
      " [0.87455239]\n",
      " [0.8904857 ]]\n",
      "Loss: \n",
      "0.00016028298934372105\n",
      "\n",
      "\n",
      "# 682\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90360406]\n",
      " [0.87455189]\n",
      " [0.89048573]]\n",
      "Loss: \n",
      "0.00016027346930215836\n",
      "\n",
      "\n",
      "# 683\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90360449]\n",
      " [0.87455139]\n",
      " [0.89048576]]\n",
      "Loss: \n",
      "0.00016026395202553562\n",
      "\n",
      "\n",
      "# 684\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90360491]\n",
      " [0.87455089]\n",
      " [0.89048579]]\n",
      "Loss: \n",
      "0.00016025443751274565\n",
      "\n",
      "\n",
      "# 685\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90360534]\n",
      " [0.87455039]\n",
      " [0.89048582]]\n",
      "Loss: \n",
      "0.00016024492576268906\n",
      "\n",
      "\n",
      "# 686\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90360576]\n",
      " [0.87454989]\n",
      " [0.89048585]]\n",
      "Loss: \n",
      "0.00016023541677425348\n",
      "\n",
      "\n",
      "# 687\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90360619]\n",
      " [0.87454939]\n",
      " [0.89048588]]\n",
      "Loss: \n",
      "0.00016022591054634203\n",
      "\n",
      "\n",
      "# 688\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90360662]\n",
      " [0.87454889]\n",
      " [0.89048591]]\n",
      "Loss: \n",
      "0.0001602164070778471\n",
      "\n",
      "\n",
      "# 689\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90360704]\n",
      " [0.87454839]\n",
      " [0.89048594]]\n",
      "Loss: \n",
      "0.00016020690636767037\n",
      "\n",
      "\n",
      "# 690\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90360747]\n",
      " [0.87454789]\n",
      " [0.89048597]]\n",
      "Loss: \n",
      "0.00016019740841470516\n",
      "\n",
      "\n",
      "# 691\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90360789]\n",
      " [0.87454738]\n",
      " [0.890486  ]]\n",
      "Loss: \n",
      "0.00016018791321785358\n",
      "\n",
      "\n",
      "# 692\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90360832]\n",
      " [0.87454688]\n",
      " [0.89048603]]\n",
      "Loss: \n",
      "0.0001601784207760117\n",
      "\n",
      "\n",
      "# 693\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90360875]\n",
      " [0.87454638]\n",
      " [0.89048606]]\n",
      "Loss: \n",
      "0.00016016893108808196\n",
      "\n",
      "\n",
      "# 694\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90360917]\n",
      " [0.87454588]\n",
      " [0.89048609]]\n",
      "Loss: \n",
      "0.00016015944415296527\n",
      "\n",
      "\n",
      "# 695\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.9036096 ]\n",
      " [0.87454539]\n",
      " [0.89048612]]\n",
      "Loss: \n",
      "0.0001601499599695575\n",
      "\n",
      "\n",
      "# 696\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90361002]\n",
      " [0.87454489]\n",
      " [0.89048615]]\n",
      "Loss: \n",
      "0.00016014047853676343\n",
      "\n",
      "\n",
      "# 697\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90361045]\n",
      " [0.87454439]\n",
      " [0.89048618]]\n",
      "Loss: \n",
      "0.0001601309998534871\n",
      "\n",
      "\n",
      "# 698\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90361087]\n",
      " [0.87454389]\n",
      " [0.89048621]]\n",
      "Loss: \n",
      "0.00016012152391862454\n",
      "\n",
      "\n",
      "# 699\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.9036113 ]\n",
      " [0.87454339]\n",
      " [0.89048624]]\n",
      "Loss: \n",
      "0.00016011205073108474\n",
      "\n",
      "\n",
      "# 700\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90361172]\n",
      " [0.87454289]\n",
      " [0.89048627]]\n",
      "Loss: \n",
      "0.00016010258028976987\n",
      "\n",
      "\n",
      "# 701\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90361215]\n",
      " [0.87454239]\n",
      " [0.8904863 ]]\n",
      "Loss: \n",
      "0.00016009311259357966\n",
      "\n",
      "\n",
      "# 702\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90361257]\n",
      " [0.87454189]\n",
      " [0.89048633]]\n",
      "Loss: \n",
      "0.00016008364764142513\n",
      "\n",
      "\n",
      "# 703\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90361299]\n",
      " [0.87454139]\n",
      " [0.89048636]]\n",
      "Loss: \n",
      "0.00016007418543220484\n",
      "\n",
      "\n",
      "# 704\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90361342]\n",
      " [0.87454089]\n",
      " [0.89048639]]\n",
      "Loss: \n",
      "0.0001600647259648313\n",
      "\n",
      "\n",
      "# 705\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90361384]\n",
      " [0.8745404 ]\n",
      " [0.89048642]]\n",
      "Loss: \n",
      "0.0001600552692382064\n",
      "\n",
      "\n",
      "# 706\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90361427]\n",
      " [0.8745399 ]\n",
      " [0.89048645]]\n",
      "Loss: \n",
      "0.0001600458152512361\n",
      "\n",
      "\n",
      "# 707\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90361469]\n",
      " [0.8745394 ]\n",
      " [0.89048648]]\n",
      "Loss: \n",
      "0.00016003636400282995\n",
      "\n",
      "\n",
      "# 708\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90361512]\n",
      " [0.8745389 ]\n",
      " [0.8904865 ]]\n",
      "Loss: \n",
      "0.00016002691549189574\n",
      "\n",
      "\n",
      "# 709\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90361554]\n",
      " [0.8745384 ]\n",
      " [0.89048653]]\n",
      "Loss: \n",
      "0.00016001746971734164\n",
      "\n",
      "\n",
      "# 710\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90361596]\n",
      " [0.87453791]\n",
      " [0.89048656]]\n",
      "Loss: \n",
      "0.00016000802667807384\n",
      "\n",
      "\n",
      "# 711\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90361639]\n",
      " [0.87453741]\n",
      " [0.89048659]]\n",
      "Loss: \n",
      "0.00015999858637300883\n",
      "\n",
      "\n",
      "# 712\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90361681]\n",
      " [0.87453691]\n",
      " [0.89048662]]\n",
      "Loss: \n",
      "0.00015998914880104834\n",
      "\n",
      "\n",
      "# 713\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90361723]\n",
      " [0.87453641]\n",
      " [0.89048665]]\n",
      "Loss: \n",
      "0.00015997971396110807\n",
      "\n",
      "\n",
      "# 714\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90361766]\n",
      " [0.87453592]\n",
      " [0.89048668]]\n",
      "Loss: \n",
      "0.00015997028185209833\n",
      "\n",
      "\n",
      "# 715\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90361808]\n",
      " [0.87453542]\n",
      " [0.89048671]]\n",
      "Loss: \n",
      "0.00015996085247293155\n",
      "\n",
      "\n",
      "# 716\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.9036185 ]\n",
      " [0.87453492]\n",
      " [0.89048674]]\n",
      "Loss: \n",
      "0.00015995142582252037\n",
      "\n",
      "\n",
      "# 717\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90361893]\n",
      " [0.87453442]\n",
      " [0.89048677]]\n",
      "Loss: \n",
      "0.00015994200189976994\n",
      "\n",
      "\n",
      "# 718\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90361935]\n",
      " [0.87453393]\n",
      " [0.8904868 ]]\n",
      "Loss: \n",
      "0.00015993258070360583\n",
      "\n",
      "\n",
      "# 719\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90361977]\n",
      " [0.87453343]\n",
      " [0.89048683]]\n",
      "Loss: \n",
      "0.0001599231622329319\n",
      "\n",
      "\n",
      "# 720\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.9036202 ]\n",
      " [0.87453294]\n",
      " [0.89048686]]\n",
      "Loss: \n",
      "0.00015991374648666756\n",
      "\n",
      "\n",
      "# 721\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90362062]\n",
      " [0.87453244]\n",
      " [0.89048689]]\n",
      "Loss: \n",
      "0.00015990433346372974\n",
      "\n",
      "\n",
      "# 722\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90362104]\n",
      " [0.87453194]\n",
      " [0.89048692]]\n",
      "Loss: \n",
      "0.00015989492316302625\n",
      "\n",
      "\n",
      "# 723\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90362146]\n",
      " [0.87453145]\n",
      " [0.89048695]]\n",
      "Loss: \n",
      "0.00015988551558347998\n",
      "\n",
      "\n",
      "# 724\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90362189]\n",
      " [0.87453095]\n",
      " [0.89048698]]\n",
      "Loss: \n",
      "0.00015987611072400555\n",
      "\n",
      "\n",
      "# 725\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90362231]\n",
      " [0.87453046]\n",
      " [0.89048701]]\n",
      "Loss: \n",
      "0.00015986670858351875\n",
      "\n",
      "\n",
      "# 726\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90362273]\n",
      " [0.87452996]\n",
      " [0.89048704]]\n",
      "Loss: \n",
      "0.00015985730916093997\n",
      "\n",
      "\n",
      "# 727\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90362315]\n",
      " [0.87452946]\n",
      " [0.89048707]]\n",
      "Loss: \n",
      "0.00015984791245518242\n",
      "\n",
      "\n",
      "# 728\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90362357]\n",
      " [0.87452897]\n",
      " [0.89048709]]\n",
      "Loss: \n",
      "0.00015983851846517027\n",
      "\n",
      "\n",
      "# 729\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.903624  ]\n",
      " [0.87452847]\n",
      " [0.89048712]]\n",
      "Loss: \n",
      "0.00015982912718981893\n",
      "\n",
      "\n",
      "# 730\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90362442]\n",
      " [0.87452798]\n",
      " [0.89048715]]\n",
      "Loss: \n",
      "0.00015981973862805307\n",
      "\n",
      "\n",
      "# 731\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90362484]\n",
      " [0.87452748]\n",
      " [0.89048718]]\n",
      "Loss: \n",
      "0.00015981035277878736\n",
      "\n",
      "\n",
      "# 732\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90362526]\n",
      " [0.87452699]\n",
      " [0.89048721]]\n",
      "Loss: \n",
      "0.00015980096964094643\n",
      "\n",
      "\n",
      "# 733\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90362568]\n",
      " [0.8745265 ]\n",
      " [0.89048724]]\n",
      "Loss: \n",
      "0.00015979158921345263\n",
      "\n",
      "\n",
      "# 734\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.9036261 ]\n",
      " [0.874526  ]\n",
      " [0.89048727]]\n",
      "Loss: \n",
      "0.00015978221149522275\n",
      "\n",
      "\n",
      "# 735\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90362652]\n",
      " [0.87452551]\n",
      " [0.8904873 ]]\n",
      "Loss: \n",
      "0.0001597728364851838\n",
      "\n",
      "\n",
      "# 736\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90362695]\n",
      " [0.87452501]\n",
      " [0.89048733]]\n",
      "Loss: \n",
      "0.00015976346418225635\n",
      "\n",
      "\n",
      "# 737\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90362737]\n",
      " [0.87452452]\n",
      " [0.89048736]]\n",
      "Loss: \n",
      "0.00015975409458536812\n",
      "\n",
      "\n",
      "# 738\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90362779]\n",
      " [0.87452402]\n",
      " [0.89048739]]\n",
      "Loss: \n",
      "0.00015974472769343735\n",
      "\n",
      "\n",
      "# 739\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90362821]\n",
      " [0.87452353]\n",
      " [0.89048742]]\n",
      "Loss: \n",
      "0.0001597353635053921\n",
      "\n",
      "\n",
      "# 740\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90362863]\n",
      " [0.87452304]\n",
      " [0.89048745]]\n",
      "Loss: \n",
      "0.00015972600202016012\n",
      "\n",
      "\n",
      "# 741\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90362905]\n",
      " [0.87452254]\n",
      " [0.89048748]]\n",
      "Loss: \n",
      "0.00015971664323666048\n",
      "\n",
      "\n",
      "# 742\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90362947]\n",
      " [0.87452205]\n",
      " [0.8904875 ]]\n",
      "Loss: \n",
      "0.00015970728715382514\n",
      "\n",
      "\n",
      "# 743\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90362989]\n",
      " [0.87452156]\n",
      " [0.89048753]]\n",
      "Loss: \n",
      "0.00015969793377057547\n",
      "\n",
      "\n",
      "# 744\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90363031]\n",
      " [0.87452106]\n",
      " [0.89048756]]\n",
      "Loss: \n",
      "0.00015968858308584562\n",
      "\n",
      "\n",
      "# 745\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90363073]\n",
      " [0.87452057]\n",
      " [0.89048759]]\n",
      "Loss: \n",
      "0.0001596792350985602\n",
      "\n",
      "\n",
      "# 746\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90363115]\n",
      " [0.87452008]\n",
      " [0.89048762]]\n",
      "Loss: \n",
      "0.00015966988980764456\n",
      "\n",
      "\n",
      "# 747\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90363157]\n",
      " [0.87451958]\n",
      " [0.89048765]]\n",
      "Loss: \n",
      "0.00015966054721203442\n",
      "\n",
      "\n",
      "# 748\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90363199]\n",
      " [0.87451909]\n",
      " [0.89048768]]\n",
      "Loss: \n",
      "0.00015965120731065372\n",
      "\n",
      "\n",
      "# 749\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90363241]\n",
      " [0.8745186 ]\n",
      " [0.89048771]]\n",
      "Loss: \n",
      "0.00015964187010243032\n",
      "\n",
      "\n",
      "# 750\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90363283]\n",
      " [0.87451811]\n",
      " [0.89048774]]\n",
      "Loss: \n",
      "0.00015963253558630541\n",
      "\n",
      "\n",
      "# 751\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90363325]\n",
      " [0.87451762]\n",
      " [0.89048777]]\n",
      "Loss: \n",
      "0.00015962320376120077\n",
      "\n",
      "\n",
      "# 752\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90363367]\n",
      " [0.87451712]\n",
      " [0.8904878 ]]\n",
      "Loss: \n",
      "0.0001596138746260483\n",
      "\n",
      "\n",
      "# 753\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90363409]\n",
      " [0.87451663]\n",
      " [0.89048782]]\n",
      "Loss: \n",
      "0.00015960454817978603\n",
      "\n",
      "\n",
      "# 754\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90363451]\n",
      " [0.87451614]\n",
      " [0.89048785]]\n",
      "Loss: \n",
      "0.0001595952244213399\n",
      "\n",
      "\n",
      "# 755\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90363493]\n",
      " [0.87451565]\n",
      " [0.89048788]]\n",
      "Loss: \n",
      "0.00015958590334964922\n",
      "\n",
      "\n",
      "# 756\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90363534]\n",
      " [0.87451516]\n",
      " [0.89048791]]\n",
      "Loss: \n",
      "0.00015957658496364193\n",
      "\n",
      "\n",
      "# 757\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90363576]\n",
      " [0.87451466]\n",
      " [0.89048794]]\n",
      "Loss: \n",
      "0.00015956726926225577\n",
      "\n",
      "\n",
      "# 758\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90363618]\n",
      " [0.87451417]\n",
      " [0.89048797]]\n",
      "Loss: \n",
      "0.0001595579562444273\n",
      "\n",
      "\n",
      "# 759\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.9036366 ]\n",
      " [0.87451368]\n",
      " [0.890488  ]]\n",
      "Loss: \n",
      "0.0001595486459090874\n",
      "\n",
      "\n",
      "# 760\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90363702]\n",
      " [0.87451319]\n",
      " [0.89048803]]\n",
      "Loss: \n",
      "0.00015953933825517392\n",
      "\n",
      "\n",
      "# 761\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90363744]\n",
      " [0.8745127 ]\n",
      " [0.89048806]]\n",
      "Loss: \n",
      "0.00015953003328162167\n",
      "\n",
      "\n",
      "# 762\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90363786]\n",
      " [0.87451221]\n",
      " [0.89048809]]\n",
      "Loss: \n",
      "0.00015952073098737354\n",
      "\n",
      "\n",
      "# 763\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90363828]\n",
      " [0.87451172]\n",
      " [0.89048811]]\n",
      "Loss: \n",
      "0.00015951143137136103\n",
      "\n",
      "\n",
      "# 764\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90363869]\n",
      " [0.87451123]\n",
      " [0.89048814]]\n",
      "Loss: \n",
      "0.0001595021344325239\n",
      "\n",
      "\n",
      "# 765\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90363911]\n",
      " [0.87451074]\n",
      " [0.89048817]]\n",
      "Loss: \n",
      "0.00015949284016979743\n",
      "\n",
      "\n",
      "# 766\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90363953]\n",
      " [0.87451025]\n",
      " [0.8904882 ]]\n",
      "Loss: \n",
      "0.00015948354858212973\n",
      "\n",
      "\n",
      "# 767\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90363995]\n",
      " [0.87450976]\n",
      " [0.89048823]]\n",
      "Loss: \n",
      "0.00015947425966844945\n",
      "\n",
      "\n",
      "# 768\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90364037]\n",
      " [0.87450927]\n",
      " [0.89048826]]\n",
      "Loss: \n",
      "0.0001594649734277026\n",
      "\n",
      "\n",
      "# 769\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90364078]\n",
      " [0.87450878]\n",
      " [0.89048829]]\n",
      "Loss: \n",
      "0.00015945568985882875\n",
      "\n",
      "\n",
      "# 770\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.9036412 ]\n",
      " [0.87450829]\n",
      " [0.89048832]]\n",
      "Loss: \n",
      "0.00015944640896077084\n",
      "\n",
      "\n",
      "# 771\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90364162]\n",
      " [0.8745078 ]\n",
      " [0.89048835]]\n",
      "Loss: \n",
      "0.00015943713073246818\n",
      "\n",
      "\n",
      "# 772\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90364204]\n",
      " [0.87450731]\n",
      " [0.89048837]]\n",
      "Loss: \n",
      "0.00015942785517286548\n",
      "\n",
      "\n",
      "# 773\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90364245]\n",
      " [0.87450682]\n",
      " [0.8904884 ]]\n",
      "Loss: \n",
      "0.00015941858228090146\n",
      "\n",
      "\n",
      "# 774\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90364287]\n",
      " [0.87450633]\n",
      " [0.89048843]]\n",
      "Loss: \n",
      "0.00015940931205551959\n",
      "\n",
      "\n",
      "# 775\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90364329]\n",
      " [0.87450584]\n",
      " [0.89048846]]\n",
      "Loss: \n",
      "0.00015940004449566938\n",
      "\n",
      "\n",
      "# 776\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.9036437 ]\n",
      " [0.87450535]\n",
      " [0.89048849]]\n",
      "Loss: \n",
      "0.0001593907796002902\n",
      "\n",
      "\n",
      "# 777\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90364412]\n",
      " [0.87450486]\n",
      " [0.89048852]]\n",
      "Loss: \n",
      "0.00015938151736832944\n",
      "\n",
      "\n",
      "# 778\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90364454]\n",
      " [0.87450438]\n",
      " [0.89048855]]\n",
      "Loss: \n",
      "0.00015937225779873005\n",
      "\n",
      "\n",
      "# 779\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90364495]\n",
      " [0.87450389]\n",
      " [0.89048858]]\n",
      "Loss: \n",
      "0.0001593630008904362\n",
      "\n",
      "\n",
      "# 780\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90364537]\n",
      " [0.8745034 ]\n",
      " [0.8904886 ]]\n",
      "Loss: \n",
      "0.00015935374664240179\n",
      "\n",
      "\n",
      "# 781\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90364579]\n",
      " [0.87450291]\n",
      " [0.89048863]]\n",
      "Loss: \n",
      "0.00015934449505356678\n",
      "\n",
      "\n",
      "# 782\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.9036462 ]\n",
      " [0.87450242]\n",
      " [0.89048866]]\n",
      "Loss: \n",
      "0.0001593352461228793\n",
      "\n",
      "\n",
      "# 783\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90364662]\n",
      " [0.87450194]\n",
      " [0.89048869]]\n",
      "Loss: \n",
      "0.0001593259998492911\n",
      "\n",
      "\n",
      "# 784\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90364704]\n",
      " [0.87450145]\n",
      " [0.89048872]]\n",
      "Loss: \n",
      "0.00015931675623174875\n",
      "\n",
      "\n",
      "# 785\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90364745]\n",
      " [0.87450096]\n",
      " [0.89048875]]\n",
      "Loss: \n",
      "0.00015930751526920046\n",
      "\n",
      "\n",
      "# 786\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90364787]\n",
      " [0.87450047]\n",
      " [0.89048878]]\n",
      "Loss: \n",
      "0.00015929827696059518\n",
      "\n",
      "\n",
      "# 787\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90364828]\n",
      " [0.87449998]\n",
      " [0.8904888 ]]\n",
      "Loss: \n",
      "0.00015928904130488533\n",
      "\n",
      "\n",
      "# 788\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.9036487 ]\n",
      " [0.8744995 ]\n",
      " [0.89048883]]\n",
      "Loss: \n",
      "0.00015927980830102102\n",
      "\n",
      "\n",
      "# 789\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90364911]\n",
      " [0.87449901]\n",
      " [0.89048886]]\n",
      "Loss: \n",
      "0.0001592705779479508\n",
      "\n",
      "\n",
      "# 790\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90364953]\n",
      " [0.87449852]\n",
      " [0.89048889]]\n",
      "Loss: \n",
      "0.0001592613502446306\n",
      "\n",
      "\n",
      "# 791\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90364995]\n",
      " [0.87449804]\n",
      " [0.89048892]]\n",
      "Loss: \n",
      "0.00015925212519000756\n",
      "\n",
      "\n",
      "# 792\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90365036]\n",
      " [0.87449755]\n",
      " [0.89048895]]\n",
      "Loss: \n",
      "0.00015924290278303749\n",
      "\n",
      "\n",
      "# 793\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90365078]\n",
      " [0.87449706]\n",
      " [0.89048898]]\n",
      "Loss: \n",
      "0.00015923368302267463\n",
      "\n",
      "\n",
      "# 794\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90365119]\n",
      " [0.87449658]\n",
      " [0.890489  ]]\n",
      "Loss: \n",
      "0.00015922446590786916\n",
      "\n",
      "\n",
      "# 795\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90365161]\n",
      " [0.87449609]\n",
      " [0.89048903]]\n",
      "Loss: \n",
      "0.0001592152514375777\n",
      "\n",
      "\n",
      "# 796\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90365202]\n",
      " [0.8744956 ]\n",
      " [0.89048906]]\n",
      "Loss: \n",
      "0.00015920603961075435\n",
      "\n",
      "\n",
      "# 797\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90365244]\n",
      " [0.87449512]\n",
      " [0.89048909]]\n",
      "Loss: \n",
      "0.0001591968304263563\n",
      "\n",
      "\n",
      "# 798\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90365285]\n",
      " [0.87449463]\n",
      " [0.89048912]]\n",
      "Loss: \n",
      "0.00015918762388333427\n",
      "\n",
      "\n",
      "# 799\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90365327]\n",
      " [0.87449415]\n",
      " [0.89048915]]\n",
      "Loss: \n",
      "0.00015917841998064832\n",
      "\n",
      "\n",
      "# 800\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90365368]\n",
      " [0.87449366]\n",
      " [0.89048918]]\n",
      "Loss: \n",
      "0.00015916921871725806\n",
      "\n",
      "\n",
      "# 801\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90365409]\n",
      " [0.87449318]\n",
      " [0.8904892 ]]\n",
      "Loss: \n",
      "0.00015916002009211394\n",
      "\n",
      "\n",
      "# 802\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90365451]\n",
      " [0.87449269]\n",
      " [0.89048923]]\n",
      "Loss: \n",
      "0.00015915082410417823\n",
      "\n",
      "\n",
      "# 803\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90365492]\n",
      " [0.8744922 ]\n",
      " [0.89048926]]\n",
      "Loss: \n",
      "0.00015914163075241025\n",
      "\n",
      "\n",
      "# 804\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90365534]\n",
      " [0.87449172]\n",
      " [0.89048929]]\n",
      "Loss: \n",
      "0.0001591324400357654\n",
      "\n",
      "\n",
      "# 805\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90365575]\n",
      " [0.87449123]\n",
      " [0.89048932]]\n",
      "Loss: \n",
      "0.00015912325195320643\n",
      "\n",
      "\n",
      "# 806\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90365617]\n",
      " [0.87449075]\n",
      " [0.89048935]]\n",
      "Loss: \n",
      "0.00015911406650368875\n",
      "\n",
      "\n",
      "# 807\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90365658]\n",
      " [0.87449026]\n",
      " [0.89048937]]\n",
      "Loss: \n",
      "0.00015910488368618022\n",
      "\n",
      "\n",
      "# 808\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90365699]\n",
      " [0.87448978]\n",
      " [0.8904894 ]]\n",
      "Loss: \n",
      "0.00015909570349963178\n",
      "\n",
      "\n",
      "# 809\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90365741]\n",
      " [0.8744893 ]\n",
      " [0.89048943]]\n",
      "Loss: \n",
      "0.0001590865259430118\n",
      "\n",
      "\n",
      "# 810\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90365782]\n",
      " [0.87448881]\n",
      " [0.89048946]]\n",
      "Loss: \n",
      "0.00015907735101528418\n",
      "\n",
      "\n",
      "# 811\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90365823]\n",
      " [0.87448833]\n",
      " [0.89048949]]\n",
      "Loss: \n",
      "0.00015906817871540248\n",
      "\n",
      "\n",
      "# 812\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90365865]\n",
      " [0.87448784]\n",
      " [0.89048952]]\n",
      "Loss: \n",
      "0.0001590590090423412\n",
      "\n",
      "\n",
      "# 813\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90365906]\n",
      " [0.87448736]\n",
      " [0.89048954]]\n",
      "Loss: \n",
      "0.0001590498419950555\n",
      "\n",
      "\n",
      "# 814\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90365947]\n",
      " [0.87448687]\n",
      " [0.89048957]]\n",
      "Loss: \n",
      "0.00015904067757250995\n",
      "\n",
      "\n",
      "# 815\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90365989]\n",
      " [0.87448639]\n",
      " [0.8904896 ]]\n",
      "Loss: \n",
      "0.00015903151577367116\n",
      "\n",
      "\n",
      "# 816\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.9036603 ]\n",
      " [0.87448591]\n",
      " [0.89048963]]\n",
      "Loss: \n",
      "0.00015902235659750747\n",
      "\n",
      "\n",
      "# 817\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90366071]\n",
      " [0.87448542]\n",
      " [0.89048966]]\n",
      "Loss: \n",
      "0.00015901320004297676\n",
      "\n",
      "\n",
      "# 818\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90366112]\n",
      " [0.87448494]\n",
      " [0.89048969]]\n",
      "Loss: \n",
      "0.00015900404610905003\n",
      "\n",
      "\n",
      "# 819\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90366154]\n",
      " [0.87448446]\n",
      " [0.89048971]]\n",
      "Loss: \n",
      "0.00015899489479469684\n",
      "\n",
      "\n",
      "# 820\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90366195]\n",
      " [0.87448397]\n",
      " [0.89048974]]\n",
      "Loss: \n",
      "0.00015898574609887682\n",
      "\n",
      "\n",
      "# 821\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90366236]\n",
      " [0.87448349]\n",
      " [0.89048977]]\n",
      "Loss: \n",
      "0.00015897660002056355\n",
      "\n",
      "\n",
      "# 822\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90366277]\n",
      " [0.87448301]\n",
      " [0.8904898 ]]\n",
      "Loss: \n",
      "0.00015896745655872037\n",
      "\n",
      "\n",
      "# 823\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90366319]\n",
      " [0.87448253]\n",
      " [0.89048983]]\n",
      "Loss: \n",
      "0.00015895831571231846\n",
      "\n",
      "\n",
      "# 824\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.9036636 ]\n",
      " [0.87448204]\n",
      " [0.89048985]]\n",
      "Loss: \n",
      "0.000158949177480331\n",
      "\n",
      "\n",
      "# 825\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90366401]\n",
      " [0.87448156]\n",
      " [0.89048988]]\n",
      "Loss: \n",
      "0.00015894004186171957\n",
      "\n",
      "\n",
      "# 826\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90366442]\n",
      " [0.87448108]\n",
      " [0.89048991]]\n",
      "Loss: \n",
      "0.0001589309088554601\n",
      "\n",
      "\n",
      "# 827\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90366483]\n",
      " [0.8744806 ]\n",
      " [0.89048994]]\n",
      "Loss: \n",
      "0.00015892177846052292\n",
      "\n",
      "\n",
      "# 828\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90366525]\n",
      " [0.87448011]\n",
      " [0.89048997]]\n",
      "Loss: \n",
      "0.0001589126506758754\n",
      "\n",
      "\n",
      "# 829\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90366566]\n",
      " [0.87447963]\n",
      " [0.89049   ]]\n",
      "Loss: \n",
      "0.00015890352550049347\n",
      "\n",
      "\n",
      "# 830\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90366607]\n",
      " [0.87447915]\n",
      " [0.89049002]]\n",
      "Loss: \n",
      "0.0001588944029333451\n",
      "\n",
      "\n",
      "# 831\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90366648]\n",
      " [0.87447867]\n",
      " [0.89049005]]\n",
      "Loss: \n",
      "0.00015888528297340856\n",
      "\n",
      "\n",
      "# 832\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90366689]\n",
      " [0.87447819]\n",
      " [0.89049008]]\n",
      "Loss: \n",
      "0.000158876165619651\n",
      "\n",
      "\n",
      "# 833\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.9036673 ]\n",
      " [0.87447771]\n",
      " [0.89049011]]\n",
      "Loss: \n",
      "0.00015886705087105223\n",
      "\n",
      "\n",
      "# 834\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90366771]\n",
      " [0.87447722]\n",
      " [0.89049014]]\n",
      "Loss: \n",
      "0.00015885793872658186\n",
      "\n",
      "\n",
      "# 835\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90366813]\n",
      " [0.87447674]\n",
      " [0.89049016]]\n",
      "Loss: \n",
      "0.00015884882918521532\n",
      "\n",
      "\n",
      "# 836\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90366854]\n",
      " [0.87447626]\n",
      " [0.89049019]]\n",
      "Loss: \n",
      "0.00015883972224593106\n",
      "\n",
      "\n",
      "# 837\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90366895]\n",
      " [0.87447578]\n",
      " [0.89049022]]\n",
      "Loss: \n",
      "0.0001588306179076999\n",
      "\n",
      "\n",
      "# 838\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90366936]\n",
      " [0.8744753 ]\n",
      " [0.89049025]]\n",
      "Loss: \n",
      "0.00015882151616950136\n",
      "\n",
      "\n",
      "# 839\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90366977]\n",
      " [0.87447482]\n",
      " [0.89049028]]\n",
      "Loss: \n",
      "0.00015881241703031155\n",
      "\n",
      "\n",
      "# 840\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90367018]\n",
      " [0.87447434]\n",
      " [0.8904903 ]]\n",
      "Loss: \n",
      "0.0001588033204891092\n",
      "\n",
      "\n",
      "# 841\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90367059]\n",
      " [0.87447386]\n",
      " [0.89049033]]\n",
      "Loss: \n",
      "0.00015879422654486807\n",
      "\n",
      "\n",
      "# 842\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.903671  ]\n",
      " [0.87447338]\n",
      " [0.89049036]]\n",
      "Loss: \n",
      "0.00015878513519656983\n",
      "\n",
      "\n",
      "# 843\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90367141]\n",
      " [0.8744729 ]\n",
      " [0.89049039]]\n",
      "Loss: \n",
      "0.00015877604644319265\n",
      "\n",
      "\n",
      "# 844\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90367182]\n",
      " [0.87447242]\n",
      " [0.89049042]]\n",
      "Loss: \n",
      "0.00015876696028371414\n",
      "\n",
      "\n",
      "# 845\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90367223]\n",
      " [0.87447194]\n",
      " [0.89049044]]\n",
      "Loss: \n",
      "0.000158757876717119\n",
      "\n",
      "\n",
      "# 846\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90367264]\n",
      " [0.87447146]\n",
      " [0.89049047]]\n",
      "Loss: \n",
      "0.0001587487957423819\n",
      "\n",
      "\n",
      "# 847\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90367305]\n",
      " [0.87447098]\n",
      " [0.8904905 ]]\n",
      "Loss: \n",
      "0.000158739717358485\n",
      "\n",
      "\n",
      "# 848\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90367346]\n",
      " [0.8744705 ]\n",
      " [0.89049053]]\n",
      "Loss: \n",
      "0.00015873064156441148\n",
      "\n",
      "\n",
      "# 849\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90367387]\n",
      " [0.87447002]\n",
      " [0.89049055]]\n",
      "Loss: \n",
      "0.0001587215683591398\n",
      "\n",
      "\n",
      "# 850\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90367428]\n",
      " [0.87446954]\n",
      " [0.89049058]]\n",
      "Loss: \n",
      "0.00015871249774165465\n",
      "\n",
      "\n",
      "# 851\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90367469]\n",
      " [0.87446906]\n",
      " [0.89049061]]\n",
      "Loss: \n",
      "0.00015870342971094286\n",
      "\n",
      "\n",
      "# 852\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.9036751 ]\n",
      " [0.87446858]\n",
      " [0.89049064]]\n",
      "Loss: \n",
      "0.00015869436426598044\n",
      "\n",
      "\n",
      "# 853\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90367551]\n",
      " [0.87446811]\n",
      " [0.89049067]]\n",
      "Loss: \n",
      "0.00015868530140575234\n",
      "\n",
      "\n",
      "# 854\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90367592]\n",
      " [0.87446763]\n",
      " [0.89049069]]\n",
      "Loss: \n",
      "0.00015867624112924812\n",
      "\n",
      "\n",
      "# 855\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90367633]\n",
      " [0.87446715]\n",
      " [0.89049072]]\n",
      "Loss: \n",
      "0.00015866718343545091\n",
      "\n",
      "\n",
      "# 856\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90367673]\n",
      " [0.87446667]\n",
      " [0.89049075]]\n",
      "Loss: \n",
      "0.0001586581283233403\n",
      "\n",
      "\n",
      "# 857\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90367714]\n",
      " [0.87446619]\n",
      " [0.89049078]]\n",
      "Loss: \n",
      "0.00015864907579190893\n",
      "\n",
      "\n",
      "# 858\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90367755]\n",
      " [0.87446571]\n",
      " [0.8904908 ]]\n",
      "Loss: \n",
      "0.00015864002584013788\n",
      "\n",
      "\n",
      "# 859\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90367796]\n",
      " [0.87446524]\n",
      " [0.89049083]]\n",
      "Loss: \n",
      "0.0001586309784670174\n",
      "\n",
      "\n",
      "# 860\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90367837]\n",
      " [0.87446476]\n",
      " [0.89049086]]\n",
      "Loss: \n",
      "0.00015862193367153476\n",
      "\n",
      "\n",
      "# 861\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90367878]\n",
      " [0.87446428]\n",
      " [0.89049089]]\n",
      "Loss: \n",
      "0.00015861289145267752\n",
      "\n",
      "\n",
      "# 862\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90367919]\n",
      " [0.8744638 ]\n",
      " [0.89049092]]\n",
      "Loss: \n",
      "0.00015860385180943058\n",
      "\n",
      "\n",
      "# 863\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90367959]\n",
      " [0.87446332]\n",
      " [0.89049094]]\n",
      "Loss: \n",
      "0.0001585948147407872\n",
      "\n",
      "\n",
      "# 864\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90368   ]\n",
      " [0.87446285]\n",
      " [0.89049097]]\n",
      "Loss: \n",
      "0.0001585857802457329\n",
      "\n",
      "\n",
      "# 865\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90368041]\n",
      " [0.87446237]\n",
      " [0.890491  ]]\n",
      "Loss: \n",
      "0.00015857674832326358\n",
      "\n",
      "\n",
      "# 866\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90368082]\n",
      " [0.87446189]\n",
      " [0.89049103]]\n",
      "Loss: \n",
      "0.00015856771897236374\n",
      "\n",
      "\n",
      "# 867\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90368123]\n",
      " [0.87446142]\n",
      " [0.89049105]]\n",
      "Loss: \n",
      "0.00015855869219202385\n",
      "\n",
      "\n",
      "# 868\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90368163]\n",
      " [0.87446094]\n",
      " [0.89049108]]\n",
      "Loss: \n",
      "0.00015854966798124274\n",
      "\n",
      "\n",
      "# 869\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90368204]\n",
      " [0.87446046]\n",
      " [0.89049111]]\n",
      "Loss: \n",
      "0.0001585406463390004\n",
      "\n",
      "\n",
      "# 870\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90368245]\n",
      " [0.87445999]\n",
      " [0.89049114]]\n",
      "Loss: \n",
      "0.0001585316272643006\n",
      "\n",
      "\n",
      "# 871\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90368286]\n",
      " [0.87445951]\n",
      " [0.89049116]]\n",
      "Loss: \n",
      "0.0001585226107561284\n",
      "\n",
      "\n",
      "# 872\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90368326]\n",
      " [0.87445903]\n",
      " [0.89049119]]\n",
      "Loss: \n",
      "0.00015851359681347984\n",
      "\n",
      "\n",
      "# 873\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90368367]\n",
      " [0.87445856]\n",
      " [0.89049122]]\n",
      "Loss: \n",
      "0.00015850458543534803\n",
      "\n",
      "\n",
      "# 874\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90368408]\n",
      " [0.87445808]\n",
      " [0.89049125]]\n",
      "Loss: \n",
      "0.00015849557662073074\n",
      "\n",
      "\n",
      "# 875\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90368448]\n",
      " [0.8744576 ]\n",
      " [0.89049127]]\n",
      "Loss: \n",
      "0.00015848657036861781\n",
      "\n",
      "\n",
      "# 876\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90368489]\n",
      " [0.87445713]\n",
      " [0.8904913 ]]\n",
      "Loss: \n",
      "0.00015847756667800603\n",
      "\n",
      "\n",
      "# 877\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.9036853 ]\n",
      " [0.87445665]\n",
      " [0.89049133]]\n",
      "Loss: \n",
      "0.00015846856554789252\n",
      "\n",
      "\n",
      "# 878\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90368571]\n",
      " [0.87445618]\n",
      " [0.89049136]]\n",
      "Loss: \n",
      "0.00015845956697726972\n",
      "\n",
      "\n",
      "# 879\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90368611]\n",
      " [0.8744557 ]\n",
      " [0.89049138]]\n",
      "Loss: \n",
      "0.00015845057096514195\n",
      "\n",
      "\n",
      "# 880\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90368652]\n",
      " [0.87445523]\n",
      " [0.89049141]]\n",
      "Loss: \n",
      "0.00015844157751050068\n",
      "\n",
      "\n",
      "# 881\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90368693]\n",
      " [0.87445475]\n",
      " [0.89049144]]\n",
      "Loss: \n",
      "0.00015843258661234148\n",
      "\n",
      "\n",
      "# 882\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90368733]\n",
      " [0.87445428]\n",
      " [0.89049147]]\n",
      "Loss: \n",
      "0.0001584235982696697\n",
      "\n",
      "\n",
      "# 883\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90368774]\n",
      " [0.8744538 ]\n",
      " [0.89049149]]\n",
      "Loss: \n",
      "0.00015841461248147917\n",
      "\n",
      "\n",
      "# 884\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90368814]\n",
      " [0.87445333]\n",
      " [0.89049152]]\n",
      "Loss: \n",
      "0.0001584056292467706\n",
      "\n",
      "\n",
      "# 885\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90368855]\n",
      " [0.87445285]\n",
      " [0.89049155]]\n",
      "Loss: \n",
      "0.0001583966485645394\n",
      "\n",
      "\n",
      "# 886\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90368896]\n",
      " [0.87445238]\n",
      " [0.89049158]]\n",
      "Loss: \n",
      "0.00015838767043379234\n",
      "\n",
      "\n",
      "# 887\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90368936]\n",
      " [0.8744519 ]\n",
      " [0.8904916 ]]\n",
      "Loss: \n",
      "0.0001583786948535273\n",
      "\n",
      "\n",
      "# 888\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90368977]\n",
      " [0.87445143]\n",
      " [0.89049163]]\n",
      "Loss: \n",
      "0.0001583697218227445\n",
      "\n",
      "\n",
      "# 889\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90369017]\n",
      " [0.87445095]\n",
      " [0.89049166]]\n",
      "Loss: \n",
      "0.00015836075134044916\n",
      "\n",
      "\n",
      "# 890\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90369058]\n",
      " [0.87445048]\n",
      " [0.89049169]]\n",
      "Loss: \n",
      "0.00015835178340563912\n",
      "\n",
      "\n",
      "# 891\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90369098]\n",
      " [0.87445001]\n",
      " [0.89049171]]\n",
      "Loss: \n",
      "0.00015834281801731985\n",
      "\n",
      "\n",
      "# 892\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90369139]\n",
      " [0.87444953]\n",
      " [0.89049174]]\n",
      "Loss: \n",
      "0.00015833385517448998\n",
      "\n",
      "\n",
      "# 893\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90369179]\n",
      " [0.87444906]\n",
      " [0.89049177]]\n",
      "Loss: \n",
      "0.00015832489487616066\n",
      "\n",
      "\n",
      "# 894\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.9036922 ]\n",
      " [0.87444859]\n",
      " [0.8904918 ]]\n",
      "Loss: \n",
      "0.00015831593712132958\n",
      "\n",
      "\n",
      "# 895\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90369261]\n",
      " [0.87444811]\n",
      " [0.89049182]]\n",
      "Loss: \n",
      "0.00015830698190900485\n",
      "\n",
      "\n",
      "# 896\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90369301]\n",
      " [0.87444764]\n",
      " [0.89049185]]\n",
      "Loss: \n",
      "0.0001582980292381879\n",
      "\n",
      "\n",
      "# 897\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90369342]\n",
      " [0.87444717]\n",
      " [0.89049188]]\n",
      "Loss: \n",
      "0.00015828907910789064\n",
      "\n",
      "\n",
      "# 898\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90369382]\n",
      " [0.87444669]\n",
      " [0.8904919 ]]\n",
      "Loss: \n",
      "0.00015828013151711212\n",
      "\n",
      "\n",
      "# 899\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90369422]\n",
      " [0.87444622]\n",
      " [0.89049193]]\n",
      "Loss: \n",
      "0.0001582711864648659\n",
      "\n",
      "\n",
      "# 900\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90369463]\n",
      " [0.87444575]\n",
      " [0.89049196]]\n",
      "Loss: \n",
      "0.00015826224395015036\n",
      "\n",
      "\n",
      "# 901\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90369503]\n",
      " [0.87444527]\n",
      " [0.89049199]]\n",
      "Loss: \n",
      "0.00015825330397198004\n",
      "\n",
      "\n",
      "# 902\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90369544]\n",
      " [0.8744448 ]\n",
      " [0.89049201]]\n",
      "Loss: \n",
      "0.0001582443665293597\n",
      "\n",
      "\n",
      "# 903\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90369584]\n",
      " [0.87444433]\n",
      " [0.89049204]]\n",
      "Loss: \n",
      "0.00015823543162129944\n",
      "\n",
      "\n",
      "# 904\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90369625]\n",
      " [0.87444386]\n",
      " [0.89049207]]\n",
      "Loss: \n",
      "0.00015822649924680985\n",
      "\n",
      "\n",
      "# 905\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90369665]\n",
      " [0.87444338]\n",
      " [0.89049209]]\n",
      "Loss: \n",
      "0.00015821756940489841\n",
      "\n",
      "\n",
      "# 906\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90369705]\n",
      " [0.87444291]\n",
      " [0.89049212]]\n",
      "Loss: \n",
      "0.00015820864209457086\n",
      "\n",
      "\n",
      "# 907\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90369746]\n",
      " [0.87444244]\n",
      " [0.89049215]]\n",
      "Loss: \n",
      "0.00015819971731484544\n",
      "\n",
      "\n",
      "# 908\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90369786]\n",
      " [0.87444197]\n",
      " [0.89049218]]\n",
      "Loss: \n",
      "0.00015819079506472822\n",
      "\n",
      "\n",
      "# 909\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90369827]\n",
      " [0.8744415 ]\n",
      " [0.8904922 ]]\n",
      "Loss: \n",
      "0.00015818187534323065\n",
      "\n",
      "\n",
      "# 910\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90369867]\n",
      " [0.87444103]\n",
      " [0.89049223]]\n",
      "Loss: \n",
      "0.00015817295814936726\n",
      "\n",
      "\n",
      "# 911\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90369907]\n",
      " [0.87444055]\n",
      " [0.89049226]]\n",
      "Loss: \n",
      "0.0001581640434821487\n",
      "\n",
      "\n",
      "# 912\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90369948]\n",
      " [0.87444008]\n",
      " [0.89049228]]\n",
      "Loss: \n",
      "0.00015815513134058968\n",
      "\n",
      "\n",
      "# 913\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90369988]\n",
      " [0.87443961]\n",
      " [0.89049231]]\n",
      "Loss: \n",
      "0.00015814622172369755\n",
      "\n",
      "\n",
      "# 914\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90370028]\n",
      " [0.87443914]\n",
      " [0.89049234]]\n",
      "Loss: \n",
      "0.00015813731463049335\n",
      "\n",
      "\n",
      "# 915\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90370069]\n",
      " [0.87443867]\n",
      " [0.89049237]]\n",
      "Loss: \n",
      "0.00015812841005998887\n",
      "\n",
      "\n",
      "# 916\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90370109]\n",
      " [0.8744382 ]\n",
      " [0.89049239]]\n",
      "Loss: \n",
      "0.00015811950801119878\n",
      "\n",
      "\n",
      "# 917\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90370149]\n",
      " [0.87443773]\n",
      " [0.89049242]]\n",
      "Loss: \n",
      "0.00015811060848313884\n",
      "\n",
      "\n",
      "# 918\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.9037019 ]\n",
      " [0.87443726]\n",
      " [0.89049245]]\n",
      "Loss: \n",
      "0.0001581017114748212\n",
      "\n",
      "\n",
      "# 919\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.9037023 ]\n",
      " [0.87443679]\n",
      " [0.89049247]]\n",
      "Loss: \n",
      "0.0001580928169852678\n",
      "\n",
      "\n",
      "# 920\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.9037027 ]\n",
      " [0.87443632]\n",
      " [0.8904925 ]]\n",
      "Loss: \n",
      "0.0001580839250134925\n",
      "\n",
      "\n",
      "# 921\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.9037031 ]\n",
      " [0.87443585]\n",
      " [0.89049253]]\n",
      "Loss: \n",
      "0.00015807503555851244\n",
      "\n",
      "\n",
      "# 922\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90370351]\n",
      " [0.87443538]\n",
      " [0.89049255]]\n",
      "Loss: \n",
      "0.0001580661486193445\n",
      "\n",
      "\n",
      "# 923\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90370391]\n",
      " [0.87443491]\n",
      " [0.89049258]]\n",
      "Loss: \n",
      "0.0001580572641950093\n",
      "\n",
      "\n",
      "# 924\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90370431]\n",
      " [0.87443444]\n",
      " [0.89049261]]\n",
      "Loss: \n",
      "0.00015804838228452388\n",
      "\n",
      "\n",
      "# 925\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90370471]\n",
      " [0.87443397]\n",
      " [0.89049264]]\n",
      "Loss: \n",
      "0.0001580395028869069\n",
      "\n",
      "\n",
      "# 926\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90370511]\n",
      " [0.8744335 ]\n",
      " [0.89049266]]\n",
      "Loss: \n",
      "0.00015803062600118042\n",
      "\n",
      "\n",
      "# 927\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90370552]\n",
      " [0.87443303]\n",
      " [0.89049269]]\n",
      "Loss: \n",
      "0.00015802175162636236\n",
      "\n",
      "\n",
      "# 928\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90370592]\n",
      " [0.87443256]\n",
      " [0.89049272]]\n",
      "Loss: \n",
      "0.0001580128797614734\n",
      "\n",
      "\n",
      "# 929\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90370632]\n",
      " [0.87443209]\n",
      " [0.89049274]]\n",
      "Loss: \n",
      "0.00015800401040553548\n",
      "\n",
      "\n",
      "# 930\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90370672]\n",
      " [0.87443162]\n",
      " [0.89049277]]\n",
      "Loss: \n",
      "0.00015799514355756963\n",
      "\n",
      "\n",
      "# 931\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90370712]\n",
      " [0.87443115]\n",
      " [0.8904928 ]]\n",
      "Loss: \n",
      "0.00015798627921659772\n",
      "\n",
      "\n",
      "# 932\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90370752]\n",
      " [0.87443068]\n",
      " [0.89049282]]\n",
      "Loss: \n",
      "0.00015797741738164363\n",
      "\n",
      "\n",
      "# 933\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90370793]\n",
      " [0.87443022]\n",
      " [0.89049285]]\n",
      "Loss: \n",
      "0.00015796855805172522\n",
      "\n",
      "\n",
      "# 934\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90370833]\n",
      " [0.87442975]\n",
      " [0.89049288]]\n",
      "Loss: \n",
      "0.000157959701225874\n",
      "\n",
      "\n",
      "# 935\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90370873]\n",
      " [0.87442928]\n",
      " [0.8904929 ]]\n",
      "Loss: \n",
      "0.0001579508469031083\n",
      "\n",
      "\n",
      "# 936\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90370913]\n",
      " [0.87442881]\n",
      " [0.89049293]]\n",
      "Loss: \n",
      "0.00015794199508245316\n",
      "\n",
      "\n",
      "# 937\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90370953]\n",
      " [0.87442834]\n",
      " [0.89049296]]\n",
      "Loss: \n",
      "0.0001579331457629374\n",
      "\n",
      "\n",
      "# 938\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90370993]\n",
      " [0.87442787]\n",
      " [0.89049298]]\n",
      "Loss: \n",
      "0.0001579242989435796\n",
      "\n",
      "\n",
      "# 939\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90371033]\n",
      " [0.87442741]\n",
      " [0.89049301]]\n",
      "Loss: \n",
      "0.00015791545462341344\n",
      "\n",
      "\n",
      "# 940\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90371073]\n",
      " [0.87442694]\n",
      " [0.89049304]]\n",
      "Loss: \n",
      "0.00015790661280145525\n",
      "\n",
      "\n",
      "# 941\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90371113]\n",
      " [0.87442647]\n",
      " [0.89049306]]\n",
      "Loss: \n",
      "0.00015789777347674017\n",
      "\n",
      "\n",
      "# 942\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90371153]\n",
      " [0.874426  ]\n",
      " [0.89049309]]\n",
      "Loss: \n",
      "0.00015788893664829402\n",
      "\n",
      "\n",
      "# 943\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90371193]\n",
      " [0.87442554]\n",
      " [0.89049312]]\n",
      "Loss: \n",
      "0.0001578801023151442\n",
      "\n",
      "\n",
      "# 944\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90371234]\n",
      " [0.87442507]\n",
      " [0.89049314]]\n",
      "Loss: \n",
      "0.00015787127047631812\n",
      "\n",
      "\n",
      "# 945\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90371274]\n",
      " [0.8744246 ]\n",
      " [0.89049317]]\n",
      "Loss: \n",
      "0.000157862441130842\n",
      "\n",
      "\n",
      "# 946\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90371314]\n",
      " [0.87442413]\n",
      " [0.8904932 ]]\n",
      "Loss: \n",
      "0.00015785361427775148\n",
      "\n",
      "\n",
      "# 947\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90371354]\n",
      " [0.87442367]\n",
      " [0.89049322]]\n",
      "Loss: \n",
      "0.00015784478991606892\n",
      "\n",
      "\n",
      "# 948\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90371394]\n",
      " [0.8744232 ]\n",
      " [0.89049325]]\n",
      "Loss: \n",
      "0.00015783596804482661\n",
      "\n",
      "\n",
      "# 949\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90371434]\n",
      " [0.87442273]\n",
      " [0.89049328]]\n",
      "Loss: \n",
      "0.00015782714866306044\n",
      "\n",
      "\n",
      "# 950\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90371474]\n",
      " [0.87442227]\n",
      " [0.8904933 ]]\n",
      "Loss: \n",
      "0.00015781833176979547\n",
      "\n",
      "\n",
      "# 951\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90371513]\n",
      " [0.8744218 ]\n",
      " [0.89049333]]\n",
      "Loss: \n",
      "0.00015780951736406437\n",
      "\n",
      "\n",
      "# 952\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90371553]\n",
      " [0.87442133]\n",
      " [0.89049336]]\n",
      "Loss: \n",
      "0.0001578007054449004\n",
      "\n",
      "\n",
      "# 953\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90371593]\n",
      " [0.87442087]\n",
      " [0.89049338]]\n",
      "Loss: \n",
      "0.0001577918960113355\n",
      "\n",
      "\n",
      "# 954\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90371633]\n",
      " [0.8744204 ]\n",
      " [0.89049341]]\n",
      "Loss: \n",
      "0.00015778308906240395\n",
      "\n",
      "\n",
      "# 955\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90371673]\n",
      " [0.87441994]\n",
      " [0.89049344]]\n",
      "Loss: \n",
      "0.00015777428459713482\n",
      "\n",
      "\n",
      "# 956\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90371713]\n",
      " [0.87441947]\n",
      " [0.89049346]]\n",
      "Loss: \n",
      "0.00015776548261456832\n",
      "\n",
      "\n",
      "# 957\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90371753]\n",
      " [0.87441901]\n",
      " [0.89049349]]\n",
      "Loss: \n",
      "0.00015775668311373363\n",
      "\n",
      "\n",
      "# 958\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90371793]\n",
      " [0.87441854]\n",
      " [0.89049352]]\n",
      "Loss: \n",
      "0.00015774788609366572\n",
      "\n",
      "\n",
      "# 959\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90371833]\n",
      " [0.87441807]\n",
      " [0.89049354]]\n",
      "Loss: \n",
      "0.00015773909155340562\n",
      "\n",
      "\n",
      "# 960\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90371873]\n",
      " [0.87441761]\n",
      " [0.89049357]]\n",
      "Loss: \n",
      "0.00015773029949198367\n",
      "\n",
      "\n",
      "# 961\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90371913]\n",
      " [0.87441714]\n",
      " [0.8904936 ]]\n",
      "Loss: \n",
      "0.00015772150990843683\n",
      "\n",
      "\n",
      "# 962\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90371952]\n",
      " [0.87441668]\n",
      " [0.89049362]]\n",
      "Loss: \n",
      "0.00015771272280180223\n",
      "\n",
      "\n",
      "# 963\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90371992]\n",
      " [0.87441621]\n",
      " [0.89049365]]\n",
      "Loss: \n",
      "0.00015770393817111933\n",
      "\n",
      "\n",
      "# 964\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90372032]\n",
      " [0.87441575]\n",
      " [0.89049368]]\n",
      "Loss: \n",
      "0.0001576951560154228\n",
      "\n",
      "\n",
      "# 965\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90372072]\n",
      " [0.87441528]\n",
      " [0.8904937 ]]\n",
      "Loss: \n",
      "0.0001576863763337508\n",
      "\n",
      "\n",
      "# 966\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90372112]\n",
      " [0.87441482]\n",
      " [0.89049373]]\n",
      "Loss: \n",
      "0.0001576775991251439\n",
      "\n",
      "\n",
      "# 967\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90372152]\n",
      " [0.87441436]\n",
      " [0.89049376]]\n",
      "Loss: \n",
      "0.0001576688243886404\n",
      "\n",
      "\n",
      "# 968\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90372191]\n",
      " [0.87441389]\n",
      " [0.89049378]]\n",
      "Loss: \n",
      "0.00015766005212328022\n",
      "\n",
      "\n",
      "# 969\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90372231]\n",
      " [0.87441343]\n",
      " [0.89049381]]\n",
      "Loss: \n",
      "0.00015765128232809962\n",
      "\n",
      "\n",
      "# 970\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90372271]\n",
      " [0.87441296]\n",
      " [0.89049383]]\n",
      "Loss: \n",
      "0.0001576425150021455\n",
      "\n",
      "\n",
      "# 971\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90372311]\n",
      " [0.8744125 ]\n",
      " [0.89049386]]\n",
      "Loss: \n",
      "0.0001576337501444559\n",
      "\n",
      "\n",
      "# 972\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90372351]\n",
      " [0.87441204]\n",
      " [0.89049389]]\n",
      "Loss: \n",
      "0.00015762498775407068\n",
      "\n",
      "\n",
      "# 973\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.9037239 ]\n",
      " [0.87441157]\n",
      " [0.89049391]]\n",
      "Loss: \n",
      "0.00015761622783003285\n",
      "\n",
      "\n",
      "# 974\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.9037243 ]\n",
      " [0.87441111]\n",
      " [0.89049394]]\n",
      "Loss: \n",
      "0.00015760747037138508\n",
      "\n",
      "\n",
      "# 975\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.9037247 ]\n",
      " [0.87441064]\n",
      " [0.89049397]]\n",
      "Loss: \n",
      "0.00015759871537717138\n",
      "\n",
      "\n",
      "# 976\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.9037251 ]\n",
      " [0.87441018]\n",
      " [0.89049399]]\n",
      "Loss: \n",
      "0.0001575899628464303\n",
      "\n",
      "\n",
      "# 977\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90372549]\n",
      " [0.87440972]\n",
      " [0.89049402]]\n",
      "Loss: \n",
      "0.0001575812127782106\n",
      "\n",
      "\n",
      "# 978\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90372589]\n",
      " [0.87440926]\n",
      " [0.89049404]]\n",
      "Loss: \n",
      "0.00015757246517155473\n",
      "\n",
      "\n",
      "# 979\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90372629]\n",
      " [0.87440879]\n",
      " [0.89049407]]\n",
      "Loss: \n",
      "0.0001575637200255061\n",
      "\n",
      "\n",
      "# 980\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90372668]\n",
      " [0.87440833]\n",
      " [0.8904941 ]]\n",
      "Loss: \n",
      "0.00015755497733911262\n",
      "\n",
      "\n",
      "# 981\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90372708]\n",
      " [0.87440787]\n",
      " [0.89049412]]\n",
      "Loss: \n",
      "0.0001575462371114183\n",
      "\n",
      "\n",
      "# 982\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90372748]\n",
      " [0.8744074 ]\n",
      " [0.89049415]]\n",
      "Loss: \n",
      "0.0001575374993414679\n",
      "\n",
      "\n",
      "# 983\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90372787]\n",
      " [0.87440694]\n",
      " [0.89049418]]\n",
      "Loss: \n",
      "0.00015752876402831123\n",
      "\n",
      "\n",
      "# 984\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90372827]\n",
      " [0.87440648]\n",
      " [0.8904942 ]]\n",
      "Loss: \n",
      "0.0001575200311709923\n",
      "\n",
      "\n",
      "# 985\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90372867]\n",
      " [0.87440602]\n",
      " [0.89049423]]\n",
      "Loss: \n",
      "0.00015751130076855786\n",
      "\n",
      "\n",
      "# 986\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90372906]\n",
      " [0.87440556]\n",
      " [0.89049425]]\n",
      "Loss: \n",
      "0.00015750257282005876\n",
      "\n",
      "\n",
      "# 987\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90372946]\n",
      " [0.87440509]\n",
      " [0.89049428]]\n",
      "Loss: \n",
      "0.0001574938473245454\n",
      "\n",
      "\n",
      "# 988\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90372986]\n",
      " [0.87440463]\n",
      " [0.89049431]]\n",
      "Loss: \n",
      "0.0001574851242810591\n",
      "\n",
      "\n",
      "# 989\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90373025]\n",
      " [0.87440417]\n",
      " [0.89049433]]\n",
      "Loss: \n",
      "0.00015747640368865489\n",
      "\n",
      "\n",
      "# 990\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90373065]\n",
      " [0.87440371]\n",
      " [0.89049436]]\n",
      "Loss: \n",
      "0.00015746768554637973\n",
      "\n",
      "\n",
      "# 991\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90373104]\n",
      " [0.87440325]\n",
      " [0.89049439]]\n",
      "Loss: \n",
      "0.00015745896985328546\n",
      "\n",
      "\n",
      "# 992\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90373144]\n",
      " [0.87440279]\n",
      " [0.89049441]]\n",
      "Loss: \n",
      "0.00015745025660842673\n",
      "\n",
      "\n",
      "# 993\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90373183]\n",
      " [0.87440232]\n",
      " [0.89049444]]\n",
      "Loss: \n",
      "0.00015744154581084503\n",
      "\n",
      "\n",
      "# 994\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90373223]\n",
      " [0.87440186]\n",
      " [0.89049446]]\n",
      "Loss: \n",
      "0.00015743283745959973\n",
      "\n",
      "\n",
      "# 995\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90373263]\n",
      " [0.8744014 ]\n",
      " [0.89049449]]\n",
      "Loss: \n",
      "0.000157424131553742\n",
      "\n",
      "\n",
      "# 996\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90373302]\n",
      " [0.87440094]\n",
      " [0.89049452]]\n",
      "Loss: \n",
      "0.00015741542809232187\n",
      "\n",
      "\n",
      "# 997\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90373342]\n",
      " [0.87440048]\n",
      " [0.89049454]]\n",
      "Loss: \n",
      "0.00015740672707439222\n",
      "\n",
      "\n",
      "# 998\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90373381]\n",
      " [0.87440002]\n",
      " [0.89049457]]\n",
      "Loss: \n",
      "0.0001573980284990092\n",
      "\n",
      "\n",
      "# 999\n",
      "\n",
      "Input (scaled): \n",
      "[[0.4 0.9]\n",
      " [0.2 0.5]\n",
      " [0.6 0.6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      "[[0.90373421]\n",
      " [0.87439956]\n",
      " [0.89049459]]\n",
      "Loss: \n",
      "0.00015738933236522456\n",
      "\n",
      "\n",
      "Predicted data based on trained weights: \n",
      "Input (scaled): \n",
      "[[1. 1.]]\n",
      "Output: \n",
      "[[0.91638081]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# X = (hours studying, hours sleeping), y = score on test\n",
    "x_all = np.array(([2, 9], [1, 5], [3, 6], [5, 10]), dtype=float) # input data\n",
    "y = np.array(([92], [86], [89]), dtype=float) # output\n",
    "\n",
    "# scale units\n",
    "x_all = x_all/np.amax(x_all, axis=0) # scaling input data\n",
    "y = y/100 # scaling output data (max test score is 100)\n",
    "\n",
    "# split data\n",
    "X = np.split(x_all, [3])[0] # training data\n",
    "x_predicted = np.split(x_all, [3])[1] # testing data\n",
    "\n",
    "class neural_network(object):\n",
    "  def __init__(self):\n",
    "  #parameters\n",
    "    self.inputSize = 2\n",
    "    self.outputSize = 1\n",
    "    self.hiddenSize = 3\n",
    "\n",
    "  #weights\n",
    "    self.W1 = np.random.randn(self.inputSize, self.hiddenSize) # (3x2) weight matrix from input to hidden layer\n",
    "    self.W2 = np.random.randn(self.hiddenSize, self.outputSize) # (3x1) weight matrix from hidden to output layer\n",
    "\n",
    "  def forward(self, X):\n",
    "    #forward propagation through our network\n",
    "    self.z = np.dot(X, self.W1) # dot product of X (input) and first set of 3x2 weights\n",
    "    self.z2 = self.sigmoid(self.z) # activation function\n",
    "    self.z3 = np.dot(self.z2, self.W2) # dot product of hidden layer (z2) and second set of 3x1 weights\n",
    "    o = self.sigmoid(self.z3) # final activation function\n",
    "    return o\n",
    "\n",
    "  def sigmoid(self, s):\n",
    "    # activation function\n",
    "    return 1/(1+np.exp(-s))\n",
    "\n",
    "  def sigmoidPrime(self, s):\n",
    "    #derivative of sigmoid\n",
    "    return s * (1 - s)\n",
    "\n",
    "  def backward(self, X, y, o):\n",
    "    # backward propagate through the network\n",
    "    self.o_error = y - o # error in output\n",
    "    self.o_delta = self.o_error*self.sigmoidPrime(o) # applying derivative of sigmoid to error\n",
    "\n",
    "    self.z2_error = self.o_delta.dot(self.W2.T) # z2 error: how much our hidden layer weights contributed to output error\n",
    "    self.z2_delta = self.z2_error*self.sigmoidPrime(self.z2) # applying derivative of sigmoid to z2 error\n",
    "\n",
    "    self.W1 += X.T.dot(self.z2_delta) # adjusting first set (input --> hidden) weights\n",
    "    self.W2 += self.z2.T.dot(self.o_delta) # adjusting second set (hidden --> output) weights\n",
    "\n",
    "  def train(self, X, y):\n",
    "    o = self.forward(X)\n",
    "    self.backward(X, y, o)\n",
    "\n",
    "  def saveWeights(self):\n",
    "    np.savetxt(\"w1.txt\", self.W1, fmt=\"%s\")\n",
    "    np.savetxt(\"w2.txt\", self.W2, fmt=\"%s\")\n",
    "\n",
    "  def predict(self):\n",
    "    print(\"Predicted data based on trained weights: \")\n",
    "    print(\"Input (scaled): \\n\" + str(x_predicted))\n",
    "    print(\"Output: \\n\" + str(self.forward(x_predicted)))\n",
    "\n",
    "nn = neural_network()\n",
    "for i in range(1000): # trains the nn 1,000 times\n",
    "  print(\"# \" + str(i) + \"\\n\")\n",
    "  print(\"Input (scaled): \\n\" + str(X))\n",
    "  print(\"Actual Output: \\n\" + str(y))\n",
    "  print(\"Predicted Output: \\n\" + str(nn.forward(X)))\n",
    "  print(\"Loss: \\n\" + str(np.mean(np.square(y - nn.forward(X))))) # mean squared error\n",
    "  print(\"\\n\")\n",
    "  nn.train(X, y)\n",
    "\n",
    "nn.saveWeights()\n",
    "nn.predict()"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Derivative of Sigmoid Prime\n",
    "\n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
